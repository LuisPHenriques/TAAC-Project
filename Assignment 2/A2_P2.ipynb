{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:03:56.498276300Z",
     "start_time": "2023-11-28T17:03:56.491330700Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 2. (B) I."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[1, 0, 0, 1, 0, 1, 1, 1, 1, 0]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bag_of_words(sentence, vocabulary):\n",
    "    # Initialize a vector with zeros for each word in the vocabulary\n",
    "    bag_of_words_vector = [0] * len(vocabulary)\n",
    "\n",
    "    # Tokenize the sentence into words\n",
    "    words = sentence.split()\n",
    "\n",
    "    # Count the frequency of each word in the sentence\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            index = vocabulary.index(word)\n",
    "            bag_of_words_vector[index] += 1\n",
    "\n",
    "    return bag_of_words_vector\n",
    "\n",
    "vocabulary = ['and', 'apple', 'banana', 'eat', 'hate', 'I', 'pie', 'strawberry', 'the', 'they']\n",
    "\n",
    "input_sentence = \"You and I eat the strawberry pie\"\n",
    "\n",
    "result = bag_of_words(input_sentence, vocabulary)\n",
    "\n",
    "\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:24:37.670795500Z",
     "start_time": "2023-11-28T17:24:37.645079100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise 2. (B) II."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.15633009706732018,\n 0.0,\n 0.0,\n 0.2702283027548262,\n 0.0,\n 0.21347090311639716,\n 0.3658068211806669,\n 0.544772959537148,\n 0.16440326996208335,\n 0.0]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tf(term, document):\n",
    "    term_count = document.count(term)\n",
    "    total_terms = len(document)\n",
    "\n",
    "    return term_count / total_terms if total_terms > 0 else 0.0\n",
    "\n",
    "def idf(term, document_frequency, total_documents):\n",
    "    term_document_frequency = document_frequency.get(term, 0)\n",
    "\n",
    "    return math.log(total_documents / (term_document_frequency + 1)) + 1\n",
    "\n",
    "def tfidf(term, document, document_frequency, total_documents):\n",
    "\n",
    "    return tf(term, document) * idf(term, document_frequency, total_documents)\n",
    "\n",
    "def compute_tfidf_representation(sentence, vocabulary, document_frequency, total_documents):\n",
    "    words = sentence.split()\n",
    "    tfidf_vector = [tfidf(word, words, document_frequency, total_documents) for word in vocabulary]\n",
    "\n",
    "    return tfidf_vector\n",
    "\n",
    "vocabulary = ['and', 'apple', 'banana', 'eat', 'hate', 'I', 'pie', 'strawberry', 'the', 'they']\n",
    "document_frequency = {'and': 90, 'apple': 30, 'banana': 15, 'eat': 40, 'hate': 10, 'I': 60, 'pie': 20, 'strawberry': 5, 'the': 85, 'they': 30}\n",
    "total_documents = 100\n",
    "\n",
    "\n",
    "input_sentence = \"You and I eat the strawberry pie\"\n",
    "\n",
    "\n",
    "tfidf_result = compute_tfidf_representation(input_sentence, vocabulary, document_frequency, total_documents)\n",
    "\n",
    "tfidf_result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:27:06.403348500Z",
     "start_time": "2023-11-28T17:27:06.396863300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF representation: [0.015051502236832335, 0.0, 0.0, 0.13089867598202215, 0.0, 0.0, 0.22991970177630003, 0.4279617533648558, 0.02321698992825356, 0.0]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = [\"and\", \"apple\", \"banana\", \"eat\", \"hate\", \"I\", \"pie\", \"strawberry\", \"the\", \"they\"]\n",
    "\n",
    "document_counts = [90, 30, 15, 40, 10, 60, 20, 5, 85, 30]\n",
    "\n",
    "total_documents = 100\n",
    "\n",
    "sentence = \"You and I eat the strawberry pie\"\n",
    "\n",
    "# Tokenize the sentence into words\n",
    "words = sentence.lower().split()\n",
    "\n",
    "# Compute TF-IDF representation\n",
    "tfidf_representation = []\n",
    "\n",
    "for term in vocabulary:\n",
    "    # Compute TF (Term Frequency)\n",
    "    tf = words.count(term) / len(words) if len(words) > 0 else 0\n",
    "\n",
    "    # Compute IDF (Inverse Document Frequency)\n",
    "    idf = math.log(total_documents / document_counts[vocabulary.index(term)])\n",
    "\n",
    "    # Compute TF-IDF\n",
    "    tfidf = tf * idf\n",
    "\n",
    "    # Append TF-IDF value to the representation\n",
    "    tfidf_representation.append(tfidf)\n",
    "\n",
    "print(\"TF-IDF representation:\", tfidf_representation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "References\n",
    " - https://www.learndatasci.com/glossary/tf-idf-term-frequency-inverse-document-frequency/#:~:text=The%20TF%2DIDF%20of%20a,multiplying%20TF%20and%20IDF%20scores.&text=Translated%20into%20plain%20English%2C%20importance,between%20documents%20measured%20by%20IDF."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers):\n",
    "        \"\"\"\n",
    "        Initializes the LSTMLanguageModel.\n",
    "\n",
    "        Parameters:\n",
    "            - vocab_size (int): Size of the vocabulary.\n",
    "            - embed_size (int): Size of the word embeddings.\n",
    "            - hidden_size (int): Size of the hidden state of the LSTM.\n",
    "            - num_layers (int): Number of layers in the LSTM.\n",
    "        \"\"\"\n",
    "        super(LSTMLanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h0=None):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the LSTMLanguageModel.\n",
    "\n",
    "        Parameters:\n",
    "            - x (torch.Tensor): Input sequence of token indices (batch_size, sequence_length).\n",
    "            - h0 (torch.Tensor, optional): Initial hidden state (num_layers * num_directions, batch_size, hidden_size).\n",
    "\n",
    "        Returns:\n",
    "            - output (torch.Tensor): Output sequence from the language model (batch_size, sequence_length, vocab_size).\n",
    "            - hn (torch.Tensor): Final hidden state (num_layers * num_directions, batch_size, hidden_size).\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x)\n",
    "        output, hn = self.lstm(embedded, h0)\n",
    "        output = self.fc(output)\n",
    "        return output, hn\n",
    "\n",
    "    def generate(self, x, h0=None, no=10):\n",
    "        \"\"\"\n",
    "        Generates a sequence of token indices using greedy decoding.\n",
    "\n",
    "        Parameters:\n",
    "            - x (torch.Tensor): Input token index (batch_size, 1).\n",
    "            - h0 (torch.Tensor, optional): Initial hidden state (num_layers * num_directions, batch_size, hidden_size).\n",
    "            - no (int): Number of tokens to be generated.\n",
    "\n",
    "        Returns:\n",
    "            - generated_sequence (torch.Tensor): Decoded sequence of token indices (batch_size, no).\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            generated_sequence = []\n",
    "            current_token = x\n",
    "\n",
    "            for _ in range(no):\n",
    "                output, hn = self.forward(current_token, h0)\n",
    "                probabilities = nn.functional.softmax(output[:, -1, :], dim=1)\n",
    "                next_token = torch.argmax(probabilities, dim=1, keepdim=True)\n",
    "                generated_sequence.append(next_token)\n",
    "                current_token = next_token\n",
    "\n",
    "            generated_sequence = torch.cat(generated_sequence, dim=1)\n",
    "            return generated_sequence"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T17:03:43.860357400Z",
     "start_time": "2023-11-28T17:03:39.407274100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
