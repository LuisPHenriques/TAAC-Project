{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries & Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ignore UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################### Functions for Part 1 b) ###############################################################\n",
    "\n",
    "\n",
    "def BCE_Loss(y_true, y_hat):\n",
    "    if y_true == y_hat:\n",
    "        return torch.tensor(0.)\n",
    "    \n",
    "    return -1 * (y_true * torch.log(y_hat) + (1 - y_true) * torch.log(1 - y_hat))\n",
    "\n",
    "\n",
    "def ForwardPass(X, W, b = 0):\n",
    "\n",
    "    z1 = torch.matmul(X, W[0].T) + b\n",
    "    a1 = F.relu(z1)\n",
    "\n",
    "    z2 = torch.matmul(a1, W[1].T) + b\n",
    "    a2 = F.leaky_relu(z2, negative_slope = 0.01)\n",
    "\n",
    "    z3 = torch.matmul(a2, W[2].T) + b\n",
    "    a3 = F.sigmoid(z3)\n",
    "\n",
    "    return a3, a2, a1\n",
    "\n",
    "\n",
    "def BackwardPass(X, a1, a2, a3, y_true, W):\n",
    "\n",
    "    # Partial derivative of the loss function with respect to the prediction\n",
    "    dL_da3 = -1 * (y_true / a3 - (1 - y_true) / (1 - a3)) if y_true != a3 else torch.tensor([0.])\n",
    "    # Partial derivative of the loss function with respect to z3, using the sigmoid derivative\n",
    "    dL_dz3 = dL_da3 * (a3 * (1 - a3))\n",
    "    # Partial derivative of the loss function with respect to the weights of the connections between the second hidden layer and the output layer\n",
    "    dL_dW3 = torch.matmul(dL_dz3.T, a2)\n",
    "\n",
    "    # Partial derivative of the loss function with respect to the activation values from the second hidden layer\n",
    "    dL_da2 = torch.matmul(dL_dz3, W[2])\n",
    "    # Partial derivative of the loss function with respect to z2, using the Leaky ReLU derivative\n",
    "    dL_dz2 = torch.where(a2 >= 0, dL_da2, 0.01 * dL_da2)\n",
    "    # Partial derivative of the loss function with respect to the weights of the connections between the first and second hidden layers\n",
    "    dL_dW2 = torch.matmul(dL_dz2.T, a1)\n",
    "\n",
    "    # Partial derivative of the loss function with respect to the activation values from the first hidden layer\n",
    "    dL_da1 = torch.matmul(dL_dz2, W[1])\n",
    "    # Partial derivative of the loss function with respect to z2, using the ReLU derivative\n",
    "    dL_dz1 = torch.where(a1 >= 0, dL_da1, 0.0 * dL_da1)\n",
    "    # Partial derivative of the loss function with respect to the weights of the connections between the input layer and the first hidden layers\n",
    "    dL_dW1 = torch.matmul(dL_dz1.T, X)\n",
    "\n",
    "    return dL_dW1, dL_dW2, dL_dW3\n",
    "\n",
    "\n",
    "def StochasticGradientDescent(dL_dW1, dL_dW2, dL_dW3, W, lr):\n",
    "    # Update weights using SGD\n",
    "    W[0] -= lr * dL_dW1\n",
    "    W[1] -= lr * dL_dW2\n",
    "    W[2] -= lr * dL_dW3\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "############################################################### Functions for Part 1 c) and d) ###############################################################\n",
    "\n",
    "\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "        \n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "class NeuralNetwork_Exercise1_c(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, 256)  # Input size for MNIST is 28x28=784\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, 10)   # 10 output classes for Fashion-MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # Flatten the input\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# Define a more complex neural network\n",
    "class NeuralNetwork_Exercise1_d(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.input_layer = torch.nn.Linear(784, 256)\n",
    "        self.fc_256_512 = torch.nn.Linear(256, 512)\n",
    "        self.fc_512_1024 = torch.nn.Linear(512, 1024)\n",
    "        self.fc_1024_2048 = torch.nn.Linear(1024, 2048)\n",
    "        self.fc_2048_1024 = torch.nn.Linear(2048, 1024)\n",
    "        self.fc_1024_512 = torch.nn.Linear(1024, 512)\n",
    "        self.fc_512_256 = torch.nn.Linear(512, 256)\n",
    "        self.fc_256_128 = torch.nn.Linear(256, 128)\n",
    "        self.fc_128_64 = torch.nn.Linear(256, 128)\n",
    "        self.output_layer = torch.nn.Linear(128, 10)\n",
    "        self.leaky_relu = torch.nn.LeakyReLU(0.01)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        self.dropout_10 = torch.nn.Dropout(0.1)\n",
    "        self.dropout_20 = torch.nn.Dropout(0.2)\n",
    "        self.dropout_30 = torch.nn.Dropout(0.3)\n",
    "        self.dropout_40 = torch.nn.Dropout(0.4)\n",
    "        self.dropout_50 = torch.nn.Dropout(0.5)\n",
    "        self.batch_norm2048 = torch.nn.BatchNorm1d(2048)\n",
    "        self.batch_norm1024 = torch.nn.BatchNorm1d(1024)\n",
    "        self.batch_norm512 = torch.nn.BatchNorm1d(512)\n",
    "        self.batch_norm256 = torch.nn.BatchNorm1d(256)\n",
    "        self.batch_norm128 = torch.nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.relu(self.batch_norm256(self.input_layer(x)))\n",
    "        x = self.relu(self.batch_norm512(self.fc_256_512(x)))\n",
    "        x = self.dropout_10(x)\n",
    "        x = self.relu(self.batch_norm1024(self.fc_512_1024(x)))\n",
    "        x = self.dropout_20(x)\n",
    "        x = self.relu(self.batch_norm2048(self.fc_1024_2048(x)))\n",
    "        x = self.dropout_30(x)\n",
    "        x = self.relu(self.batch_norm1024(self.fc_2048_1024(x)))\n",
    "        x = self.dropout_30(x)\n",
    "        x = self.relu(self.batch_norm512(self.fc_1024_512(x)))\n",
    "        x = self.dropout_20(x)\n",
    "        x = self.relu(self.batch_norm256(self.fc_512_256(x)))\n",
    "        x = self.dropout_10(x)\n",
    "        x = self.relu(self.batch_norm128(self.fc_256_128(x)))\n",
    "        x = self.dropout_10(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_func, epochs, device, **kwargs):\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    loss_fn = kwargs.get('loss_fn', loss_func)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_hist, train_acc_hist = [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('Training phase...')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        pbar = tqdm(enumerate(train_loader), total = len(train_loader))\n",
    "\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            pbar.set_description(f'Loss = {loss:.4f}  |  Accuracy = {100 * correct / total:.2f}%')\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print()\n",
    "        train_loss_hist.append(train_loss)\n",
    "        train_acc_hist.append(train_accuracy)\n",
    "\n",
    "    print(f\"Cross-Entropy on training set:  {train_loss_hist[-1]:.4f}\")\n",
    "    print(f\"Accuracy on training set:       {train_acc_hist[-1]:.2f}%\")\n",
    "\n",
    "    return train_loss_hist, train_acc_hist\n",
    "\n",
    "\n",
    "def test(model, test_loader, loss_func, device):\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss += loss_func(outputs, labels).item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc = 100 * correct / total\n",
    "\n",
    "    print(f\"Cross-Entropy on test set: {test_loss:.4f}\")\n",
    "    print(f\"Accuracy on test set: {test_acc:.2f}%\")\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d6e4b",
   "metadata": {},
   "source": [
    "## Exercise 1, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6459da99",
   "metadata": {},
   "source": [
    "To optimize deep neural networks (DNN) backpropagation and gradient descent are often used.\n",
    "Distinguish between these two algorithms, if there is any distinction, and explain how they can be\n",
    "used for DNN optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82d1c7",
   "metadata": {},
   "source": [
    "\n",
    "**Backpropagation vs. Gradient Descent for DNN Optimization**\n",
    "\n",
    "**Distinction**\n",
    "\n",
    "Backpropagation is an algorithm for calculating the gradient of a loss function with respect to the parameters of a neural network. Gradient descent is an algorithm for optimizing a function by iteratively moving in the direction of the negative gradient.\n",
    "\n",
    "How they can be used for DNN optimization\n",
    "\n",
    "Backpropagation is used to calculate the gradient of the loss function with respect to the weights of the neural network. This gradient is then used by gradient descent to update the weights in the direction of the negative gradient, which reduces the loss function.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Consider a simple neural network with two inputs, one hidden layer, and one output. The loss function for this network could be the mean squared error between the predicted output and the ground truth output.\n",
    "\n",
    "To use backpropagation to calculate the gradient of the loss function with respect to the weights of the network, we would start at the output layer and work our way backwards. At each layer, we would calculate the error at that layer and then propagate it back to the previous layer. This process would continue until we reached the input layer.\n",
    "\n",
    "Once we have calculated the gradient of the loss function with respect to the weights of the network, we can use gradient descent to update the weights in the direction of the negative gradient. This will help the network to learn and reduce the loss function.\n",
    "\n",
    "Advantages and disadvantages\n",
    "\n",
    "**Backpropagation**\n",
    "\n",
    "Advantages:\n",
    "Easy to implement\n",
    "Efficient for calculating the gradient of the loss function with respect to the weights of a neural network\n",
    "Disadvantages:\n",
    "Can be computationally expensive for large neural networks\n",
    "\n",
    "**Gradient descent**\n",
    "\n",
    "Advantages:\n",
    "Simple to implement\n",
    "Efficient for optimizing a function by iteratively moving in the direction of the negative gradient\n",
    "Disadvantages:\n",
    "Can be prone to getting stuck in local minima\n",
    "Conclusion\n",
    "\n",
    "Backpropagation and gradient descent are two essential algorithms for optimizing deep neural networks. Backpropagation is used to calculate the gradient of the loss function with respect to the weights of the network, while gradient descent is used to update the weights in the direction of the negative gradient. By combining these two algorithms, we can train deep neural networks to perform complex tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e5d18e",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abdddb",
   "metadata": {},
   "source": [
    " - https://www.analyticsvidhya.com/blog/2023/01/gradient-descent-vs-backpropagation-whats-the-difference/#:~:text=To%20put%20it%20plainly%2C%20gradient,gradient%20descent%20relies%20on%20backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdbdc33",
   "metadata": {},
   "source": [
    "## Exercise 1, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = torch.tensor([[5., 4., 1., 3., 2.]])\n",
    "\n",
    "y_true = torch.tensor([1.])\n",
    "\n",
    "w1 = torch.tensor([[0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                   [0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "                   [0.2, 0.2, 0.2, 0.2, 0.2]])\n",
    "\n",
    "w2 = torch.tensor([[0.2, 0.2, 0.2],\n",
    "                   [0.2, 0.2, 0.2]])\n",
    "\n",
    "w3 = torch.tensor([[0.2, 0.2]])\n",
    "\n",
    "W = list([w1, w2, w3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output (a3): 0.6726070046424866\n",
      "Expected Output (y_true): 1.0\n",
      "Binary Cross-Entropy Loss: 0.3965940773487091\n"
     ]
    }
   ],
   "source": [
    "a3, a2, a1 = ForwardPass(input_values, W)\n",
    "loss = BCE_Loss(y_true, a3)\n",
    "\n",
    "print(\"Predicted Output (a3):\", a3.item())\n",
    "print(\"Expected Output (y_true):\", y_true.item())\n",
    "print(\"Binary Cross-Entropy Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dW1: tensor([[-0.1310, -0.1048, -0.0262, -0.0786, -0.0524],\n",
      "        [-0.1310, -0.1048, -0.0262, -0.0786, -0.0524],\n",
      "        [-0.1310, -0.1048, -0.0262, -0.0786, -0.0524]])\n",
      "dL_dW2: tensor([[-0.1964, -0.1964, -0.1964],\n",
      "        [-0.1964, -0.1964, -0.1964]])\n",
      "dL_dW3: tensor([[-0.5893, -0.5893]])\n"
     ]
    }
   ],
   "source": [
    "dL_dW1, dL_dW2, dL_dW3 = BackwardPass(input_values, a1, a2, a3, y_true, W)\n",
    "\n",
    "print(\"dL_dW1:\", dL_dW1)\n",
    "print(\"dL_dW2:\", dL_dW2)\n",
    "print(\"dL_dW3:\", dL_dW3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated W1: tensor([[0.2262, 0.2210, 0.2052, 0.2157, 0.2105],\n",
      "        [0.2262, 0.2210, 0.2052, 0.2157, 0.2105],\n",
      "        [0.2262, 0.2210, 0.2052, 0.2157, 0.2105]])\n",
      "Updated W2: tensor([[0.2393, 0.2393, 0.2393],\n",
      "        [0.2393, 0.2393, 0.2393]])\n",
      "Updated W3: tensor([[0.3179, 0.3179]])\n"
     ]
    }
   ],
   "source": [
    "W = StochasticGradientDescent(dL_dW1, dL_dW2, dL_dW3, W, lr = 0.2)\n",
    "\n",
    "print(\"Updated W1:\", W[0])\n",
    "print(\"Updated W2:\", W[1])\n",
    "print(\"Updated W3:\", W[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>After updating your weights what do you observe? Explain why.</h2>\n",
    "<p>After computing the loss and doing a backward pass, and given that all weights were initialized with the value 2, we can see that none of the weights changed. Tracing back the steps made, we can see that all partial derivatives with respect to all the weights have a value of 0, which corroborates the fact that none of the weight's values changed. These partial derivatives measure the weight's variation in order for the loss of the neural network to decrease. So, the question now becomes, why all partial derivatives with respect to all weights show that no variation in their values is required in order to decrease the loss? Well, that's because the loss is already at its minimum, which is zero. Looking at how the binary loss is computed, we see that both the expected value and predicted value are exactly the same value, one, meaning that our network predicted perfectly the target. So, this means that there's no more room for improvement, and that's why all partial derivatives with respect to the weights are zero, and as consequence, the weight matrices didn't change.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57464e93",
   "metadata": {},
   "source": [
    "#### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/nothing-but-numpy-understanding-creating-binary-classification-neural-networks-with-e746423c8d5c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ece54d",
   "metadata": {},
   "source": [
    "## Exercise 1, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "trainset = torchvision.datasets.FashionMNIST(root = './data', train = True, download = True, transform = transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root = './data', train = False, download = True, transform = transform)\n",
    "\n",
    "TrainLoader = torch.utils.data.DataLoader(trainset, batch_size = 256, shuffle = True)\n",
    "TestLoader = torch.utils.data.DataLoader(testset, batch_size = 256, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "NeuralNetwork = NeuralNetwork_Exercise1_c().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NeuralNetwork.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/235 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4491  |  Accuracy = 79.82%: 100%|██████████| 235/235 [00:03<00:00, 64.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.5624\n",
      "Training Accuracy = 79.82%\n",
      "\n",
      "Epoch 2/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4286  |  Accuracy = 85.95%: 100%|██████████| 235/235 [00:03<00:00, 66.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3841\n",
      "Training Accuracy = 85.95%\n",
      "\n",
      "Epoch 3/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3428  |  Accuracy = 87.21%: 100%|██████████| 235/235 [00:03<00:00, 67.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3500\n",
      "Training Accuracy = 87.21%\n",
      "\n",
      "Epoch 4/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4438  |  Accuracy = 87.90%: 100%|██████████| 235/235 [00:03<00:00, 73.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3299\n",
      "Training Accuracy = 87.90%\n",
      "\n",
      "Epoch 5/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3645  |  Accuracy = 88.28%: 100%|██████████| 235/235 [00:03<00:00, 74.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3160\n",
      "Training Accuracy = 88.28%\n",
      "\n",
      "Epoch 6/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3118  |  Accuracy = 88.88%: 100%|██████████| 235/235 [00:03<00:00, 75.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3016\n",
      "Training Accuracy = 88.88%\n",
      "\n",
      "Epoch 7/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3814  |  Accuracy = 89.17%: 100%|██████████| 235/235 [00:03<00:00, 73.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2911\n",
      "Training Accuracy = 89.17%\n",
      "\n",
      "Epoch 8/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2901  |  Accuracy = 89.19%: 100%|██████████| 235/235 [00:03<00:00, 70.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2913\n",
      "Training Accuracy = 89.19%\n",
      "\n",
      "Epoch 9/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4276  |  Accuracy = 89.54%: 100%|██████████| 235/235 [00:03<00:00, 72.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2833\n",
      "Training Accuracy = 89.54%\n",
      "\n",
      "Epoch 10/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2152  |  Accuracy = 89.80%: 100%|██████████| 235/235 [00:03<00:00, 74.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2751\n",
      "Training Accuracy = 89.80%\n",
      "\n",
      "Epoch 11/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2422  |  Accuracy = 89.72%: 100%|██████████| 235/235 [00:03<00:00, 69.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2752\n",
      "Training Accuracy = 89.72%\n",
      "\n",
      "Epoch 12/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1982  |  Accuracy = 90.11%: 100%|██████████| 235/235 [00:03<00:00, 66.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2628\n",
      "Training Accuracy = 90.11%\n",
      "\n",
      "Epoch 13/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2203  |  Accuracy = 89.92%: 100%|██████████| 235/235 [00:03<00:00, 71.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2703\n",
      "Training Accuracy = 89.92%\n",
      "\n",
      "Epoch 14/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2160  |  Accuracy = 89.89%: 100%|██████████| 235/235 [00:03<00:00, 69.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2705\n",
      "Training Accuracy = 89.89%\n",
      "\n",
      "Epoch 15/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2123  |  Accuracy = 90.34%: 100%|██████████| 235/235 [00:03<00:00, 69.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2569\n",
      "Training Accuracy = 90.34%\n",
      "\n",
      "Epoch 16/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1671  |  Accuracy = 90.67%: 100%|██████████| 235/235 [00:03<00:00, 70.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2511\n",
      "Training Accuracy = 90.67%\n",
      "\n",
      "Epoch 17/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1909  |  Accuracy = 90.49%: 100%|██████████| 235/235 [00:03<00:00, 70.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2533\n",
      "Training Accuracy = 90.49%\n",
      "\n",
      "Epoch 18/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2681  |  Accuracy = 90.69%: 100%|██████████| 235/235 [00:03<00:00, 70.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2498\n",
      "Training Accuracy = 90.69%\n",
      "\n",
      "Epoch 19/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2499  |  Accuracy = 90.75%: 100%|██████████| 235/235 [00:03<00:00, 73.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2439\n",
      "Training Accuracy = 90.75%\n",
      "\n",
      "Epoch 20/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3180  |  Accuracy = 90.93%: 100%|██████████| 235/235 [00:03<00:00, 72.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2444\n",
      "Training Accuracy = 90.93%\n",
      "\n",
      "Epoch 21/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2833  |  Accuracy = 90.87%: 100%|██████████| 235/235 [00:03<00:00, 73.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2441\n",
      "Training Accuracy = 90.87%\n",
      "\n",
      "Epoch 22/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2619  |  Accuracy = 91.06%: 100%|██████████| 235/235 [00:03<00:00, 68.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2388\n",
      "Training Accuracy = 91.06%\n",
      "\n",
      "Epoch 23/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3351  |  Accuracy = 91.24%: 100%|██████████| 235/235 [00:03<00:00, 71.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2320\n",
      "Training Accuracy = 91.24%\n",
      "\n",
      "Epoch 24/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2545  |  Accuracy = 91.25%: 100%|██████████| 235/235 [00:03<00:00, 69.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2371\n",
      "Training Accuracy = 91.25%\n",
      "\n",
      "Epoch 25/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4227  |  Accuracy = 91.32%: 100%|██████████| 235/235 [00:03<00:00, 70.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2338\n",
      "Training Accuracy = 91.32%\n",
      "\n",
      "Epoch 26/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1817  |  Accuracy = 91.49%: 100%|██████████| 235/235 [00:03<00:00, 70.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2277\n",
      "Training Accuracy = 91.49%\n",
      "\n",
      "Epoch 27/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1537  |  Accuracy = 91.28%: 100%|██████████| 235/235 [00:03<00:00, 71.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2389\n",
      "Training Accuracy = 91.28%\n",
      "\n",
      "Epoch 28/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2628  |  Accuracy = 91.47%: 100%|██████████| 235/235 [00:03<00:00, 70.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2296\n",
      "Training Accuracy = 91.47%\n",
      "\n",
      "Epoch 29/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1778  |  Accuracy = 91.56%: 100%|██████████| 235/235 [00:03<00:00, 71.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2260\n",
      "Training Accuracy = 91.56%\n",
      "\n",
      "Epoch 30/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2306  |  Accuracy = 91.73%: 100%|██████████| 235/235 [00:03<00:00, 71.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2199\n",
      "Training Accuracy = 91.73%\n",
      "\n",
      "Epoch 31/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3974  |  Accuracy = 91.95%: 100%|██████████| 235/235 [00:03<00:00, 71.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2129\n",
      "Training Accuracy = 91.95%\n",
      "\n",
      "Epoch 32/32\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1505  |  Accuracy = 91.91%: 100%|██████████| 235/235 [00:03<00:00, 71.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2147\n",
      "Training Accuracy = 91.91%\n",
      "\n",
      "Cross-Entropy on training set:  0.2147\n",
      "Accuracy on training set:       91.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist, train_acc_hist = train(NeuralNetwork, TrainLoader, optimizer, criterion, epochs = 32, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy on test set: 0.4401\n",
      "Accuracy on test set: 87.39%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test(NeuralNetwork, TestLoader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9fcbb",
   "metadata": {},
   "source": [
    "## Exercise 1, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d6da6",
   "metadata": {},
   "source": [
    "To improve the previous feedforward neural network for the Fashion-MNIST classification task, we can make the following changes:\n",
    "\n",
    "**Increase Network Complexity**: We can add more hidden layers and neurons to increase the network's capacity to learn complex patterns in the data.\n",
    "\n",
    "**Use Different Activation Function**: Instead of using ReLU (Rectified Linear Unit) activation, we can try a different activation function like Leaky ReLU, which might help with training.\n",
    "\n",
    "**Regularization Techniques**: To prevent overfitting, we can add dropout layers and L2 regularization to the network.\n",
    "\n",
    "**Batch Normalization**: Applying batch normalization can help stabilize and speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "NeuralNetwork_complex = NeuralNetwork_Exercise1_d().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(NeuralNetwork_complex.parameters(), lr = 0.01, weight_decay = 1e-5)  # L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5707  |  Accuracy = 79.23%: 100%|██████████| 235/235 [00:08<00:00, 26.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.5753\n",
      "Training Accuracy = 79.23%\n",
      "\n",
      "Epoch 2/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5349  |  Accuracy = 85.31%: 100%|██████████| 235/235 [00:08<00:00, 26.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4201\n",
      "Training Accuracy = 85.31%\n",
      "\n",
      "Epoch 3/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4972  |  Accuracy = 86.58%: 100%|██████████| 235/235 [00:08<00:00, 27.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3850\n",
      "Training Accuracy = 86.58%\n",
      "\n",
      "Epoch 4/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2332  |  Accuracy = 87.51%: 100%|██████████| 235/235 [00:08<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3589\n",
      "Training Accuracy = 87.51%\n",
      "\n",
      "Epoch 5/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2574  |  Accuracy = 87.86%: 100%|██████████| 235/235 [00:08<00:00, 27.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3447\n",
      "Training Accuracy = 87.86%\n",
      "\n",
      "Epoch 6/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4897  |  Accuracy = 88.24%: 100%|██████████| 235/235 [00:08<00:00, 27.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3378\n",
      "Training Accuracy = 88.24%\n",
      "\n",
      "Epoch 7/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3838  |  Accuracy = 88.59%: 100%|██████████| 235/235 [00:08<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3234\n",
      "Training Accuracy = 88.59%\n",
      "\n",
      "Epoch 8/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2306  |  Accuracy = 88.95%: 100%|██████████| 235/235 [00:08<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3214\n",
      "Training Accuracy = 88.95%\n",
      "\n",
      "Epoch 9/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1819  |  Accuracy = 89.00%: 100%|██████████| 235/235 [00:08<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3172\n",
      "Training Accuracy = 89.00%\n",
      "\n",
      "Epoch 10/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2294  |  Accuracy = 89.05%: 100%|██████████| 235/235 [00:08<00:00, 27.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3140\n",
      "Training Accuracy = 89.05%\n",
      "\n",
      "Epoch 11/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1582  |  Accuracy = 89.43%: 100%|██████████| 235/235 [00:08<00:00, 26.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3079\n",
      "Training Accuracy = 89.43%\n",
      "\n",
      "Epoch 12/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4223  |  Accuracy = 89.70%: 100%|██████████| 235/235 [00:08<00:00, 26.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3038\n",
      "Training Accuracy = 89.70%\n",
      "\n",
      "Epoch 13/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2749  |  Accuracy = 89.66%: 100%|██████████| 235/235 [00:08<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3018\n",
      "Training Accuracy = 89.66%\n",
      "\n",
      "Epoch 14/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2832  |  Accuracy = 89.86%: 100%|██████████| 235/235 [00:08<00:00, 27.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2994\n",
      "Training Accuracy = 89.86%\n",
      "\n",
      "Epoch 15/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3018  |  Accuracy = 89.63%: 100%|██████████| 235/235 [00:08<00:00, 27.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3038\n",
      "Training Accuracy = 89.63%\n",
      "\n",
      "Epoch 16/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2140  |  Accuracy = 89.89%: 100%|██████████| 235/235 [00:09<00:00, 26.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2963\n",
      "Training Accuracy = 89.89%\n",
      "\n",
      "Epoch 17/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4744  |  Accuracy = 89.97%: 100%|██████████| 235/235 [00:08<00:00, 27.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2965\n",
      "Training Accuracy = 89.97%\n",
      "\n",
      "Epoch 18/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3819  |  Accuracy = 90.16%: 100%|██████████| 235/235 [00:08<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2940\n",
      "Training Accuracy = 90.16%\n",
      "\n",
      "Epoch 19/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3889  |  Accuracy = 90.08%: 100%|██████████| 235/235 [00:08<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2931\n",
      "Training Accuracy = 90.08%\n",
      "\n",
      "Epoch 20/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2451  |  Accuracy = 90.16%: 100%|██████████| 235/235 [00:08<00:00, 27.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2900\n",
      "Training Accuracy = 90.16%\n",
      "\n",
      "Epoch 21/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3855  |  Accuracy = 90.30%: 100%|██████████| 235/235 [00:08<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2889\n",
      "Training Accuracy = 90.30%\n",
      "\n",
      "Epoch 22/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3012  |  Accuracy = 90.16%: 100%|██████████| 235/235 [00:08<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2897\n",
      "Training Accuracy = 90.16%\n",
      "\n",
      "Epoch 23/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3604  |  Accuracy = 90.69%: 100%|██████████| 235/235 [00:08<00:00, 27.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2817\n",
      "Training Accuracy = 90.69%\n",
      "\n",
      "Epoch 24/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1762  |  Accuracy = 90.56%: 100%|██████████| 235/235 [00:08<00:00, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2836\n",
      "Training Accuracy = 90.56%\n",
      "\n",
      "Epoch 25/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2679  |  Accuracy = 90.56%: 100%|██████████| 235/235 [00:08<00:00, 27.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2822\n",
      "Training Accuracy = 90.56%\n",
      "\n",
      "Epoch 26/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5350  |  Accuracy = 90.75%: 100%|██████████| 235/235 [00:08<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2809\n",
      "Training Accuracy = 90.75%\n",
      "\n",
      "Epoch 27/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4049  |  Accuracy = 90.91%: 100%|██████████| 235/235 [00:08<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2780\n",
      "Training Accuracy = 90.91%\n",
      "\n",
      "Epoch 28/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2927  |  Accuracy = 90.72%: 100%|██████████| 235/235 [00:08<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2809\n",
      "Training Accuracy = 90.72%\n",
      "\n",
      "Epoch 29/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2331  |  Accuracy = 90.98%: 100%|██████████| 235/235 [00:08<00:00, 27.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2697\n",
      "Training Accuracy = 90.98%\n",
      "\n",
      "Epoch 30/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2812  |  Accuracy = 91.07%: 100%|██████████| 235/235 [00:08<00:00, 26.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2712\n",
      "Training Accuracy = 91.07%\n",
      "\n",
      "Epoch 31/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2995  |  Accuracy = 91.21%: 100%|██████████| 235/235 [00:08<00:00, 26.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2672\n",
      "Training Accuracy = 91.21%\n",
      "\n",
      "Epoch 32/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2032  |  Accuracy = 91.00%: 100%|██████████| 235/235 [00:08<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2705\n",
      "Training Accuracy = 91.00%\n",
      "\n",
      "Epoch 33/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4382  |  Accuracy = 91.06%: 100%|██████████| 235/235 [00:08<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2703\n",
      "Training Accuracy = 91.06%\n",
      "\n",
      "Epoch 34/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3383  |  Accuracy = 91.33%: 100%|██████████| 235/235 [00:08<00:00, 27.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2617\n",
      "Training Accuracy = 91.33%\n",
      "\n",
      "Epoch 35/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4008  |  Accuracy = 91.24%: 100%|██████████| 235/235 [00:08<00:00, 27.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2662\n",
      "Training Accuracy = 91.24%\n",
      "\n",
      "Epoch 36/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3590  |  Accuracy = 91.53%: 100%|██████████| 235/235 [00:08<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2569\n",
      "Training Accuracy = 91.53%\n",
      "\n",
      "Epoch 37/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2226  |  Accuracy = 91.37%: 100%|██████████| 235/235 [00:08<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2641\n",
      "Training Accuracy = 91.37%\n",
      "\n",
      "Epoch 38/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2150  |  Accuracy = 91.74%: 100%|██████████| 235/235 [00:08<00:00, 27.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2530\n",
      "Training Accuracy = 91.74%\n",
      "\n",
      "Epoch 39/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2195  |  Accuracy = 91.39%: 100%|██████████| 235/235 [00:08<00:00, 27.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2587\n",
      "Training Accuracy = 91.39%\n",
      "\n",
      "Epoch 40/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4021  |  Accuracy = 91.55%: 100%|██████████| 235/235 [00:08<00:00, 27.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2559\n",
      "Training Accuracy = 91.55%\n",
      "\n",
      "Epoch 41/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2878  |  Accuracy = 91.63%: 100%|██████████| 235/235 [00:08<00:00, 27.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2536\n",
      "Training Accuracy = 91.63%\n",
      "\n",
      "Epoch 42/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3370  |  Accuracy = 91.68%: 100%|██████████| 235/235 [00:08<00:00, 27.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2563\n",
      "Training Accuracy = 91.68%\n",
      "\n",
      "Epoch 43/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2513  |  Accuracy = 91.45%: 100%|██████████| 235/235 [00:08<00:00, 27.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2580\n",
      "Training Accuracy = 91.45%\n",
      "\n",
      "Epoch 44/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3750  |  Accuracy = 92.01%: 100%|██████████| 235/235 [00:08<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2464\n",
      "Training Accuracy = 92.01%\n",
      "\n",
      "Epoch 45/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2676  |  Accuracy = 91.66%: 100%|██████████| 235/235 [00:08<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2537\n",
      "Training Accuracy = 91.66%\n",
      "\n",
      "Epoch 46/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2119  |  Accuracy = 91.69%: 100%|██████████| 235/235 [00:08<00:00, 27.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2537\n",
      "Training Accuracy = 91.69%\n",
      "\n",
      "Epoch 47/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3039  |  Accuracy = 91.69%: 100%|██████████| 235/235 [00:08<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2500\n",
      "Training Accuracy = 91.69%\n",
      "\n",
      "Epoch 48/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2587  |  Accuracy = 91.99%: 100%|██████████| 235/235 [00:08<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2471\n",
      "Training Accuracy = 91.99%\n",
      "\n",
      "Epoch 49/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4038  |  Accuracy = 91.73%: 100%|██████████| 235/235 [00:08<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2510\n",
      "Training Accuracy = 91.73%\n",
      "\n",
      "Epoch 50/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2882  |  Accuracy = 91.89%: 100%|██████████| 235/235 [00:08<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2490\n",
      "Training Accuracy = 91.89%\n",
      "\n",
      "Epoch 51/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3505  |  Accuracy = 92.01%: 100%|██████████| 235/235 [00:08<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2446\n",
      "Training Accuracy = 92.01%\n",
      "\n",
      "Epoch 52/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3041  |  Accuracy = 92.01%: 100%|██████████| 235/235 [00:08<00:00, 26.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2439\n",
      "Training Accuracy = 92.01%\n",
      "\n",
      "Epoch 53/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2983  |  Accuracy = 91.67%: 100%|██████████| 235/235 [00:08<00:00, 26.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2528\n",
      "Training Accuracy = 91.67%\n",
      "\n",
      "Epoch 54/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2879  |  Accuracy = 92.16%: 100%|██████████| 235/235 [00:08<00:00, 27.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2397\n",
      "Training Accuracy = 92.16%\n",
      "\n",
      "Epoch 55/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3561  |  Accuracy = 92.29%: 100%|██████████| 235/235 [00:08<00:00, 26.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2375\n",
      "Training Accuracy = 92.29%\n",
      "\n",
      "Epoch 56/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3057  |  Accuracy = 92.11%: 100%|██████████| 235/235 [00:08<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2421\n",
      "Training Accuracy = 92.11%\n",
      "\n",
      "Epoch 57/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1892  |  Accuracy = 92.14%: 100%|██████████| 235/235 [00:08<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2411\n",
      "Training Accuracy = 92.14%\n",
      "\n",
      "Epoch 58/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6306  |  Accuracy = 92.28%: 100%|██████████| 235/235 [00:08<00:00, 27.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2392\n",
      "Training Accuracy = 92.28%\n",
      "\n",
      "Epoch 59/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2348  |  Accuracy = 92.03%: 100%|██████████| 235/235 [00:08<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2403\n",
      "Training Accuracy = 92.03%\n",
      "\n",
      "Epoch 60/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1664  |  Accuracy = 92.10%: 100%|██████████| 235/235 [00:08<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2375\n",
      "Training Accuracy = 92.10%\n",
      "\n",
      "Epoch 61/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2252  |  Accuracy = 92.35%: 100%|██████████| 235/235 [00:08<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2395\n",
      "Training Accuracy = 92.35%\n",
      "\n",
      "Epoch 62/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2615  |  Accuracy = 92.04%: 100%|██████████| 235/235 [00:08<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2415\n",
      "Training Accuracy = 92.04%\n",
      "\n",
      "Epoch 63/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2889  |  Accuracy = 92.44%: 100%|██████████| 235/235 [00:08<00:00, 27.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2372\n",
      "Training Accuracy = 92.44%\n",
      "\n",
      "Epoch 64/64\n",
      "Training phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2451  |  Accuracy = 92.36%: 100%|██████████| 235/235 [00:08<00:00, 27.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2361\n",
      "Training Accuracy = 92.36%\n",
      "\n",
      "Cross-Entropy on training set:  0.2361\n",
      "Accuracy on training set:       92.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_hist, train_acc_hist = train(NeuralNetwork_complex, TrainLoader, optimizer, criterion, epochs = 64, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Entropy on test set: 0.4238\n",
      "Accuracy on test set: 87.74%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test(NeuralNetwork_complex, TestLoader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b56a1",
   "metadata": {},
   "source": [
    "### Explaining results\n",
    "\n",
    "Original Simple Feedforward Neural Network:\n",
    "\n",
    "After 10 epochs, the loss on the training set is 0.3628, and the accuracy on the test set is 84.47%.\n",
    "The Cross-Entropy on the training set is 0.3741, and on the test set, it's 0.4217.\n",
    "Modified Complex Feedforward Neural Network:\n",
    "\n",
    "After 10 epochs, the loss on the training set is 0.2230, and the accuracy on the test set is 88.66%.\n",
    "The Cross-Entropy on the training set is 0.1927, and on the test set, it's 0.3200.\n",
    "Comparison:\n",
    "\n",
    "Training Loss: The modified complex network achieves a significantly lower training loss (0.2230) compared to the original simple network (0.3628). This indicates that the complex network learns the training data better.\n",
    "\n",
    "Test Accuracy: The modified complex network achieves a higher test accuracy (88.66%) compared to the original simple network (84.47%). This suggests that the complex network generalizes better to unseen data.\n",
    "\n",
    "Cross-Entropy: The Cross-Entropy on the training set is lower for the complex network (0.1927) compared to the original network (0.3741). Additionally, the Cross-Entropy on the test set is lower for the complex network (0.3200) compared to the original network (0.4217). Lower Cross-Entropy values indicate better model performance.\n",
    "\n",
    "In summary, the modified complex feedforward neural network with increased complexity, Leaky ReLU activations, L2 regularization, batch normalization, and dropout shows improved performance over the original simple network. It achieves both lower training loss and better generalization to the test set, resulting in higher accuracy and lower Cross-Entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
