{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Custom Functions & Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:50:51.762292300Z",
     "start_time": "2023-12-21T14:50:49.382402900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import re\n",
    "import spacy \n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Ignore RuntimeWarning and UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:02:13.334929800Z",
     "start_time": "2023-12-21T15:02:13.276939Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub('http\\S*', ' ', text)\n",
    "    \n",
    "    # remove non-alphabetic\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # make lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove one character word\n",
    "    text = re.sub(\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    text = re.sub(\"^[a-zA-Z]\\s+\", '', text)\n",
    "    \n",
    "    # replace double space to one space\n",
    "    text = re.sub(\"\\s+\", ' ', text)\n",
    "    \n",
    "    # tokenize, lemmatize, remove stop words\n",
    "    doc = nlp(text)\n",
    "    text = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "class BPE():\n",
    "    \"\"\"Byte-Pair Encoding: Subword-based tokenization algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus, vocab_size):\n",
    "        \"\"\"Initialize BPE tokenizer.\"\"\"\n",
    "        self.corpus = corpus\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # pre-tokenize the corpus into words, BERT pre-tokenizer is used here\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.word_freqs = defaultdict(int)\n",
    "        self.splits = {}\n",
    "        self.merges = {}\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train BPE tokenizer.\"\"\"\n",
    "    # (1) Compute the frequencies of each word in the corpus\n",
    "    # (2) Compute the base vocabulary of all characters in the corpus\n",
    "    # (3) Split each word into individual characters before training\n",
    "    # (4) Merge the most frequent pair iteratively until the vocabulary size is reached\n",
    "\n",
    "        # compute the frequencies of each word in the corpus\n",
    "        for text in self.corpus:\n",
    "            words_with_offsets = self.tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "            new_words = [word for word, offset in words_with_offsets]\n",
    "            for word in new_words:\n",
    "                self.word_freqs[word] += 1\n",
    "\n",
    "        # compute the base vocabulary of all characters in the corpus\n",
    "        alphabet = []\n",
    "        for word in self.word_freqs.keys():\n",
    "            for letter in word:\n",
    "                if letter not in alphabet:\n",
    "                    alphabet.append(letter)\n",
    "        alphabet.sort()\n",
    "\n",
    "        # add the special token </w> at the beginning of the vocabulary\n",
    "        vocab = [\"</w>\"] + alphabet.copy()\n",
    "\n",
    "        # split each word into individual characters before training\n",
    "        self.splits = {word: [c for c in word] for word in self.word_freqs.keys()}\n",
    "\n",
    "        # merge the most frequent pair iteratively until the vocabulary size is reached\n",
    "        while len(vocab) < self.vocab_size:\n",
    "\n",
    "            # compute the frequency of each pair\n",
    "            pair_freqs = self.compute_pair_freqs()\n",
    "\n",
    "            # find the most frequent pair\n",
    "            best_pair = \"\"\n",
    "            max_freq = None\n",
    "            for pair, freq in pair_freqs.items():\n",
    "                if max_freq is None or max_freq < freq:\n",
    "                    best_pair = pair\n",
    "                    max_freq = freq\n",
    "\n",
    "            # merge the most frequent pair\n",
    "            self.splits = self.merge_pair(*best_pair)\n",
    "            self.merges[best_pair] = best_pair[0] + best_pair[1]\n",
    "            vocab.append(best_pair[0] + best_pair[1])\n",
    "        return self.merges\n",
    "\n",
    "\n",
    "    def compute_pair_freqs(self):\n",
    "        \"\"\"Compute the frequency of each pair.\"\"\"\n",
    "\n",
    "        pair_freqs = defaultdict(int)\n",
    "        for word, freq in self.word_freqs.items():\n",
    "            split = self.splits[word]\n",
    "            if len(split) == 1:\n",
    "                continue\n",
    "            for i in range(len(split) - 1):\n",
    "                pair = (split[i], split[i + 1])\n",
    "                pair_freqs[pair] += freq\n",
    "        return pair_freqs\n",
    "\n",
    "\n",
    "    def merge_pair(self, a, b):\n",
    "        \"\"\"Merge the given pair.\"\"\"\n",
    "\n",
    "        for word in self.word_freqs:\n",
    "            split = self.splits[word]\n",
    "            if len(split) == 1:\n",
    "                continue\n",
    "            i = 0\n",
    "            while i < len(split) - 1:\n",
    "                if split[i] == a and split[i + 1] == b:\n",
    "                    split = split[:i] + [a + b] + split[i + 2 :]\n",
    "                else:\n",
    "                    i += 1\n",
    "            self.splits[word] = split\n",
    "        return self.splits\n",
    "    \n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize a given text with trained BPE tokenizer (including pre-tokenization, split, and merge).\"\"\"\n",
    "        \n",
    "        pre_tokenize_result = self.tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "        pre_tokenized_text = [word for word, offset in pre_tokenize_result]\n",
    "        splits_text = [[l for l in word] for word in pre_tokenized_text]\n",
    "\n",
    "        for pair, merge in self.merges.items():\n",
    "            for idx, split in enumerate(splits_text):\n",
    "                i = 0\n",
    "                while i < len(split) - 1:\n",
    "                    if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                        split = split[:i] + [merge] + split[i + 2 :]\n",
    "                    else:\n",
    "                        i += 1\n",
    "                splits_text[idx] = split\n",
    "        result = sum(splits_text, [])\n",
    "        return result\n",
    "    \n",
    "\n",
    "def get_tfidf_matrix(df, vectorizer):\n",
    "    \n",
    "    # Convert the TF-IDF matrix to a dense NumPy array\n",
    "    matrix = df.todense()\n",
    "\n",
    "    # Convert the dense matrix to a DataFrame\n",
    "    matrix = pd.DataFrame(matrix, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# The sequences being in the formar ['word1', 'word2', 'word3', ...], preprocess it\n",
    "def string2embedding_idx(text_sequence, model):\n",
    "\n",
    "    sequence = []\n",
    "    for token in text_sequence:\n",
    "        try:\n",
    "            sequence.append(model.wv.key_to_index[token])\n",
    "        except:\n",
    "            sequence.append(2899)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def TSNE_10ClosestWords(model, word, size):\n",
    "    \n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    close_words = model.wv.similar_by_word(word)\n",
    "    arr = np.append(arr, np.array([model.wv[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "            \n",
    "    tsne = TSNE(n_components=2, random_state=0, perplexity = 10)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class TweetsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, word2vec_model):\n",
    "        self.df = df\n",
    "        self.word2vec_model = word2vec_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.df.iloc[idx, -1 if self.word2vec_model == 'skipgram' else -2]\n",
    "        label = self.df.iloc[idx, 1]\n",
    "\n",
    "        # Convert sequence to a 1D tensor\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.long)\n",
    "\n",
    "        # Convert label to a 1D tensor (scalar)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return sequence_tensor, label_tensor\n",
    "\n",
    "\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "def train(model, train_loader, test_loader, optimizer, loss_func, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - loss_func (torch.nn.Module): The loss function used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    loss_fn = kwargs.get('loss_fn', loss_func)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            predicted = (output > 0.5).float()\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in pbar:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predicted = (output > 0.5).float()\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings\n",
    "class CustomLSTM(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embeddings = torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.fc(output[:, -1, :])  # Use the last time step's output\n",
    "        return output\n",
    "\n",
    "\n",
    "# GRU model with pre-trained Word2Vec embeddings\n",
    "class CustomGRU(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomGRU, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embeddings = torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.fc(output[:, -1, :])  # Use the last time step's output\n",
    "        return output\n",
    "    \n",
    "\n",
    "# GRU model with pre-trained Word2Vec embeddings and attention mechanism\n",
    "class CustomGRU_Attention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomGRU_Attention, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "        self.attention = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.gru(x)\n",
    "        attention_weights = torch.nn.functional.softmax(self.attention(output), dim = 1)\n",
    "        output = torch.sum(attention_weights * output, dim = 1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings and attention mechanism\n",
    "class CustomLSTM_Attention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomLSTM_Attention, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "        self.attention = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        attention_weights = torch.nn.functional.softmax(self.attention(output), dim = 1)\n",
    "        output = torch.sum(attention_weights * output, dim = 1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "    \n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings and multi-head attention mechanism\n",
    "class CustomLSTM_MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, dropout=0.1, num_layers=1, bidirectional=False, freeze_embeddings=True, num_heads=8):\n",
    "        super(CustomLSTM_MultiHeadAttention, self).__init__()\n",
    "\n",
    "        # Word embedding layer\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze=freeze_embeddings)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.sequence_size = 50\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # Multi-Head Attention layer\n",
    "        self.multihead_attention = torch.nn.MultiheadAttention(embed_dim=hidden_size * (2 if bidirectional else 1), num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Fully-connected layers for classification head\n",
    "        self.fc1 = torch.nn.Linear(hidden_size * (2 if bidirectional else 1) * self.sequence_size, hidden_size * (2 if bidirectional else 1))\n",
    "        self.fc2 = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.leaky_relu = torch.nn.LeakyReLU()\n",
    "        self.bn = torch.nn.BatchNorm1d(hidden_size * (2 if bidirectional else 1))\n",
    "        self.classification_head = torch.nn.Sequential(self.fc1, self.leaky_relu, self.bn, self.fc2)\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization\n",
    "        for layer in self.classification_head:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(layer.weight, nonlinearity = 'leaky_relu')\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization for the multi-head attention\n",
    "        torch.nn.init.kaiming_uniform_(self.multihead_attention.in_proj_weight, nonlinearity = 'leaky_relu')\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization for the LSTM\n",
    "        for layer in self.lstm._all_weights:\n",
    "            for param_name in layer:\n",
    "                if 'weight' in param_name:\n",
    "                    torch.nn.init.kaiming_uniform_(getattr(self.lstm, param_name), nonlinearity = 'leaky_relu')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the embedding of each token in the sequence\n",
    "        embed = self.embedding(x)\n",
    "        # Apply LSTM to the sequence of embeddings\n",
    "        hx, cx = self.lstm(embed)\n",
    "        # Apply multihead attention and get attention weights\n",
    "        attn_output, attn_weights = self.multihead_attention(hx, hx, hx)\n",
    "        # Flatten or pool the multihead attention outputs across the sequence dimension\n",
    "        flattened_output = attn_output.reshape(attn_output.size(0), -1)\n",
    "        # Compute the logits considering the weighted values (V) of the multihead attention\n",
    "        logits = self.classification_head(flattened_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        self.positional_encoding = torch.zeros((1, max_len, d_model))\n",
    "        self.positional_encoding[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        self.positional_encoding[0, :, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.positional_encoding[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class TransformerEncoder(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, embedding_dim, num_heads, hidden_dim, num_layers, max_len=512, dropout=0.1, freeze_embeddings = True):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dim, max_len)\n",
    "        \n",
    "        self.transformer_encoder_layer = torch.nn.TransformerEncoderLayer(\n",
    "                                                                          d_model=embedding_dim,\n",
    "                                                                          nhead=num_heads,\n",
    "                                                                          dim_feedforward=hidden_dim,\n",
    "                                                                          dropout=dropout\n",
    "                                                                          )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(self.transformer_encoder_layer, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = x.permute(1, 0, 2)  # Change from (batch_size, seq_len, embedding_dim) to (seq_len, batch_size, embedding_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.permute(1, 0, 2)  # Change back to (batch_size, seq_len, embedding_dim)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TransformerEncoderForClassification(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, embedding_dim, num_heads, hidden_dim, num_layers, max_len=512, dropout=0.1, freeze_embeddings = True, num_classes=1):\n",
    "        super(TransformerEncoderForClassification, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder = TransformerEncoder(word2vec_model, num_heads, hidden_dim, num_layers, max_len, dropout, freeze_embeddings)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc = torch.nn.Linear(self.embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_output = self.encoder(x)\n",
    "        \n",
    "        # Global average pooling along the sequence dimension\n",
    "        pooled_output = torch.nn.functional.adaptive_avg_pool1d(encoder_output.permute(0, 2, 1), 1).squeeze(-1)\n",
    "        \n",
    "        # Classification head\n",
    "        logits = self.fc(pooled_output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "# FCNN model to be used with the TF-IDF features\n",
    "class CustomFCNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CustomFCNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:27:53.432052200Z",
     "start_time": "2023-12-21T15:27:53.373916800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0                 Just happened a terrible car crash       1\n",
       "1  Heard about #earthquake is different cities, s...       1\n",
       "2  there is a forest fire at spot pond, geese are...       1\n",
       "3           Apocalypse lighting. #Spokane #wildfires       1\n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_train = pd.read_csv('../data/tweets_data/train.csv')[['text', 'target']].reset_index(drop=True)\n",
    "tweets_test = pd.read_csv('../data/tweets_data/test.csv')[['id', 'text']]\n",
    "tweets_labels = pd.read_csv('../data/tweets_data/test_labels.csv', encoding='latin-1')[['choose_one', 'text']]\n",
    "\n",
    "tweets_labels['target'] = (tweets_labels['choose_one']=='Relevant').astype(int)\n",
    "tweets_labels['id'] = tweets_labels.index\n",
    "\n",
    "tweets_test = pd.merge(left = tweets_test, right = tweets_labels, on='id', how = 'left')[['id', 'text_x', 'target']]\n",
    "tweets_test.rename(columns={'text_x': 'text'}, inplace=True)\n",
    "tweets_test = tweets_test[['text', 'target']]\n",
    "\n",
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text using key-words and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:29:01.782176300Z",
     "start_time": "2023-12-21T15:27:58.466800200Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_train['clean_text'] = tweets_train['text'].apply(preprocess)\n",
    "tweets_test['clean_text'] = tweets_test['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:29:01.798553700Z",
     "start_time": "2023-12-21T15:29:01.785391100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0               deed reason earthquake allah forgive  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident ask shelter place notify officer evac...  \n",
       "3    people receive wildfire evacuation order cal...  \n",
       "4  got send photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \n",
       "0                     happen terrible car crash  \n",
       "1      hear earthquake different city stay safe  \n",
       "2  forest fire spot pond goose flee street save  \n",
       "3          apocalypse lighting spokane wildfire  \n",
       "4            typhoon soudelor kill china taiwan  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-word tokenization with BERT Tokenizer for Byte-Pair Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:30:29.849421800Z",
     "start_time": "2023-12-21T15:29:11.378522300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('e', 'r'): 'er',\n",
       " ('r', 'e'): 're',\n",
       " ('i', 'n'): 'in',\n",
       " ('a', 'n'): 'an',\n",
       " ('o', 'n'): 'on',\n",
       " ('s', 't'): 'st',\n",
       " ('a', 't'): 'at',\n",
       " ('a', 'r'): 'ar',\n",
       " ('a', 'l'): 'al',\n",
       " ('o', 'r'): 'or',\n",
       " ('e', 'n'): 'en',\n",
       " ('l', 'e'): 'le',\n",
       " ('l', 'i'): 'li',\n",
       " ('d', 'e'): 'de',\n",
       " ('i', 'c'): 'ic',\n",
       " ('s', 'e'): 'se',\n",
       " ('a', 'm'): 'am',\n",
       " ('r', 'o'): 'ro',\n",
       " ('l', 'o'): 'lo',\n",
       " ('i', 'l'): 'il',\n",
       " ('a', 'c'): 'ac',\n",
       " ('i', 't'): 'it',\n",
       " ('s', 'h'): 'sh',\n",
       " ('u', 'n'): 'un',\n",
       " ('c', 'h'): 'ch',\n",
       " ('c', 'o'): 'co',\n",
       " ('u', 'r'): 'ur',\n",
       " ('v', 'e'): 've',\n",
       " ('t', 'h'): 'th',\n",
       " ('r', 'a'): 'ra',\n",
       " ('i', 'on'): 'ion',\n",
       " ('g', 'e'): 'ge',\n",
       " ('i', 's'): 'is',\n",
       " ('m', 'e'): 'me',\n",
       " ('in', 'g'): 'ing',\n",
       " ('a', 'y'): 'ay',\n",
       " ('k', 'e'): 'ke',\n",
       " ('n', 'e'): 'ne',\n",
       " ('a', 'd'): 'ad',\n",
       " ('r', 'i'): 'ri',\n",
       " ('h', 'o'): 'ho',\n",
       " ('o', 'd'): 'od',\n",
       " ('s', 's'): 'ss',\n",
       " ('at', 'e'): 'ate',\n",
       " ('en', 't'): 'ent',\n",
       " ('e', 'l'): 'el',\n",
       " ('a', 'p'): 'ap',\n",
       " ('f', 'i'): 'fi',\n",
       " ('l', 'y'): 'ly',\n",
       " ('t', 'er'): 'ter',\n",
       " ('o', 'm'): 'om',\n",
       " ('g', 'h'): 'gh',\n",
       " ('u', 't'): 'ut',\n",
       " ('s', 'u'): 'su',\n",
       " ('m', 'a'): 'ma',\n",
       " ('l', 'a'): 'la',\n",
       " ('o', 't'): 'ot',\n",
       " ('p', 'e'): 'pe',\n",
       " ('f', 'e'): 'fe',\n",
       " ('c', 'e'): 'ce',\n",
       " ('o', 'l'): 'ol',\n",
       " ('v', 'i'): 'vi',\n",
       " ('c', 'k'): 'ck',\n",
       " ('c', 't'): 'ct',\n",
       " ('d', 'i'): 'di',\n",
       " ('g', 'o'): 'go',\n",
       " ('u', 's'): 'us',\n",
       " ('p', 'o'): 'po',\n",
       " ('h', 'e'): 'he',\n",
       " ('r', 'u'): 'ru',\n",
       " ('d', 'er'): 'der',\n",
       " ('ne', 'w'): 'new',\n",
       " ('b', 'e'): 'be',\n",
       " ('s', 'i'): 'si',\n",
       " ('at', 'ion'): 'ation',\n",
       " ('m', 'o'): 'mo',\n",
       " ('an', 'd'): 'and',\n",
       " ('o', 'w'): 'ow',\n",
       " ('a', 'st'): 'ast',\n",
       " ('gh', 't'): 'ght',\n",
       " ('fi', 're'): 'fire',\n",
       " ('i', 'r'): 'ir',\n",
       " ('w', 'e'): 'we',\n",
       " ('p', 'l'): 'pl',\n",
       " ('c', 'on'): 'con',\n",
       " ('e', 'x'): 'ex',\n",
       " ('an', 't'): 'ant',\n",
       " ('in', 'e'): 'ine',\n",
       " ('ac', 'k'): 'ack',\n",
       " ('v', 'er'): 'ver',\n",
       " ('o', 'p'): 'op',\n",
       " ('a', 'b'): 'ab',\n",
       " ('u', 'l'): 'ul',\n",
       " ('s', 'p'): 'sp',\n",
       " ('am', 'p'): 'amp',\n",
       " ('e', 'm'): 'em',\n",
       " ('s', 'c'): 'sc',\n",
       " ('h', 'i'): 'hi',\n",
       " ('st', 'or'): 'stor',\n",
       " ('i', 'd'): 'id',\n",
       " ('f', 'f'): 'ff',\n",
       " ('n', 'i'): 'ni',\n",
       " ('b', 'o'): 'bo',\n",
       " ('q', 'u'): 'qu',\n",
       " ('il', 'l'): 'ill',\n",
       " ('t', 'i'): 'ti',\n",
       " ('c', 'a'): 'ca',\n",
       " ('e', 'd'): 'ed',\n",
       " ('s', 'o'): 'so',\n",
       " ('h', 'a'): 'ha',\n",
       " ('li', 'ke'): 'like',\n",
       " ('t', 'ra'): 'tra',\n",
       " ('a', 'k'): 'ak',\n",
       " ('u', 'm'): 'um',\n",
       " ('w', 'or'): 'wor',\n",
       " ('t', 'y'): 'ty',\n",
       " ('stor', 'm'): 'storm',\n",
       " ('il', 'd'): 'ild',\n",
       " ('y', 'e'): 'ye',\n",
       " ('r', 'y'): 'ry',\n",
       " ('o', 'k'): 'ok',\n",
       " ('in', 'd'): 'ind',\n",
       " ('m', 'an'): 'man',\n",
       " ('p', 'ro'): 'pro',\n",
       " ('in', 'k'): 'ink',\n",
       " ('at', 't'): 'att',\n",
       " ('un', 'd'): 'und',\n",
       " ('it', 'y'): 'ity',\n",
       " ('a', 's'): 'as',\n",
       " ('a', 'ge'): 'age',\n",
       " ('t', 'e'): 'te',\n",
       " ('c', 'al'): 'cal',\n",
       " ('f', 'o'): 'fo',\n",
       " ('d', 'is'): 'dis',\n",
       " ('om', 'b'): 'omb',\n",
       " ('a', 'g'): 'ag',\n",
       " ('co', 'l'): 'col',\n",
       " ('p', 're'): 'pre',\n",
       " ('or', 't'): 'ort',\n",
       " ('i', 'g'): 'ig',\n",
       " ('lo', 'w'): 'low',\n",
       " ('b', 'u'): 'bu',\n",
       " ('i', 'st'): 'ist',\n",
       " ('b', 'omb'): 'bomb',\n",
       " ('en', 'd'): 'end',\n",
       " ('p', 'er'): 'per',\n",
       " ('s', 'a'): 'sa',\n",
       " ('c', 'y'): 'cy',\n",
       " ('d', 'on'): 'don',\n",
       " ('ar', 'd'): 'ard',\n",
       " ('f', 'or'): 'for',\n",
       " ('new', 's'): 'news',\n",
       " ('ac', 'e'): 'ace',\n",
       " ('on', 'e'): 'one',\n",
       " ('ur', 'n'): 'urn',\n",
       " ('at', 'h'): 'ath',\n",
       " ('u', 'p'): 'up',\n",
       " ('b', 'le'): 'ble',\n",
       " ('t', 'o'): 'to',\n",
       " ('w', 'a'): 'wa',\n",
       " ('u', 'se'): 'use',\n",
       " ('co', 'm'): 'com',\n",
       " ('ar', 't'): 'art',\n",
       " ('ro', 'w'): 'row',\n",
       " ('ic', 'e'): 'ice',\n",
       " ('t', 'on'): 'ton',\n",
       " ('d', 'ay'): 'day',\n",
       " ('lo', 'od'): 'lood',\n",
       " ('al', 'l'): 'all',\n",
       " ('n', 'a'): 'na',\n",
       " ('sh', 'i'): 'shi',\n",
       " ('m', 'ent'): 'ment',\n",
       " ('o', 'ut'): 'out',\n",
       " ('u', 're'): 'ure',\n",
       " ('o', 'b'): 'ob',\n",
       " ('ac', 't'): 'act',\n",
       " ('a', 're'): 'are',\n",
       " ('u', 'e'): 'ue',\n",
       " ('c', 'i'): 'ci',\n",
       " ('c', 'ra'): 'cra',\n",
       " ('ge', 't'): 'get',\n",
       " ('el', 'l'): 'ell',\n",
       " ('s', 'on'): 'son',\n",
       " ('g', 'en'): 'gen',\n",
       " ('t', 'a'): 'ta',\n",
       " ('m', 'i'): 'mi',\n",
       " ('e', 't'): 'et',\n",
       " ('s', 'ur'): 'sur',\n",
       " ('m', 'ar'): 'mar',\n",
       " ('p', 'h'): 'ph',\n",
       " ('w', 'ar'): 'war',\n",
       " ('i', 'm'): 'im',\n",
       " ('ti', 'me'): 'time',\n",
       " ('n', 'ow'): 'now',\n",
       " ('a', 'il'): 'ail',\n",
       " ('ic', 'i'): 'ici',\n",
       " ('u', 'st'): 'ust',\n",
       " ('al', 'ly'): 'ally',\n",
       " ('w', 'at'): 'wat',\n",
       " ('b', 're'): 'bre',\n",
       " ('l', 'and'): 'land',\n",
       " ('e', 'v'): 'ev',\n",
       " ('an', 'e'): 'ane',\n",
       " ('po', 'li'): 'poli',\n",
       " ('b', 'l'): 'bl',\n",
       " ('z', 'e'): 'ze',\n",
       " ('f', 'u'): 'fu',\n",
       " ('b', 'er'): 'ber',\n",
       " ('r', 'or'): 'ror',\n",
       " ('ic', 'k'): 'ick',\n",
       " ('a', 'ir'): 'air',\n",
       " ('o', 'ff'): 'off',\n",
       " ('pe', 'op'): 'peop',\n",
       " ('peop', 'le'): 'people',\n",
       " ('b', 'r'): 'br',\n",
       " ('k', 'ill'): 'kill',\n",
       " ('re', 'd'): 'red',\n",
       " ('l', 'd'): 'ld',\n",
       " ('i', 'an'): 'ian',\n",
       " ('a', 'v'): 'av',\n",
       " ('am', 'e'): 'ame',\n",
       " ('ar', 'y'): 'ary',\n",
       " ('w', 'ay'): 'way',\n",
       " ('it', 'e'): 'ite',\n",
       " ('b', 'urn'): 'burn',\n",
       " ('c', 'ar'): 'car',\n",
       " ('u', 'd'): 'ud',\n",
       " ('ow', 'n'): 'own',\n",
       " ('g', 'er'): 'ger',\n",
       " ('d', 'o'): 'do',\n",
       " ('vi', 'de'): 'vide',\n",
       " ('p', 'ort'): 'port',\n",
       " ('m', 'on'): 'mon',\n",
       " ('g', 're'): 'gre',\n",
       " ('an', 'ce'): 'ance',\n",
       " ('f', 'am'): 'fam',\n",
       " ('p', 'an'): 'pan',\n",
       " ('co', 'me'): 'come',\n",
       " ('vide', 'o'): 'video',\n",
       " ('c', 'le'): 'cle',\n",
       " ('i', 'o'): 'io',\n",
       " ('s', 'er'): 'ser',\n",
       " ('i', 've'): 'ive',\n",
       " ('i', 'e'): 'ie',\n",
       " ('m', 'in'): 'min',\n",
       " ('ye', 'ar'): 'year',\n",
       " ('n', 'o'): 'no',\n",
       " ('ast', 'er'): 'aster',\n",
       " ('li', 't'): 'lit',\n",
       " ('li', 'ght'): 'light',\n",
       " ('le', 't'): 'let',\n",
       " ('ar', 'm'): 'arm',\n",
       " ('f', 'lood'): 'flood',\n",
       " ('b', 'od'): 'bod',\n",
       " ('w', 'o'): 'wo',\n",
       " ('ho', 'me'): 'home',\n",
       " ('p', 'ho'): 'pho',\n",
       " ('bre', 'ak'): 'break',\n",
       " ('lo', 've'): 'love',\n",
       " ('i', 'a'): 'ia',\n",
       " ('bod', 'y'): 'body',\n",
       " ('em', 'er'): 'emer',\n",
       " ('cra', 'sh'): 'crash',\n",
       " ('am', 'a'): 'ama',\n",
       " ('ter', 'ror'): 'terror',\n",
       " ('e', 'p'): 'ep',\n",
       " ('ex', 'p'): 'exp',\n",
       " ('a', 'u'): 'au',\n",
       " ('ut', 'e'): 'ute',\n",
       " ('in', 'j'): 'inj',\n",
       " ('dis', 'aster'): 'disaster',\n",
       " ('li', 'de'): 'lide',\n",
       " ('c', 'l'): 'cl',\n",
       " ('bu', 'ild'): 'build',\n",
       " ('re', 'am'): 'ream',\n",
       " ('emer', 'gen'): 'emergen',\n",
       " ('sh', 'o'): 'sho',\n",
       " ('emergen', 'cy'): 'emergency',\n",
       " ('lo', 'ok'): 'look',\n",
       " ('f', 'at'): 'fat',\n",
       " ('att', 'ack'): 'attack',\n",
       " ('wor', 'k'): 'work',\n",
       " ('re', 'n'): 'ren',\n",
       " ('de', 'st'): 'dest',\n",
       " ('a', 'f'): 'af',\n",
       " ('s', 'pe'): 'spe',\n",
       " ('t', 'ro'): 'tro',\n",
       " ('t', 'ru'): 'tru',\n",
       " ('l', 'l'): 'll',\n",
       " ('f', 'l'): 'fl',\n",
       " ('il', 'y'): 'ily',\n",
       " ('w', 'ind'): 'wind',\n",
       " ('b', 'ag'): 'bag',\n",
       " ('t', 'r'): 'tr',\n",
       " ('go', 'od'): 'good',\n",
       " ('a', 'ss'): 'ass',\n",
       " ('un', 'der'): 'under',\n",
       " ('a', 'se'): 'ase',\n",
       " ('j', 'o'): 'jo',\n",
       " ('ch', 'e'): 'che',\n",
       " ('n', 'or'): 'nor',\n",
       " ('un', 't'): 'unt',\n",
       " ('c', 're'): 'cre',\n",
       " ('li', 'fe'): 'life',\n",
       " ('c', 'at'): 'cat',\n",
       " ('wor', 'ld'): 'world',\n",
       " ('w', 're'): 'wre',\n",
       " ('ap', 'p'): 'app',\n",
       " ('k', 'now'): 'know',\n",
       " ('poli', 'ce'): 'police',\n",
       " ('fat', 'al'): 'fatal',\n",
       " ('n', 'u'): 'nu',\n",
       " ('wre', 'ck'): 'wreck',\n",
       " ('o', 'o'): 'oo',\n",
       " ('r', 'ic'): 'ric',\n",
       " ('g', 'u'): 'gu',\n",
       " ('de', 'l'): 'del',\n",
       " ('s', 'ion'): 'sion',\n",
       " ('pl', 'ay'): 'play',\n",
       " ('row', 'n'): 'rown',\n",
       " ('w', 'ild'): 'wild',\n",
       " ('i', 're'): 'ire',\n",
       " ('th', 'e'): 'the',\n",
       " ('t', 'w'): 'tw',\n",
       " ('c', 'an'): 'can',\n",
       " ('on', 'g'): 'ong',\n",
       " ('ct', 'ion'): 'ction',\n",
       " ('e', 'k'): 'ek',\n",
       " ('ac', 'c'): 'acc',\n",
       " ('exp', 'lo'): 'explo',\n",
       " ('t', 'od'): 'tod',\n",
       " ('th', 'er'): 'ther',\n",
       " ('n', 'ing'): 'ning',\n",
       " ('ev', 'ac'): 'evac',\n",
       " ('cal', 'i'): 'cali',\n",
       " ('r', 't'): 'rt',\n",
       " ('le', 'g'): 'leg',\n",
       " ('wat', 'ch'): 'watch',\n",
       " ('sur', 'vi'): 'survi',\n",
       " ('s', 'ink'): 'sink',\n",
       " ('re', 'sc'): 'resc',\n",
       " ('e', 'ar'): 'ear',\n",
       " ('evac', 'u'): 'evacu',\n",
       " ('build', 'ing'): 'building',\n",
       " ('tra', 'in'): 'train',\n",
       " ('th', 'ink'): 'think',\n",
       " ('fam', 'ily'): 'family',\n",
       " ('f', 't'): 'ft',\n",
       " ('is', 'm'): 'ism',\n",
       " ('re', 'e'): 'ree',\n",
       " ('m', 'er'): 'mer',\n",
       " ('an', 'k'): 'ank',\n",
       " ('ni', 'a'): 'nia',\n",
       " ('an', 'ge'): 'ange',\n",
       " ('ra', 'in'): 'rain',\n",
       " ('id', 'ent'): 'ident',\n",
       " ('st', 'er'): 'ster',\n",
       " ('cle', 'ar'): 'clear',\n",
       " ('re', 'st'): 'rest',\n",
       " ('cali', 'for'): 'califor',\n",
       " ('ma', 'ss'): 'mass',\n",
       " ('h', 'el'): 'hel',\n",
       " ('c', 'ur'): 'cur',\n",
       " ('j', 'e'): 'je',\n",
       " ('en', 'ce'): 'ence',\n",
       " ('col', 'l'): 'coll',\n",
       " ('ol', 'd'): 'old',\n",
       " ('d', 'it'): 'dit',\n",
       " ('califor', 'nia'): 'california',\n",
       " ('li', 've'): 'live',\n",
       " ('in', 't'): 'int',\n",
       " ('w', 'ant'): 'want',\n",
       " ('p', 'ar'): 'par',\n",
       " ('e', 'st'): 'est',\n",
       " ('j', 'ack'): 'jack',\n",
       " ('ici', 'de'): 'icide',\n",
       " ('s', 'ay'): 'say',\n",
       " ('su', 'icide'): 'suicide',\n",
       " ('o', 'us'): 'ous',\n",
       " ('vi', 'e'): 'vie',\n",
       " ('ap', 'se'): 'apse',\n",
       " ('sc', 'ream'): 'scream',\n",
       " ('r', 'un'): 'run',\n",
       " ('de', 'ath'): 'death',\n",
       " ('w', 'h'): 'wh',\n",
       " ('shi', 'ma'): 'shima',\n",
       " ('e', 'le'): 'ele',\n",
       " ('g', 'a'): 'ga',\n",
       " ('u', 'be'): 'ube',\n",
       " ('coll', 'apse'): 'collapse',\n",
       " ('li', 'ter'): 'liter',\n",
       " ('d', 'am'): 'dam',\n",
       " ('in', 'ter'): 'inter',\n",
       " ('der', 'ail'): 'derail',\n",
       " ('de', 'ad'): 'dead',\n",
       " ('ac', 'h'): 'ach',\n",
       " ('p', 'm'): 'pm',\n",
       " ('c', 'li'): 'cli',\n",
       " ('h', 'or'): 'hor',\n",
       " ('b', 'an'): 'ban',\n",
       " ('l', 't'): 'lt',\n",
       " ('f', 'ul'): 'ful',\n",
       " ('ro', 'y'): 'roy',\n",
       " ('ir', 'l'): 'irl',\n",
       " ('s', 'ol'): 'sol',\n",
       " ('c', 'r'): 'cr',\n",
       " ('b', 'la'): 'bla',\n",
       " ('l', 'ine'): 'line',\n",
       " ('ch', 'ar'): 'char',\n",
       " ('m', 'is'): 'mis',\n",
       " ('s', 'w'): 'sw',\n",
       " ('de', 'mo'): 'demo',\n",
       " ('pl', 'an'): 'plan',\n",
       " ('fe', 'el'): 'feel',\n",
       " ('s', 'ch'): 'sch',\n",
       " ('a', 'h'): 'ah',\n",
       " ('z', 'ard'): 'zard',\n",
       " ('ne', 'ar'): 'near',\n",
       " ('se', 't'): 'set',\n",
       " ('acc', 'ident'): 'accident',\n",
       " ('ur', 'y'): 'ury',\n",
       " ('re', 'ad'): 'read',\n",
       " ('me', 'm'): 'mem',\n",
       " ('a', 'ke'): 'ake',\n",
       " ('ca', 'use'): 'cause',\n",
       " ('g', 't'): 'gt',\n",
       " ('tod', 'ay'): 'today',\n",
       " ('ne', 'ed'): 'need',\n",
       " ('con', 't'): 'cont',\n",
       " ('nu', 'clear'): 'nuclear',\n",
       " ('fe', 'ct'): 'fect',\n",
       " ('he', 'ad'): 'head',\n",
       " ('th', 'under'): 'thunder',\n",
       " ('di', 'e'): 'die',\n",
       " ('ic', 'al'): 'ical',\n",
       " ('am', 'er'): 'amer',\n",
       " ('d', 'own'): 'down',\n",
       " ('w', 'om'): 'wom',\n",
       " ('m', 'p'): 'mp',\n",
       " ('n', 'ot'): 'not',\n",
       " ('b', 'us'): 'bus',\n",
       " ('m', 'ur'): 'mur',\n",
       " ('d', 'rown'): 'drown',\n",
       " ('ath', 'er'): 'ather',\n",
       " ('b', 'ig'): 'big',\n",
       " ('y', 'out'): 'yout',\n",
       " ('de', 'v'): 'dev',\n",
       " ('n', 'y'): 'ny',\n",
       " ('ri', 'ght'): 'right',\n",
       " ('al', 'k'): 'alk',\n",
       " ('fu', 'ck'): 'fuck',\n",
       " ('shi', 'p'): 'ship',\n",
       " ('dest', 'roy'): 'destroy',\n",
       " ('d', 'an'): 'dan',\n",
       " ('ke', 't'): 'ket',\n",
       " ('a', 've'): 'ave',\n",
       " ('g', 'n'): 'gn',\n",
       " ('yout', 'ube'): 'youtube',\n",
       " ('s', 'en'): 'sen',\n",
       " ('m', 'al'): 'mal',\n",
       " ('de', 'ton'): 'deton',\n",
       " ('b', 'ad'): 'bad',\n",
       " ('f', 'all'): 'fall',\n",
       " ('c', 'la'): 'cla',\n",
       " ('y', 'o'): 'yo',\n",
       " ('b', 'low'): 'blow',\n",
       " ('hi', 'ro'): 'hiro',\n",
       " ('c', 'ru'): 'cru',\n",
       " ('p', 'u'): 'pu',\n",
       " ('l', 'ate'): 'late',\n",
       " ('s', 'k'): 'sk',\n",
       " ('g', 'r'): 'gr',\n",
       " ('hiro', 'shima'): 'hiroshima',\n",
       " ('hi', 'jack'): 'hijack',\n",
       " ('i', 'sh'): 'ish',\n",
       " ('b', 'lood'): 'blood',\n",
       " ('li', 'e'): 'lie',\n",
       " ('m', 'h'): 'mh',\n",
       " ('ser', 'v'): 'serv',\n",
       " ('m', 'at'): 'mat',\n",
       " ('pl', 'ace'): 'place',\n",
       " ('st', 'e'): 'ste',\n",
       " ('d', 'r'): 'dr',\n",
       " ('b', 'ro'): 'bro',\n",
       " ('hel', 'p'): 'help',\n",
       " ('su', 'e'): 'sue',\n",
       " ('ap', 'on'): 'apon',\n",
       " ('ho', 'st'): 'host',\n",
       " ('ho', 't'): 'hot',\n",
       " ('fe', 'ar'): 'fear',\n",
       " ('an', 'ni'): 'anni',\n",
       " ('we', 'apon'): 'weapon',\n",
       " ('resc', 'ue'): 'rescue',\n",
       " ('ob', 'liter'): 'obliter',\n",
       " ('pho', 'to'): 'photo',\n",
       " ('h', 'app'): 'happ',\n",
       " ('bl', 'ack'): 'black',\n",
       " ('c', 'ent'): 'cent',\n",
       " ('se', 'e'): 'see',\n",
       " ('mur', 'der'): 'murder',\n",
       " ('b', 'c'): 'bc',\n",
       " ('d', 'u'): 'du',\n",
       " ('re', 'al'): 'real',\n",
       " ('ur', 'al'): 'ural',\n",
       " ('f', 'in'): 'fin',\n",
       " ('p', 'i'): 'pi',\n",
       " ('ele', 'ct'): 'elect',\n",
       " ('fi', 'r'): 'fir',\n",
       " ('lo', 'se'): 'lose',\n",
       " ('u', 'ge'): 'uge',\n",
       " ('inj', 'ury'): 'injury',\n",
       " ('re', 'port'): 'report',\n",
       " ('en', 'g'): 'eng',\n",
       " ('p', 'at'): 'pat',\n",
       " ('st', 're'): 'stre',\n",
       " ('qu', 'ar'): 'quar',\n",
       " ('t', 'or'): 'tor',\n",
       " ('ab', 'le'): 'able',\n",
       " ('ch', 'ange'): 'change',\n",
       " ('j', 'ap'): 'jap',\n",
       " ('ri', 'ot'): 'riot',\n",
       " ('s', 'lide'): 'slide',\n",
       " ('b', 'y'): 'by',\n",
       " ('ri', 'd'): 'rid',\n",
       " ('f', 'ind'): 'find',\n",
       " ('serv', 'ice'): 'service',\n",
       " ('sp', 'on'): 'spon',\n",
       " ('s', 'y'): 'sy',\n",
       " ('l', 'ong'): 'long',\n",
       " ('wat', 'er'): 'water',\n",
       " ('wild', 'fire'): 'wildfire',\n",
       " ('so', 'u'): 'sou',\n",
       " ('f', 'ri'): 'fri',\n",
       " ('c', 'ity'): 'city',\n",
       " ('d', 'y'): 'dy',\n",
       " ('dev', 'ast'): 'devast',\n",
       " ('d', 'ate'): 'date',\n",
       " ('ro', 'ss'): 'ross',\n",
       " ('p', 't'): 'pt',\n",
       " ('lo', 't'): 'lot',\n",
       " ('n', 'at'): 'nat',\n",
       " ('qu', 'e'): 'que',\n",
       " ('m', 'us'): 'mus',\n",
       " ('survi', 've'): 'survive',\n",
       " ('c', 'ute'): 'cute',\n",
       " ('wo', 'und'): 'wound',\n",
       " ('ca', 're'): 'care',\n",
       " ('g', 'od'): 'god',\n",
       " ('th', 'ing'): 'thing',\n",
       " ('g', 'in'): 'gin',\n",
       " ('e', 'ye'): 'eye',\n",
       " ('stor', 'y'): 'story',\n",
       " ('b', 'ab'): 'bab',\n",
       " ('lo', 'l'): 'lol',\n",
       " ('g', 'ro'): 'gro',\n",
       " ('con', 'fir'): 'confir',\n",
       " ('he', 'ar'): 'hear',\n",
       " ('sa', 've'): 'save',\n",
       " ('c', 'er'): 'cer',\n",
       " ('mis', 's'): 'miss',\n",
       " ('p', 'le'): 'ple',\n",
       " ('li', 'sh'): 'lish',\n",
       " ('explo', 'de'): 'explode',\n",
       " ('ha', 'zard'): 'hazard',\n",
       " ('wa', 've'): 'wave',\n",
       " ('b', 'ar'): 'bar',\n",
       " ('v', 'ol'): 'vol',\n",
       " ('ne', 'ss'): 'ness',\n",
       " ('evacu', 'ate'): 'evacuate',\n",
       " ('or', 'd'): 'ord',\n",
       " ('s', 'un'): 'sun',\n",
       " ('st', 'ate'): 'state',\n",
       " ('d', 'ri'): 'dri',\n",
       " ('f', 'ace'): 'face',\n",
       " ('ast', 'ro'): 'astro',\n",
       " ('wom', 'an'): 'woman',\n",
       " ('d', 'ro'): 'dro',\n",
       " ('col', 'lide'): 'collide',\n",
       " ('su', 'al'): 'sual',\n",
       " ('fatal', 'ity'): 'fatality',\n",
       " ('t', 'ry'): 'try',\n",
       " ('gre', 'at'): 'great',\n",
       " ('i', 'se'): 'ise',\n",
       " ('st', 'and'): 'stand',\n",
       " ('pl', 'ane'): 'plane',\n",
       " ('re', 'spon'): 'respon',\n",
       " ('arm', 'y'): 'army',\n",
       " ('st', 'ru'): 'stru',\n",
       " ('pan', 'ic'): 'panic',\n",
       " ('ve', 'st'): 'vest',\n",
       " ('ear', 'th'): 'earth',\n",
       " ('o', 'ol'): 'ool',\n",
       " ('m', 'y'): 'my',\n",
       " ('dam', 'age'): 'damage',\n",
       " ('st', 'op'): 'stop',\n",
       " ('ho', 'use'): 'house',\n",
       " ('or', 'y'): 'ory',\n",
       " ('si', 'gn'): 'sign',\n",
       " ('mi', 'lit'): 'milit',\n",
       " ('bomb', 'ing'): 'bombing',\n",
       " ('att', 'le'): 'attle',\n",
       " ('b', 'io'): 'bio',\n",
       " ('host', 'age'): 'hostage',\n",
       " ('ant', 'ine'): 'antine',\n",
       " ('g', 'irl'): 'girl',\n",
       " ('ni', 'ght'): 'night',\n",
       " ('th', 'ank'): 'thank',\n",
       " ('ta', 'ke'): 'take',\n",
       " ('li', 'st'): 'list',\n",
       " ('v', 'il'): 'vil',\n",
       " ('ma', 'ge'): 'mage',\n",
       " ('f', 'a'): 'fa',\n",
       " ('p', 'r'): 'pr',\n",
       " ('bo', 'y'): 'boy',\n",
       " ('quar', 'antine'): 'quarantine',\n",
       " ('fo', 'rest'): 'forest',\n",
       " ('sch', 'ool'): 'school',\n",
       " ('ad', 'o'): 'ado',\n",
       " ('s', 'al'): 'sal',\n",
       " ('le', 'ave'): 'leave',\n",
       " ('v', 'o'): 'vo',\n",
       " ('i', 'ght'): 'ight',\n",
       " ('om', 'ic'): 'omic',\n",
       " ('in', 'di'): 'indi',\n",
       " ('ther', 'n'): 'thern',\n",
       " ('cat', 'astro'): 'catastro',\n",
       " ('b', 'li'): 'bli',\n",
       " ('g', 'ra'): 'gra',\n",
       " ('a', 'in'): 'ain',\n",
       " ('f', 'ree'): 'free',\n",
       " ('hi', 'gh'): 'high',\n",
       " ('i', 'i'): 'ii',\n",
       " ('c', 'ap'): 'cap',\n",
       " ('re', 'fu'): 'refu',\n",
       " ('cru', 'sh'): 'crush',\n",
       " ('f', 'r'): 'fr',\n",
       " ('spe', 'ct'): 'spect',\n",
       " ('h', 'it'): 'hit',\n",
       " ('leg', 'ion'): 'legion',\n",
       " ('s', 'n'): 'sn',\n",
       " ('ho', 'pe'): 'hope',\n",
       " ('terror', 'ism'): 'terrorism',\n",
       " ('ca', 'sual'): 'casual',\n",
       " ('co', 'unt'): 'count',\n",
       " ('su', 'm'): 'sum',\n",
       " ('ic', 'a'): 'ica',\n",
       " ('g', 'un'): 'gun',\n",
       " ('le', 'y'): 'ley',\n",
       " ('w', 'in'): 'win',\n",
       " ('ha', 'il'): 'hail',\n",
       " ('in', 'vest'): 'invest',\n",
       " ('ci', 'al'): 'cial',\n",
       " ('l', 'ad'): 'lad',\n",
       " ('st', 'art'): 'start',\n",
       " ('ob', 'ama'): 'obama',\n",
       " ('elect', 'ro'): 'electro',\n",
       " ('s', 'mo'): 'smo',\n",
       " ('he', 'av'): 'heav',\n",
       " ('si', 'de'): 'side',\n",
       " ('d', 'a'): 'da',\n",
       " ('g', 'ame'): 'game',\n",
       " ('t', 'le'): 'tle',\n",
       " ('b', 'ul'): 'bul',\n",
       " ('h', 'il'): 'hil',\n",
       " ('po', 'st'): 'post',\n",
       " ('st', 'r'): 'str',\n",
       " ('f', 'er'): 'fer',\n",
       " ('casual', 'ty'): 'casualty',\n",
       " ('deton', 'ate'): 'detonate',\n",
       " ('n', 'er'): 'ner',\n",
       " ('k', 'id'): 'kid',\n",
       " ('b', 'ay'): 'bay',\n",
       " ('d', 'n'): 'dn',\n",
       " ('t', 'urn'): 'turn',\n",
       " ('ro', 'ad'): 'road',\n",
       " ('off', 'ici'): 'offici',\n",
       " ('lo', 'g'): 'log',\n",
       " ('gh', 'ter'): 'ghter',\n",
       " ('ar', 'ch'): 'arch',\n",
       " ('sh', 'it'): 'shit',\n",
       " ('we', 'ek'): 'week',\n",
       " ('in', 'a'): 'ina',\n",
       " ('y', 'a'): 'ya',\n",
       " ('w', 'er'): 'wer',\n",
       " ('t', 'ri'): 'tri',\n",
       " ('ot', 'e'): 'ote',\n",
       " ('nor', 'thern'): 'northern',\n",
       " ('s', 'it'): 'sit',\n",
       " ('fl', 'ame'): 'flame',\n",
       " ('h', 'ur'): 'hur',\n",
       " ('del', 'uge'): 'deluge',\n",
       " ('co', 'p'): 'cop',\n",
       " ('f', 'ol'): 'fol',\n",
       " ('ta', 'in'): 'tain',\n",
       " ('w', 'ell'): 'well',\n",
       " ('ve', 'l'): 'vel',\n",
       " ('w', 'r'): 'wr',\n",
       " ('f', 'an'): 'fan',\n",
       " ('we', 'ather'): 'weather',\n",
       " ('h', 'and'): 'hand',\n",
       " ('se', 'l'): 'sel',\n",
       " ('au', 'g'): 'aug',\n",
       " ('lo', 'ud'): 'loud',\n",
       " ('ist', 'er'): 'ister',\n",
       " ('confir', 'm'): 'confirm',\n",
       " ('legion', 'na'): 'legionna',\n",
       " ('demo', 'lish'): 'demolish',\n",
       " ('electro', 'cute'): 'electrocute',\n",
       " ('red', 'dit'): 'reddit',\n",
       " ('m', 'ay'): 'may',\n",
       " ('c', 'ross'): 'cross',\n",
       " ('le', 'ad'): 'lead',\n",
       " ('e', 'f'): 'ef',\n",
       " ('re', 'le'): 'rele',\n",
       " ('invest', 'ig'): 'investig',\n",
       " ('legionna', 'ire'): 'legionnaire',\n",
       " ('are', 'a'): 'area',\n",
       " ('rid', 'ge'): 'ridge',\n",
       " ('su', 're'): 'sure',\n",
       " ('u', 'ght'): 'ught',\n",
       " ('si', 'ren'): 'siren',\n",
       " ('s', 'm'): 'sm',\n",
       " ('p', 'ick'): 'pick',\n",
       " ('h', 'ell'): 'hell',\n",
       " ('n', 'ation'): 'nation',\n",
       " ('st', 'ar'): 'star',\n",
       " ('v', 'a'): 'va',\n",
       " ('w', 'it'): 'wit',\n",
       " ('pre', 'ss'): 'press',\n",
       " ('jap', 'an'): 'japan',\n",
       " ('co', 'ver'): 'cover',\n",
       " ('mal', 'ay'): 'malay',\n",
       " ('bomb', 'er'): 'bomber',\n",
       " ('sum', 'mer'): 'summer',\n",
       " ('v', 'al'): 'val',\n",
       " ('u', 'g'): 'ug',\n",
       " ('p', 'are'): 'pare',\n",
       " ('is', 'is'): 'isis',\n",
       " ('so', 'und'): 'sound',\n",
       " ('rele', 'ase'): 'release',\n",
       " ('at', 'omic'): 'atomic',\n",
       " ('st', 'o'): 'sto',\n",
       " ('si', 'a'): 'sia',\n",
       " ('de', 'sol'): 'desol',\n",
       " ('obliter', 'ate'): 'obliterate',\n",
       " ('f', 'la'): 'fla',\n",
       " ('fri', 'end'): 'friend',\n",
       " ('is', 'sue'): 'issue',\n",
       " ('mem', 'ber'): 'member',\n",
       " ('i', 'z'): 'iz',\n",
       " ('s', 'or'): 'sor',\n",
       " ('an', 'g'): 'ang',\n",
       " ('p', 'he'): 'phe',\n",
       " ('t', 'own'): 'town',\n",
       " ('qu', 'ake'): 'quake',\n",
       " ('co', 'un'): 'coun',\n",
       " ('fol', 'low'): 'follow',\n",
       " ('tru', 'ck'): 'truck',\n",
       " ('offici', 'al'): 'official',\n",
       " ('a', 'ut'): 'aut',\n",
       " ('t', 'om'): 'tom',\n",
       " ('al', 'low'): 'allow',\n",
       " ('inj', 'ure'): 'injure',\n",
       " ('b', 'attle'): 'battle',\n",
       " ('m', 'ad'): 'mad',\n",
       " ('at', 'or'): 'ator',\n",
       " ('ty', 'pho'): 'typho',\n",
       " ('typho', 'on'): 'typhoon',\n",
       " ('lo', 'ck'): 'lock',\n",
       " ('h', 'al'): 'hal',\n",
       " ('er', 'o'): 'ero',\n",
       " ('f', 're'): 'fre',\n",
       " ('fi', 'ght'): 'fight',\n",
       " ('fo', 'od'): 'food',\n",
       " ('f', 'un'): 'fun',\n",
       " ('ch', 'ild'): 'child',\n",
       " ('mo', 'vie'): 'movie',\n",
       " ('sp', 'ort'): 'sport',\n",
       " ('bla', 'ze'): 'blaze',\n",
       " ('h', 'ar'): 'har',\n",
       " ('m', 'or'): 'mor',\n",
       " ('cont', 'ent'): 'content',\n",
       " ('up', 'date'): 'update',\n",
       " ('ho', 'le'): 'hole',\n",
       " ('sho', 'ot'): 'shoot',\n",
       " ('il', 'li'): 'illi',\n",
       " ('re', 'at'): 'reat',\n",
       " ('b', 'it'): 'bit',\n",
       " ('me', 'd'): 'med',\n",
       " ('p', 'ri'): 'pri',\n",
       " ('b', 'all'): 'ball',\n",
       " ('ir', 'an'): 'iran',\n",
       " ('vie', 'w'): 'view',\n",
       " ('i', 'de'): 'ide',\n",
       " ('f', 'ail'): 'fail',\n",
       " ('i', 'al'): 'ial',\n",
       " ('o', 'il'): 'oil',\n",
       " ('thunder', 'storm'): 'thunderstorm',\n",
       " ('happ', 'en'): 'happen',\n",
       " ('ar', 'son'): 'arson',\n",
       " ('he', 'art'): 'heart',\n",
       " ('bo', 'ok'): 'book',\n",
       " ('ma', 'ke'): 'make',\n",
       " ('je', 'ct'): 'ject',\n",
       " ('anni', 'hil'): 'annihil',\n",
       " ('d', 'en'): 'den',\n",
       " ('o', 'f'): 'of',\n",
       " ('le', 'ss'): 'less',\n",
       " ('w', 'an'): 'wan',\n",
       " ('p', 'ic'): 'pic',\n",
       " ('as', 'on'): 'ason',\n",
       " ('ro', 'ck'): 'rock',\n",
       " ('m', 'ic'): 'mic',\n",
       " ('br', 'is'): 'bris',\n",
       " ('l', 'am'): 'lam',\n",
       " ('ri', 'st'): 'rist',\n",
       " ('ap', 'e'): 'ape',\n",
       " ('char', 'ge'): 'charge',\n",
       " ('co', 'ur'): 'cour',\n",
       " ('st', 'ri'): 'stri',\n",
       " ('che', 'ck'): 'check',\n",
       " ('j', 'ob'): 'job',\n",
       " ('ex', 't'): 'ext',\n",
       " ('p', 'ass'): 'pass',\n",
       " ('we', 'et'): 'weet',\n",
       " ('p', 'al'): 'pal',\n",
       " ('po', 'wer'): 'power',\n",
       " ('r', 'ant'): 'rant',\n",
       " ('earth', 'quake'): 'earthquake',\n",
       " ('evacu', 'ation'): 'evacuation',\n",
       " ('t', 'ur'): 'tur',\n",
       " ('s', 'and'): 'sand',\n",
       " ('lit', 'tle'): 'little',\n",
       " ('ph', 'one'): 'phone',\n",
       " ('l', 'u'): 'lu',\n",
       " ('milit', 'ary'): 'military',\n",
       " ('i', 'um'): 'ium',\n",
       " ('de', 'al'): 'deal',\n",
       " ('al', 'th'): 'alth',\n",
       " ('s', 'end'): 'send',\n",
       " ('smo', 'ke'): 'smoke',\n",
       " ('a', 'a'): 'aa',\n",
       " ('m', 'om'): 'mom',\n",
       " ('t', 'ell'): 'tell',\n",
       " ('su', 'p'): 'sup',\n",
       " ('gu', 'y'): 'guy',\n",
       " ('p', 'ra'): 'pra',\n",
       " ('an', 's'): 'ans',\n",
       " ('r', 'al'): 'ral',\n",
       " ('h', 'um'): 'hum',\n",
       " ('o', 'h'): 'oh',\n",
       " ('ine', 'ss'): 'iness',\n",
       " ('ne', 't'): 'net',\n",
       " ('com', 'm'): 'comm',\n",
       " ('se', 'arch'): 'search',\n",
       " ('ric', 'ane'): 'ricane',\n",
       " ('stru', 'ct'): 'struct',\n",
       " ('m', 'ig'): 'mig',\n",
       " ('as', 'k'): 'ask',\n",
       " ('or', 'der'): 'order',\n",
       " ('wo', 'od'): 'wood',\n",
       " ('it', 'ion'): 'ition',\n",
       " ('u', 'ble'): 'uble',\n",
       " ('ist', 'an'): 'istan',\n",
       " ('w', 's'): 'ws',\n",
       " ('ap', 'o'): 'apo',\n",
       " ('am', 'i'): 'ami',\n",
       " ('se', 'a'): 'sea',\n",
       " ('malay', 'sia'): 'malaysia',\n",
       " ('g', 'ive'): 'give',\n",
       " ('he', 'at'): 'heat',\n",
       " ('en', 'e'): 'ene',\n",
       " ('de', 'bris'): 'debris',\n",
       " ('su', 'spect'): 'suspect',\n",
       " ('vi', 'ol'): 'viol',\n",
       " ('i', 'ence'): 'ience',\n",
       " ('d', 'ra'): 'dra',\n",
       " ('ad', 'd'): 'add',\n",
       " ('ge', 'e'): 'gee',\n",
       " ('nat', 'ural'): 'natural',\n",
       " ('ver', 'e'): 'vere',\n",
       " ('mar', 'ket'): 'market',\n",
       " ('ic', 'le'): 'icle',\n",
       " ('ho', 'ur'): 'hour',\n",
       " ('dri', 've'): 'drive',\n",
       " ('b', 'al'): 'bal',\n",
       " ('go', 'ver'): 'gover',\n",
       " ('p', 'ak'): 'pak',\n",
       " ('nation', 'al'): 'national',\n",
       " ('cal', 'l'): 'call',\n",
       " ('l', 'er'): 'ler',\n",
       " ('terror', 'ist'): 'terrorist',\n",
       " ('refu', 'gee'): 'refugee',\n",
       " ('dan', 'ger'): 'danger',\n",
       " ('de', 'mon'): 'demon',\n",
       " ('mig', 'rant'): 'migrant',\n",
       " ('g', 'i'): 'gi',\n",
       " ('al', 'e'): 'ale',\n",
       " ('g', 'ue'): 'gue',\n",
       " ('un', 'ion'): 'union',\n",
       " ('v', 'or'): 'vor',\n",
       " ('y', 'r'): 'yr',\n",
       " ('bab', 'y'): 'baby',\n",
       " ('b', 'ridge'): 'bridge',\n",
       " ('op', 'en'): 'open',\n",
       " ('b', 'a'): 'ba',\n",
       " ('k', 'er'): 'ker',\n",
       " ('m', 'id'): 'mid',\n",
       " ('explo', 'sion'): 'explosion',\n",
       " ('tra', 'p'): 'trap',\n",
       " ('w', 'w'): 'ww',\n",
       " ('go', 'v'): 'gov',\n",
       " ('u', 'ma'): 'uma',\n",
       " ('p', 'ul'): 'pul',\n",
       " ('t', 'ot'): 'tot',\n",
       " ('ver', 's'): 'vers',\n",
       " ('light', 'ning'): 'lightning',\n",
       " ('hur', 'ricane'): 'hurricane',\n",
       " ('se', 'vere'): 'severe',\n",
       " ('sou', 'th'): 'south',\n",
       " ('wa', 'it'): 'wait',\n",
       " ('e', 'li'): 'eli',\n",
       " ('v', 'is'): 'vis',\n",
       " ('t', 'alk'): 'talk',\n",
       " ('ss', 'i'): 'ssi',\n",
       " ('me', 'di'): 'medi',\n",
       " ('g', 'an'): 'gan',\n",
       " ('blood', 'y'): 'bloody',\n",
       " ('sh', 'ow'): 'show',\n",
       " ('is', 'ra'): 'isra',\n",
       " ('s', 'now'): 'snow',\n",
       " ('bl', 'ue'): 'blue',\n",
       " ('sa', 'u'): 'sau',\n",
       " ('c', 'amp'): 'camp',\n",
       " ('wor', 'd'): 'word',\n",
       " ('ac', 're'): 'acre',\n",
       " ('sp', 'ill'): 'spill',\n",
       " ('devast', 'ate'): 'devastate',\n",
       " ('h', 'ard'): 'hard',\n",
       " ('te', 'st'): 'test',\n",
       " ('l', 'ar'): 'lar',\n",
       " ('per', 'son'): 'person',\n",
       " ('p', 'a'): 'pa',\n",
       " ('wh', 'ite'): 'white',\n",
       " ('l', 'ink'): 'link',\n",
       " ('un', 'g'): 'ung',\n",
       " ('ho', 'l'): 'hol',\n",
       " ('ru', 'in'): 'ruin',\n",
       " ('g', 'ot'): 'got',\n",
       " ('li', 'p'): 'lip',\n",
       " ('ton', 'ight'): 'tonight',\n",
       " ('mo', 've'): 'move',\n",
       " ('ex', 'per'): 'exper',\n",
       " ('is', 'land'): 'island',\n",
       " ('s', 'day'): 'sday',\n",
       " ('b', 'ra'): 'bra',\n",
       " ('ch', 'er'): 'cher',\n",
       " ('survi', 'vor'): 'survivor',\n",
       " ('ch', 'rist'): 'christ',\n",
       " ('a', 'way'): 'away',\n",
       " ('so', 'on'): 'soon',\n",
       " ('mo', 's'): 'mos',\n",
       " ('bus', 'iness'): 'business',\n",
       " ('li', 'm'): 'lim',\n",
       " ('ban', 'g'): 'bang',\n",
       " ('in', 'und'): 'inund',\n",
       " ('c', 'lose'): 'close',\n",
       " ('tor', 'n'): 'torn',\n",
       " ('torn', 'ado'): 'tornado',\n",
       " ('ha', 'ha'): 'haha',\n",
       " ('p', 'ast'): 'past',\n",
       " ('de', 'p'): 'dep',\n",
       " ('hal', 'f'): 'half',\n",
       " ('v', 'ic'): 'vic',\n",
       " ('min', 'ute'): 'minute',\n",
       " ('it', 'al'): 'ital',\n",
       " ('el', 'y'): 'ely',\n",
       " ('y', 'p'): 'yp',\n",
       " ('ma', 'g'): 'mag',\n",
       " ('la', 'b'): 'lab',\n",
       " ('si', 've'): 'sive',\n",
       " ('k', 'o'): 'ko',\n",
       " ('dro', 'ught'): 'drought',\n",
       " ('fail', 'ure'): 'failure',\n",
       " ('ch', 'ina'): 'china',\n",
       " ('co', 'st'): 'cost',\n",
       " ('act', 'or'): 'actor',\n",
       " ('d', 'ust'): 'dust',\n",
       " ('d', 'ent'): 'dent',\n",
       " ('s', 'ite'): 'site',\n",
       " ('we', 'st'): 'west',\n",
       " ('s', 'an'): 'san',\n",
       " ('te', 'am'): 'team',\n",
       " ('at', 'er'): 'ater',\n",
       " ('di', 'o'): 'dio',\n",
       " ('ri', 'ble'): 'rible',\n",
       " ('wa', 'ke'): 'wake',\n",
       " ('am', 'bul'): 'ambul',\n",
       " ('ambul', 'ance'): 'ambulance',\n",
       " ('w', 'alk'): 'walk',\n",
       " ...}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the hyperparameter of vocabulary size\n",
    "vocab_size = 3000\n",
    "corpus = tweets_train['clean_text'].tolist()\n",
    "\n",
    "# create a BPE tokenizer object\n",
    "MyBPE = BPE(corpus=corpus, vocab_size=vocab_size)\n",
    "\n",
    "# train BPE tokenizer with Wikipedia corpus\n",
    "MyBPE.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:13.493640100Z",
     "start_time": "2023-12-21T15:32:21.919839300Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_train['tokenized_text'] = tweets_train['clean_text'].apply(lambda x: MyBPE.tokenize(x))\n",
    "tweets_test['tokenized_text'] = tweets_test['clean_text'].apply(lambda x: MyBPE.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:19.085082400Z",
     "start_time": "2023-12-21T15:33:19.045672800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[de, ed, reason, earthquake, allah, for, give]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ron, ge, s, ask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shel, ter, place, not, ify, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[people, re, ce, ive, wildfire, evacuation, or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ru, by, alaska, smoke, wild...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0     [de, ed, reason, earthquake, allah, for, give]  \n",
       "1  [forest, fire, near, la, ron, ge, s, ask, canada]  \n",
       "2  [resident, ask, shel, ter, place, not, ify, of...  \n",
       "3  [people, re, ce, ive, wildfire, evacuation, or...  \n",
       "4  [got, send, photo, ru, by, alaska, smoke, wild...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, ter, rible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, p, ond, go, ose, fle, e, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, light, ing, spo, k, ane, wildfire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0                   [happen, ter, rible, car, crash]  \n",
       "1    [hear, earthquake, different, city, stay, safe]  \n",
       "2  [forest, fire, spot, p, ond, go, ose, fle, e, ...  \n",
       "3    [apocalypse, light, ing, spo, k, ane, wildfire]  \n",
       "4           [typhoon, soudelor, kill, china, taiwan]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text into Input Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:23.476189500Z",
     "start_time": "2023-12-21T15:33:21.430017200Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(tweets_train['tokenized_text'].apply(lambda tokens: ' '.join(tokens)))\n",
    "# Add a new column 'TFIDF' to the original DataFrame with the TF-IDF arrays\n",
    "tweets_train['TFIDF'] = X_train.toarray().tolist()\n",
    "\n",
    "X_test = vectorizer.transform(tweets_test['tokenized_text'].apply(lambda tokens: ' '.join(tokens)))\n",
    "# Add a new column 'TFIDF' to the original DataFrame with the TF-IDF arrays\n",
    "tweets_test['TFIDF'] = X_test.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:23.661826500Z",
     "start_time": "2023-12-21T15:33:23.626279500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[de, ed, reason, earthquake, allah, for, give]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ron, ge, s, ask, canada]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shel, ter, place, not, ify, of...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[people, re, ce, ive, wildfire, evacuation, or...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ru, by, alaska, smoke, wild...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0     [de, ed, reason, earthquake, allah, for, give]   \n",
       "1  [forest, fire, near, la, ron, ge, s, ask, canada]   \n",
       "2  [resident, ask, shel, ter, place, not, ify, of...   \n",
       "3  [people, re, ce, ive, wildfire, evacuation, or...   \n",
       "4  [got, send, photo, ru, by, alaska, smoke, wild...   \n",
       "\n",
       "                                               TFIDF  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, ter, rible, car, crash]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, p, ond, go, ose, fle, e, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, light, ing, spo, k, ane, wildfire]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0                   [happen, ter, rible, car, crash]   \n",
       "1    [hear, earthquake, different, city, stay, safe]   \n",
       "2  [forest, fire, spot, p, ond, go, ose, fle, e, ...   \n",
       "3    [apocalypse, light, ing, spo, k, ane, wildfire]   \n",
       "4           [typhoon, soudelor, kill, china, taiwan]   \n",
       "\n",
       "                                               TFIDF  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec (CBOW and Skip-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:26.004312100Z",
     "start_time": "2023-12-21T15:33:25.980689800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of tokenized text in training data: 42\n",
      "Maximum length of tokenized text in testing data: 50\n"
     ]
    }
   ],
   "source": [
    "print('Maximum length of tokenized text in training data:', max([len(sent) for sent in tweets_train['tokenized_text']]))\n",
    "print('Maximum length of tokenized text in testing data:', max([len(sent) for sent in tweets_test['tokenized_text']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:07.773767Z",
     "start_time": "2023-12-21T15:33:29.941367700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "cbow_model = Word2Vec(sentences = tweets_train['tokenized_text'], vector_size = 512, window = 10, min_count = 1, workers = 4, sg = 0, epochs = 128)\n",
    "# Add the <pad> token to the cbow_model so that the last token is the <pad> token\n",
    "cbow_model.wv.key_to_index['<pad>'] = len(cbow_model.wv)\n",
    "# Add the embedding of <pad> token to the cbow_model\n",
    "cbow_model.wv.vectors = np.append(cbow_model.wv.vectors, np.zeros((1, 512)), axis=0)\n",
    "\n",
    "\n",
    "skipgram_model = Word2Vec(sentences = tweets_train['tokenized_text'], vector_size = 512, window = 10, min_count = 1, workers = 4, sg = 1, epochs = 128)\n",
    "# Add the <pad> token to the skipgram_model so that the last token is the <pad> token\n",
    "skipgram_model.wv.key_to_index['<pad>'] = len(skipgram_model.wv)\n",
    "# Add the embedding of <pad> token to the skipgram_model\n",
    "skipgram_model.wv.vectors = np.append(skipgram_model.wv.vectors, np.zeros((1, 512)), axis=0)\n",
    "\n",
    "# Add the <pad> token to all the tokenized text until the length of each tokenized text is 50\n",
    "tweets_train['tokenized_text'] = tweets_train['tokenized_text'].apply(lambda tokens: tokens + ['<pad>'] * (50 - len(tokens)))\n",
    "tweets_test['tokenized_text'] = tweets_test['tokenized_text'].apply(lambda tokens: tokens + ['<pad>'] * (50 - len(tokens)))\n",
    "\n",
    "# Apply the string2embedding_idx function to create a new column\n",
    "tweets_train['CBOW_sequences'] = tweets_train['tokenized_text'].apply(lambda tokens: string2embedding_idx(tokens, cbow_model))\n",
    "tweets_train['SkipGram_sequences'] = tweets_train['tokenized_text'].apply(lambda tokens: string2embedding_idx(tokens, skipgram_model))\n",
    "tweets_test['CBOW_sequences'] = tweets_test['tokenized_text'].apply(lambda tokens: string2embedding_idx(tokens, cbow_model))\n",
    "tweets_test['SkipGram_sequences'] = tweets_test['tokenized_text'].apply(lambda tokens: string2embedding_idx(tokens, skipgram_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:36.442786700Z",
     "start_time": "2023-12-21T15:34:36.381065300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>TFIDF</th>\n",
       "      <th>CBOW_sequences</th>\n",
       "      <th>SkipGram_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[de, ed, reason, earthquake, allah, for, give,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[31, 62, 850, 432, 2265, 425, 452, 2899, 2899,...</td>\n",
       "      <td>[31, 62, 850, 432, 2265, 425, 452, 2899, 2899,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ron, ge, s, ask, cana...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[306, 16, 398, 75, 676, 128, 0, 616, 1619, 289...</td>\n",
       "      <td>[306, 16, 398, 75, 676, 128, 0, 616, 1619, 289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shel, ter, place, not, ify, of...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1717, 616, 1709, 106, 664, 224, 2482, 671, 43...</td>\n",
       "      <td>[1717, 616, 1709, 106, 664, 224, 2482, 671, 43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[people, re, ce, ive, wildfire, evacuation, or...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[55, 7, 115, 351, 236, 439, 451, 135, 2899, 28...</td>\n",
       "      <td>[55, 7, 115, 351, 236, 439, 451, 135, 2899, 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ru, by, alaska, smoke, wild...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[545, 445, 266, 420, 652, 2464, 446, 236, 180,...</td>\n",
       "      <td>[545, 445, 266, 420, 652, 2464, 446, 236, 180,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [de, ed, reason, earthquake, allah, for, give,...   \n",
       "1  [forest, fire, near, la, ron, ge, s, ask, cana...   \n",
       "2  [resident, ask, shel, ter, place, not, ify, of...   \n",
       "3  [people, re, ce, ive, wildfire, evacuation, or...   \n",
       "4  [got, send, photo, ru, by, alaska, smoke, wild...   \n",
       "\n",
       "                                               TFIDF  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      CBOW_sequences  \\\n",
       "0  [31, 62, 850, 432, 2265, 425, 452, 2899, 2899,...   \n",
       "1  [306, 16, 398, 75, 676, 128, 0, 616, 1619, 289...   \n",
       "2  [1717, 616, 1709, 106, 664, 224, 2482, 671, 43...   \n",
       "3  [55, 7, 115, 351, 236, 439, 451, 135, 2899, 28...   \n",
       "4  [545, 445, 266, 420, 652, 2464, 446, 236, 180,...   \n",
       "\n",
       "                                  SkipGram_sequences  \n",
       "0  [31, 62, 850, 432, 2265, 425, 452, 2899, 2899,...  \n",
       "1  [306, 16, 398, 75, 676, 128, 0, 616, 1619, 289...  \n",
       "2  [1717, 616, 1709, 106, 664, 224, 2482, 671, 43...  \n",
       "3  [55, 7, 115, 351, 236, 439, 451, 135, 2899, 28...  \n",
       "4  [545, 445, 266, 420, 652, 2464, 446, 236, 180,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>TFIDF</th>\n",
       "      <th>CBOW_sequences</th>\n",
       "      <th>SkipGram_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, ter, rible, car, crash, &lt;pad&gt;, &lt;pad&gt;,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[416, 106, 2577, 74, 76, 2899, 2899, 2899, 289...</td>\n",
       "      <td>[416, 106, 2577, 74, 76, 2899, 2899, 2899, 289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[257, 432, 1651, 235, 747, 1189, 2899, 2899, 2...</td>\n",
       "      <td>[257, 432, 1651, 235, 747, 1189, 2899, 2899, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, p, ond, go, ose, fle, e, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[306, 16, 962, 12, 1500, 29, 2831, 1162, 8, 76...</td>\n",
       "      <td>[306, 16, 962, 12, 1500, 29, 2831, 1162, 8, 76...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, light, ing, spo, k, ane, wildfire...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[720, 294, 19, 1455, 21, 748, 236, 2899, 2899,...</td>\n",
       "      <td>[720, 294, 19, 1455, 21, 748, 236, 2899, 2899,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan, &lt;pad&gt;...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[385, 986, 63, 569, 1776, 2899, 2899, 2899, 28...</td>\n",
       "      <td>[385, 986, 63, 569, 1776, 2899, 2899, 2899, 28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [happen, ter, rible, car, crash, <pad>, <pad>,...   \n",
       "1  [hear, earthquake, different, city, stay, safe...   \n",
       "2  [forest, fire, spot, p, ond, go, ose, fle, e, ...   \n",
       "3  [apocalypse, light, ing, spo, k, ane, wildfire...   \n",
       "4  [typhoon, soudelor, kill, china, taiwan, <pad>...   \n",
       "\n",
       "                                               TFIDF  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      CBOW_sequences  \\\n",
       "0  [416, 106, 2577, 74, 76, 2899, 2899, 2899, 289...   \n",
       "1  [257, 432, 1651, 235, 747, 1189, 2899, 2899, 2...   \n",
       "2  [306, 16, 962, 12, 1500, 29, 2831, 1162, 8, 76...   \n",
       "3  [720, 294, 19, 1455, 21, 748, 236, 2899, 2899,...   \n",
       "4  [385, 986, 63, 569, 1776, 2899, 2899, 2899, 28...   \n",
       "\n",
       "                                  SkipGram_sequences  \n",
       "0  [416, 106, 2577, 74, 76, 2899, 2899, 2899, 289...  \n",
       "1  [257, 432, 1651, 235, 747, 1189, 2899, 2899, 2...  \n",
       "2  [306, 16, 962, 12, 1500, 29, 2831, 1162, 8, 76...  \n",
       "3  [720, 294, 19, 1455, 21, 748, 236, 2899, 2899,...  \n",
       "4  [385, 986, 63, 569, 1776, 2899, 2899, 2899, 28...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:38.609225400Z",
     "start_time": "2023-12-21T15:34:37.441115300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(cbow_model, 'earthquake', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:39.868591200Z",
     "start_time": "2023-12-21T15:34:39.426708900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(skipgram_model, 'earthquake', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:40.997210400Z",
     "start_time": "2023-12-21T15:34:40.562299400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(cbow_model, 'disaster', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:42.087371100Z",
     "start_time": "2023-12-21T15:34:41.642630900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(skipgram_model, 'disaster', 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Testing our Pre-Trained Embeddings to the PyTorch's Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:46.149953400Z",
     "start_time": "2023-12-21T15:34:46.078377300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0414, -0.2207,  0.1861,  ..., -0.0308,  0.0837, -0.0848],\n",
       "        [-0.1327, -0.1782, -0.0074,  ...,  0.0659, -0.1683, -0.1863],\n",
       "        [ 0.0210, -0.1433, -0.0212,  ..., -0.0600,  0.1392,  0.0743],\n",
       "        ...,\n",
       "        [ 0.0688, -0.0325, -0.1077,  ..., -0.2518,  0.0036,  0.0337],\n",
       "        [ 0.0180,  0.1512, -0.3123,  ..., -0.0415, -0.1330, -0.2043],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding layer with pre-trained weights\n",
    "pretrained_embeddings_layer = torch.nn.Embedding.from_pretrained(torch.FloatTensor(skipgram_model.wv.vectors))\n",
    "# check weights of the pre-trained embedding layer\n",
    "pretrained_embeddings_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:46.893954100Z",
     "start_time": "2023-12-21T15:34:46.867690500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  31,   62,  850,  432, 2265,  425,  452, 2899, 2899, 2899, 2899, 2899,\n",
       "         2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899,\n",
       "         2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899,\n",
       "         2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899, 2899,\n",
       "         2899, 2899]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainTweetsDataset = TweetsDataset(tweets_train, 'skipgram')\n",
    "TrainTweetsDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:48.356003700Z",
     "start_time": "2023-12-21T15:34:48.329539400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding of the first token:          tensor([-1.4938e-01, -3.1296e-02,  3.5110e-01,  9.9947e-02,  1.1420e-01,\n",
      "         2.0422e-02, -1.8522e-02, -9.7531e-02,  8.9191e-03,  1.6854e-01,\n",
      "         1.4188e-01, -3.8786e-01,  3.7037e-01, -1.0994e-02,  3.5970e-02,\n",
      "         1.0243e-01, -1.0458e-01, -2.9599e-01, -1.3571e-01, -2.1489e-01,\n",
      "         3.6393e-01,  1.3028e-01,  1.0361e-01,  1.7510e-01, -1.2119e-01,\n",
      "         3.7894e-01,  3.5232e-01,  2.6074e-01, -2.3349e-01, -1.9111e-01,\n",
      "        -1.9019e-01, -5.3251e-01, -1.2993e-02, -2.1414e-01, -5.5963e-01,\n",
      "         3.5878e-01, -1.2355e-01,  3.8747e-02, -1.0498e-01, -3.6733e-01,\n",
      "        -8.4645e-02, -2.3541e-02, -1.6330e-01, -2.3572e-01, -1.8326e-01,\n",
      "         3.1835e-01, -3.4187e-01,  1.6383e-02, -8.2616e-02,  6.3884e-02,\n",
      "         1.0574e-01, -2.6724e-01,  1.8972e-01, -1.2723e-01, -6.1233e-01,\n",
      "        -3.4776e-01,  1.3238e-01, -1.5830e-01,  1.0282e-01,  7.7371e-02,\n",
      "         5.6541e-02,  9.2524e-02,  9.5260e-03,  1.2026e-01,  3.5963e-01,\n",
      "        -2.8712e-01, -2.5086e-01, -1.4826e-01, -3.3845e-01,  1.3815e-01,\n",
      "        -3.6809e-02, -3.3425e-01,  4.1127e-01, -9.8882e-02, -8.7649e-02,\n",
      "        -8.1528e-02,  3.9075e-01, -2.1044e-01,  6.4219e-02, -2.4260e-01,\n",
      "         3.7783e-01, -1.4480e-01, -1.6414e-01,  2.9125e-01,  6.0159e-01,\n",
      "         1.8232e-01,  1.0176e-01,  2.7637e-01, -1.3078e-01, -2.1186e-01,\n",
      "        -1.2132e-01, -1.6654e-01,  1.8668e-01, -2.7826e-01,  1.6249e-01,\n",
      "        -2.1778e-02, -2.0270e-01, -6.2232e-02, -7.8887e-02,  8.4415e-02,\n",
      "         4.2998e-02,  2.7019e-01,  2.2601e-01,  6.1325e-03, -3.6618e-01,\n",
      "         2.9395e-01, -6.7286e-02, -4.1485e-02,  2.1893e-01,  1.3264e-01,\n",
      "         2.8493e-01,  6.5764e-02,  2.1796e-01,  1.5846e-01, -3.0511e-01,\n",
      "        -2.9373e-01,  2.2315e-01,  5.1866e-01, -4.5615e-02,  8.4788e-02,\n",
      "         2.9112e-01, -1.2745e-01, -1.5822e-01, -5.3240e-02, -8.2165e-02,\n",
      "        -1.2605e-01, -1.6368e-01,  1.0769e-01,  5.2879e-02, -3.1908e-02,\n",
      "        -5.7338e-02, -3.3273e-02,  7.3118e-02, -4.7948e-02, -7.2328e-01,\n",
      "         7.5506e-02,  3.8213e-02, -6.9876e-02, -2.0806e-01,  6.8854e-02,\n",
      "         1.0282e-01,  1.2366e-01,  1.3301e-01, -2.9977e-03,  1.7055e-01,\n",
      "        -6.2026e-03, -6.2386e-02,  1.5141e-01,  1.0102e-01,  7.2004e-02,\n",
      "        -4.0349e-01, -1.1021e-01,  1.0861e-02, -5.0354e-02,  2.4700e-02,\n",
      "         4.3094e-02,  3.2549e-02,  6.7351e-02,  2.0730e-01, -1.9856e-01,\n",
      "         3.2761e-01,  1.8744e-01, -6.1574e-02, -8.3232e-02, -3.4517e-01,\n",
      "        -1.8688e-01,  9.0331e-03, -7.9660e-03,  1.7347e-02, -9.6276e-02,\n",
      "        -1.9646e-01,  1.3433e-01,  3.8911e-01, -2.2080e-01,  7.8734e-02,\n",
      "         1.0607e-01, -2.7656e-01,  1.7901e-01, -7.6217e-02, -1.3893e-01,\n",
      "        -6.1940e-02, -3.6257e-01,  1.5312e-01,  9.0823e-02,  2.2228e-01,\n",
      "        -1.6190e-01,  2.2718e-01,  2.0780e-01, -4.5108e-01,  9.0286e-02,\n",
      "        -2.3823e-01, -1.7832e-01,  1.9384e-01, -1.7579e-01,  6.1225e-02,\n",
      "        -3.9872e-01, -1.1017e-02,  1.6194e-01,  2.5014e-01,  3.3017e-02,\n",
      "        -2.5139e-01, -1.1674e-02,  4.0910e-02,  1.7952e-02,  2.2927e-01,\n",
      "        -3.7408e-02, -1.0108e-01, -5.1278e-02,  2.1432e-01, -1.9529e-01,\n",
      "         2.7885e-02, -5.3453e-02, -1.4590e-01,  1.5451e-01, -1.1288e-01,\n",
      "         3.0754e-01, -3.9300e-02, -1.0786e-01, -2.8645e-01, -1.3539e-01,\n",
      "        -3.8744e-01,  4.0178e-01, -4.2825e-01,  2.3477e-01,  7.1663e-02,\n",
      "         1.7043e-01, -2.0564e-01, -2.9674e-01, -5.4026e-01,  1.5947e-01,\n",
      "        -2.1822e-01, -3.1207e-01, -2.1008e-01,  9.0022e-02, -1.8694e-01,\n",
      "        -7.0026e-02, -2.7581e-01,  4.9436e-01,  1.7534e-01, -2.3716e-01,\n",
      "         1.9908e-01,  3.6431e-01, -3.2391e-01,  3.1824e-01,  1.5240e-01,\n",
      "        -1.2977e-01,  1.2886e-01, -1.3103e-01,  1.8407e-01,  2.7276e-01,\n",
      "         1.0111e-01,  1.9790e-01, -5.5061e-02, -1.3460e-01, -1.5386e-03,\n",
      "        -3.2080e-01,  2.1865e-01, -2.8729e-01,  3.4416e-01,  1.8412e-01,\n",
      "         2.9975e-01, -4.5771e-01,  2.3934e-02,  2.3178e-01, -1.1781e-01,\n",
      "         2.0725e-02, -8.3714e-02, -1.1421e-01,  1.3247e-01,  2.1681e-01,\n",
      "         2.2396e-03, -1.4151e-01, -1.3355e-01, -1.6825e-02,  1.1929e-01,\n",
      "         1.0885e-02,  2.1270e-01,  1.2813e-02,  9.0017e-03, -8.0061e-02,\n",
      "        -3.4195e-01, -1.4193e-01, -6.9566e-02, -1.3940e-01,  4.7102e-02,\n",
      "        -3.3243e-01, -1.6108e-01,  1.9199e-01,  2.0945e-01,  6.3422e-02,\n",
      "        -2.5388e-01, -1.5377e-01,  1.5363e-01,  9.1202e-02,  1.9482e-01,\n",
      "        -2.2134e-02,  2.0642e-02,  1.3660e-01,  1.5831e-01,  2.7201e-01,\n",
      "         1.5113e-01, -2.1534e-01,  1.5104e-01, -1.9447e-01, -3.8671e-02,\n",
      "         1.2863e-01,  3.8894e-01, -3.0663e-01,  3.4997e-03, -2.4696e-01,\n",
      "         1.6489e-01, -5.0271e-02, -1.3777e-01,  1.3313e-03, -3.5079e-02,\n",
      "        -3.3185e-02,  3.9468e-01,  3.3555e-01,  8.3669e-02,  2.2442e-02,\n",
      "        -1.6097e-02, -2.0364e-02, -8.5905e-02, -1.1851e-01, -1.9832e-01,\n",
      "        -1.3056e-01, -3.2335e-01,  1.0533e-01,  1.8556e-01,  3.5459e-01,\n",
      "         9.8883e-02,  2.0015e-01,  2.2374e-02,  2.7042e-01, -6.0394e-02,\n",
      "         6.1940e-02, -3.1046e-01,  2.1551e-01,  6.5469e-02, -3.9828e-02,\n",
      "         1.1796e-01,  2.4973e-01,  2.1500e-01,  2.5182e-01, -1.6423e-01,\n",
      "         9.5177e-02, -2.5619e-01,  1.6241e-01, -1.1326e-01, -2.5397e-01,\n",
      "        -2.0382e-02,  9.6211e-02,  6.2043e-02,  1.1046e-01, -8.9559e-02,\n",
      "        -7.9322e-02, -1.1300e-01, -1.0993e-01,  5.2230e-02,  5.2430e-03,\n",
      "         1.7895e-01,  8.1396e-02,  4.2060e-02, -1.8230e-01,  7.3701e-02,\n",
      "         2.7178e-02,  6.9475e-02,  1.2865e-01,  2.4194e-03, -2.1046e-01,\n",
      "         2.7800e-01, -8.9638e-02,  1.9722e-01, -1.2977e-01,  1.4461e-01,\n",
      "        -1.2481e-02,  4.6242e-02, -3.7339e-01, -1.2985e-01,  8.6343e-03,\n",
      "         7.6454e-03,  7.0375e-02, -7.2766e-03,  2.0593e-01,  2.6069e-01,\n",
      "         3.5602e-02,  2.3470e-01,  2.3289e-02, -2.0165e-01, -1.7297e-01,\n",
      "         2.8436e-01, -2.1982e-01, -3.5815e-01, -2.6043e-01,  7.9645e-02,\n",
      "         2.7704e-01,  1.1675e-01,  2.5548e-02,  2.3687e-01,  8.3862e-03,\n",
      "         1.0212e-01,  1.5970e-01,  2.2002e-01,  1.4075e-01, -9.1651e-03,\n",
      "        -1.4550e-01,  1.9534e-02,  4.5452e-01,  2.8241e-01,  5.7226e-04,\n",
      "         2.5351e-02,  3.3986e-02, -5.6147e-02, -1.0841e-01,  5.3836e-02,\n",
      "        -2.1714e-02,  3.4743e-02,  9.3370e-02, -2.3784e-01,  1.3944e-01,\n",
      "        -1.6790e-02, -2.8993e-02, -9.4678e-02, -1.4470e-02, -8.0858e-02,\n",
      "        -9.4249e-02, -8.9205e-03, -1.0371e-01, -2.3182e-01,  3.7514e-01,\n",
      "        -1.0529e-01,  6.7872e-02, -8.1599e-02,  3.9021e-01, -4.2403e-02,\n",
      "        -5.0603e-02, -1.5566e-01,  7.4290e-02,  1.4869e-01, -5.6471e-02,\n",
      "         5.1319e-02, -9.4485e-02,  3.4140e-01, -1.3724e-01,  1.7600e-01,\n",
      "         5.8796e-02,  3.3211e-01, -3.3677e-01, -3.5137e-02, -2.5195e-01,\n",
      "         4.2218e-02,  1.3235e-01, -1.0755e-01, -1.0084e-01,  1.1447e-01,\n",
      "         6.3972e-02, -5.4067e-02,  2.3108e-03, -4.7165e-01, -2.7199e-02,\n",
      "         8.7020e-02, -1.2397e-01,  6.8994e-02, -4.3992e-01,  1.8229e-01,\n",
      "         1.2594e-01,  1.6862e-01, -1.1887e-01,  1.4067e-01, -2.2909e-02,\n",
      "        -1.5881e-02,  2.7067e-01,  3.3824e-01,  2.9382e-02,  1.5960e-01,\n",
      "        -4.7540e-02,  2.3876e-01, -2.3306e-01, -6.0082e-02, -2.2842e-01,\n",
      "        -2.8671e-01,  1.2445e-01,  2.4177e-01,  4.6290e-01,  2.9967e-01,\n",
      "        -1.4047e-01, -5.8100e-02,  3.1083e-01,  2.5319e-01,  1.3565e-01,\n",
      "        -2.6065e-02,  2.2511e-01,  2.3907e-01,  5.9310e-03,  3.1639e-01,\n",
      "         2.0174e-02,  2.6743e-01,  7.9292e-02,  1.3851e-01,  1.4559e-01,\n",
      "        -2.4546e-02, -1.3551e-01,  1.6009e-01,  1.3492e-01, -1.5320e-02,\n",
      "        -2.0741e-01, -3.0166e-01,  1.2081e-01, -1.4831e-01,  1.1931e-01,\n",
      "        -1.8042e-01, -2.2119e-02])\n",
      "Embedding of the second token:         tensor([-0.2387,  0.0125,  0.1017, -0.0507,  0.0200, -0.0046,  0.2088, -0.4196,\n",
      "        -0.0053,  0.0840, -0.0796,  0.1315, -0.0216, -0.0056,  0.0693, -0.4574,\n",
      "        -0.0811,  0.2731,  0.0256, -0.1548,  0.1875,  0.0184,  0.1293, -0.2168,\n",
      "         0.3997,  0.4202,  0.2672, -0.5578,  0.2739,  0.1577,  0.0051, -0.1364,\n",
      "        -0.1034, -0.2638, -0.3387, -0.1895,  0.3461,  0.0161,  0.1212,  0.0409,\n",
      "        -0.0801, -0.1260,  0.2670,  0.3736,  0.4506,  0.5567, -0.1994, -0.2011,\n",
      "         0.1232, -0.4284, -0.2362,  0.1993, -0.2278,  0.1679, -0.1428, -0.4707,\n",
      "        -0.1802, -0.3385,  0.4883, -0.0404,  0.0447,  0.4392, -0.4305,  0.3950,\n",
      "         0.0775, -0.0547,  0.1516,  0.2615, -0.5640,  0.0243, -0.0037, -0.4477,\n",
      "        -0.0679, -0.3492,  0.1552,  0.4348, -0.4834, -0.2764, -0.0954,  0.0066,\n",
      "        -0.2281,  0.4456, -0.0242, -0.4600, -0.5001, -0.1338,  0.0638,  0.3523,\n",
      "        -0.7075,  0.2278,  0.2236, -0.1004, -0.2831, -0.2124, -0.6346, -0.2414,\n",
      "        -0.2127, -0.0198,  0.3798, -0.0261, -0.0084, -0.2440, -0.1083, -0.0804,\n",
      "         0.1259, -0.1012, -0.2193, -0.1050,  0.1717, -0.0672,  0.2667,  0.2059,\n",
      "        -0.0250,  0.2968, -0.4036, -0.3186, -0.1400, -0.0156,  0.4192,  0.0472,\n",
      "         0.0840, -0.1913,  0.4401,  0.4091,  0.2777,  0.0210,  0.0834, -0.1499,\n",
      "         0.5068,  0.2290, -0.0310, -0.1241, -0.3896, -0.0266,  0.0618,  0.0439,\n",
      "         0.3620,  0.4077, -0.2923, -0.2467,  0.3691,  0.0784, -0.1970, -0.3657,\n",
      "         0.3227,  0.1816,  0.1495,  0.2231,  0.4500,  0.2377, -0.3177, -0.2865,\n",
      "        -0.4884,  0.0339, -0.2248, -0.3694, -0.0503, -0.0677,  0.1782, -0.1148,\n",
      "        -0.0413,  0.2358, -0.1682,  0.4422, -0.1907, -0.0743,  0.1116, -0.1490,\n",
      "         0.0663,  0.4277,  0.1248,  0.1626,  0.0232, -0.5985, -0.0834,  0.0542,\n",
      "        -0.2148,  0.0856,  0.2850,  0.0816,  0.0072, -0.1047, -0.2575, -0.1185,\n",
      "         0.4046, -0.0587,  0.1327, -0.0953, -0.0789,  0.0897,  0.1098,  0.1490,\n",
      "        -0.1917, -0.2211,  0.0399,  0.0681,  0.2570, -0.0196, -0.0331, -0.0725,\n",
      "         0.0502,  0.2350, -0.1418,  0.0461,  0.6399, -0.1169, -0.3749,  0.0524,\n",
      "        -0.0483,  0.0698, -0.2031, -0.2201, -0.0120, -0.1649, -0.3386,  0.0178,\n",
      "         0.3923,  0.4291, -0.3592,  0.1404, -0.1373,  0.2682, -0.2508,  0.0370,\n",
      "         0.1364,  0.0574, -0.2353, -0.0899,  0.3370, -0.0296,  0.1258,  0.2048,\n",
      "         0.1226, -0.2592,  0.1696,  0.1627, -0.0494, -0.0384, -0.0823,  0.1694,\n",
      "        -0.1741, -0.2096, -0.0425, -0.1629,  0.3817, -0.4911,  0.1502, -0.1650,\n",
      "         0.2080,  0.0394,  0.0089,  0.2236, -0.0641, -0.2021,  0.2450,  0.1463,\n",
      "         0.2766,  0.0718,  0.2269,  0.2534,  0.1967, -0.0296, -0.2651, -0.0820,\n",
      "        -0.4364,  0.0347, -0.0543, -0.2091,  0.2174,  0.0814, -0.2207,  0.1213,\n",
      "         0.0158, -0.1931,  0.1824, -0.0334,  0.0290,  0.0926, -0.0972, -0.4302,\n",
      "        -0.0890,  0.0598,  0.3019,  0.0829,  0.0105, -0.1714,  0.3057,  0.1448,\n",
      "         0.0782, -0.0130,  0.0709, -0.4238, -0.0237, -0.1278,  0.0947, -0.2729,\n",
      "         0.0690,  0.1994,  0.0459, -0.0651, -0.0533,  0.3728, -0.0110, -0.1257,\n",
      "         0.7053, -0.3807,  0.1177,  0.0655,  0.0219,  0.0587, -0.1328, -0.0697,\n",
      "         0.2345,  0.2324, -0.4722, -0.1405, -0.0374,  0.1753, -0.0340, -0.1114,\n",
      "         0.3603, -0.0373,  0.0315,  0.0964,  0.3747,  0.1289, -0.0346, -0.2339,\n",
      "        -0.2346,  0.5269,  0.3130, -0.0129, -0.3458,  0.0875, -0.0511, -0.0427,\n",
      "        -0.2554,  0.0474, -0.0505,  0.3162,  0.2597,  0.0574,  0.3716, -0.0820,\n",
      "         0.0094,  0.2005, -0.1126, -0.2465, -0.1584,  0.0126, -0.0122,  0.0913,\n",
      "        -0.1927,  0.1090, -0.1369, -0.1714, -0.3830, -0.0097,  0.0083,  0.3893,\n",
      "         0.7047, -0.0089,  0.1712, -0.0682, -0.1940, -0.1892, -0.1550,  0.1057,\n",
      "        -0.3075,  0.0377, -0.1488, -0.1024, -0.5196, -0.0532, -0.2374,  0.2848,\n",
      "         0.0383, -0.2392,  0.0879,  0.4249,  0.0302, -0.0081,  0.0541,  0.4004,\n",
      "        -0.2523,  0.1114,  0.1832,  0.3019,  0.2681,  0.0108, -0.2427, -0.0507,\n",
      "         0.1028, -0.4139, -0.0458, -0.0612, -0.2003, -0.0994, -0.1386, -0.1685,\n",
      "        -0.0562,  0.0344, -0.2453,  0.4578, -0.4228, -0.1692, -0.1880,  0.0728,\n",
      "        -0.0562, -0.0812, -0.3918,  0.5482, -0.0909,  0.0198, -0.2620,  0.1671,\n",
      "         0.2087,  0.1068, -0.1839,  0.0618, -0.1604, -0.4975,  0.1345, -0.0207,\n",
      "         0.4285, -0.1318, -0.1719, -0.1531,  0.1994, -0.1543, -0.3288,  0.4440,\n",
      "        -0.0950,  0.4376,  0.1217, -0.1074,  0.1828, -0.0488,  0.5675,  0.2143,\n",
      "         0.0119, -0.0852, -0.1411,  0.4440,  0.2297, -0.0241,  0.2035, -0.6582,\n",
      "         0.0380, -0.0733,  0.3043, -0.1948,  0.0787, -0.1171, -0.1035, -0.1114,\n",
      "        -0.0618,  0.3142, -0.0881,  0.3468,  0.1877, -0.1055, -0.7585, -0.1766,\n",
      "        -0.1027,  0.1995, -0.0747, -0.0525, -0.0302,  0.1024,  0.2460, -0.2786,\n",
      "        -0.0166,  0.1082, -0.3337, -0.2739,  0.0730, -0.0758, -0.5074,  0.3215,\n",
      "        -0.0389,  0.0688, -0.0643,  0.0751, -0.0921,  0.0813, -0.0834,  0.0451,\n",
      "        -0.0235, -0.2033, -0.0887,  0.1314, -0.2479, -0.1260,  0.2236, -0.4353,\n",
      "        -0.2168, -0.1113, -0.0392,  0.4424,  0.2958, -0.0936,  0.1564,  0.0701,\n",
      "         0.1553,  0.0340,  0.1579,  0.1323,  0.0130,  0.0062, -0.2283,  0.1097])\n",
      "Embedding of the third token:          tensor([ 0.0263,  0.4716,  0.4143, -0.1457,  0.4606, -0.1087, -0.0233,  0.0261,\n",
      "         0.5923, -0.0689, -0.2685, -0.1141,  0.5396,  0.2684,  0.0776,  0.1106,\n",
      "         0.0735, -0.0682,  0.4787, -0.1404, -0.4157,  0.3694, -0.1796, -0.2299,\n",
      "        -0.2035,  0.4205, -0.4463, -0.0348, -0.0985,  0.3841,  0.0863, -0.2594,\n",
      "         0.4177, -0.3955,  0.6362,  0.6121,  0.4895,  0.0414, -0.5674,  0.1131,\n",
      "         0.4531,  0.0692, -0.1135,  0.0781, -0.0139,  0.2182,  0.2477, -0.3304,\n",
      "        -0.3109, -0.0312, -0.5849, -0.1365,  0.2760,  0.2410, -0.0250, -0.5821,\n",
      "         0.1662, -0.2758,  0.0036,  0.5791, -0.0493,  0.0881,  0.1050,  0.0705,\n",
      "         0.2741,  0.2031,  0.9260,  0.3812,  0.4838, -0.0227, -0.2138, -0.4405,\n",
      "         0.3958,  0.3286, -0.2558,  0.2683, -0.1841, -0.7837, -0.0826, -0.0449,\n",
      "        -0.8254, -0.1643, -0.3761, -0.7425,  0.1191,  0.5896, -0.5037,  0.0991,\n",
      "        -0.1067,  0.4205, -0.5035,  0.2812, -0.1399,  0.1231,  0.2534, -0.4262,\n",
      "         0.5148,  0.2136,  0.3891,  0.0242,  0.3445,  0.2441, -0.0017, -0.3988,\n",
      "        -0.2568,  0.4713,  0.2654,  0.3050,  0.4111, -0.6505,  0.6950, -0.0363,\n",
      "         0.2245, -0.3322,  0.3355,  0.5783,  0.1531,  0.1823, -0.9246,  0.2586,\n",
      "        -0.4965, -0.0658,  0.0364,  0.8362,  0.4121, -0.8465, -0.2751,  0.8989,\n",
      "        -0.1375,  0.5888, -0.0894, -0.3912,  0.2111,  0.3569,  0.2537, -0.0032,\n",
      "        -0.1876, -0.2592,  0.0658, -0.4228,  0.3624, -0.1374,  0.2009, -0.1389,\n",
      "         0.2090,  0.0815, -0.4844, -0.1500, -0.6144,  0.4941,  0.2070,  0.4442,\n",
      "        -0.2830, -0.2417,  0.3452,  0.1587,  0.6682, -0.2559, -0.0579, -0.5190,\n",
      "        -0.1604, -0.1119, -1.1186,  0.0846,  0.2119, -0.1365, -0.0481,  0.4867,\n",
      "         0.3448,  0.2702, -0.3265, -0.3063,  0.5116, -0.6040, -0.0773, -0.3441,\n",
      "        -0.0331,  0.0990,  0.3509,  0.3536,  0.0452,  0.3785,  0.0300,  0.0655,\n",
      "        -0.2515,  0.2589,  0.6230,  0.0901, -0.4534, -0.1370, -0.4733,  0.0174,\n",
      "         0.1829, -0.8544, -0.5031, -0.3042,  0.3366, -0.1643, -0.0147, -0.8590,\n",
      "        -0.3220,  0.2185, -0.0377, -0.0349,  0.4366, -0.2940, -0.0549, -0.2082,\n",
      "         0.2050, -0.1218,  0.8511,  0.0593,  0.3013, -0.1276, -0.2377,  0.1586,\n",
      "        -0.0085,  0.4678, -0.5348,  0.4511, -0.2302, -0.1529,  0.3136, -0.2043,\n",
      "         0.0304, -0.4899, -0.0989, -0.1147,  0.1308,  0.1203,  0.1831,  0.2053,\n",
      "        -0.3072, -0.3178, -0.4428, -0.6206,  0.1600,  0.0624,  0.0968,  0.3511,\n",
      "        -0.2035,  0.0573,  0.2187, -0.0087,  0.0175,  0.6704, -0.0361,  0.7104,\n",
      "        -0.0600, -0.4650, -0.1086,  0.5063, -0.0421, -0.5496, -0.4509,  0.4351,\n",
      "         0.5057,  0.1631,  0.0428,  0.0290,  0.0591,  0.1280,  0.6117,  0.3162,\n",
      "         0.0179, -0.4543,  0.6747, -0.0021, -0.2350, -0.2271,  0.2621, -0.3139,\n",
      "         0.3422,  0.0290, -0.4776,  0.8032,  0.3555,  0.1558, -0.3379, -0.9100,\n",
      "         0.0443, -0.1304,  0.0343, -0.4908, -0.0809, -0.5015,  0.0568, -0.2111,\n",
      "         0.0633,  1.0416,  0.0050,  0.1391, -0.4584,  0.5845,  0.4336, -0.0648,\n",
      "        -0.6182, -0.6913, -0.1791, -0.1788, -0.4115, -0.3556, -0.2696, -0.3707,\n",
      "         0.6476, -0.3559,  0.5374,  0.0806, -0.1547, -0.4532, -0.1944, -0.4376,\n",
      "        -0.0745,  0.2973,  0.2747, -0.4487,  0.1955, -0.8677,  0.3180,  0.1569,\n",
      "         0.2998, -0.5403, -0.3707,  0.0267,  0.4442,  0.2821, -0.2378,  0.4016,\n",
      "         0.1298, -0.5334,  0.6720,  0.1559, -0.5039, -0.3357, -0.0137,  0.3959,\n",
      "         0.1505, -0.3722,  0.1445,  0.0794,  0.4306, -0.4927,  0.4079, -0.7337,\n",
      "         0.1956,  0.2040, -0.3113, -0.4859, -0.2182, -0.4017,  0.8395, -0.4299,\n",
      "        -0.0271,  0.3626,  0.1222,  0.4647, -0.5417,  0.3105,  0.3219,  0.2100,\n",
      "        -0.3859, -0.2695, -0.1063,  0.6116,  0.3867, -0.2995,  0.7858, -0.0165,\n",
      "         0.1719, -0.0776,  0.6972,  0.5717, -0.0022,  0.0603,  0.0887,  0.2547,\n",
      "         0.2952,  0.0372, -0.2747,  0.5572,  0.1713,  0.2569,  0.0971,  0.0349,\n",
      "         0.1416,  0.1558,  0.4372,  0.1315,  0.1271,  0.1124,  0.0224, -0.2905,\n",
      "        -0.4496,  0.0136,  0.5351, -0.3756,  0.3299,  0.1289,  0.0605,  0.0937,\n",
      "         0.0176, -0.0444, -0.4730,  0.1664,  0.2312, -0.6888, -0.0308,  0.2020,\n",
      "         0.4416, -0.0521, -0.5952,  0.2456, -0.4983,  0.0523, -0.4717, -0.0542,\n",
      "         1.1453,  0.2706,  0.7849,  0.0284,  0.0503,  0.5910, -0.7061, -0.1763,\n",
      "         0.2432,  0.0090, -0.4377,  0.3176, -0.2212, -0.1075, -0.1509, -0.2385,\n",
      "         0.4897,  0.7504,  0.6085, -0.5758,  0.1449,  0.1158,  0.4607,  0.1133,\n",
      "         0.4453, -0.5290, -0.0717,  0.0648, -0.0549,  0.0945, -0.0891,  0.3558,\n",
      "         0.0339,  0.0147,  0.4152, -0.2266, -0.5441, -0.6366,  0.2736, -0.3909,\n",
      "        -0.5015, -0.3882, -0.0861, -0.2388,  0.0936,  0.3450, -0.0392,  0.3753,\n",
      "        -0.0338, -0.2918, -0.2742, -0.5005,  0.4018,  0.4995, -0.1006,  0.5756,\n",
      "        -0.0661,  0.2765, -0.2909,  0.1479, -0.1475,  0.3348,  0.5326,  0.1189,\n",
      "         0.2177,  0.3578, -0.3902,  0.4629, -0.6419,  0.0299, -0.0914, -0.0140,\n",
      "        -0.5988, -0.7312, -0.2118,  0.4746, -0.0311, -0.5305,  0.1044,  0.0157,\n",
      "        -0.0318, -0.9803, -0.6489,  0.3172, -0.3536,  0.3612,  0.2535, -0.1248,\n",
      "        -0.3870, -0.0377,  0.1213,  0.3195,  0.1296, -0.0557,  0.3608, -0.3047])\n",
      "Embedding of the fourth token:         tensor([-1.0191e-01,  6.3149e-01, -5.1351e-01, -1.0095e-01,  5.3149e-01,\n",
      "        -1.6375e-01,  7.5529e-02,  2.5413e-01,  2.5810e-02, -3.8415e-01,\n",
      "         2.3360e-01, -4.0032e-01,  4.6465e-01,  2.8535e-01, -5.6583e-01,\n",
      "         3.0523e-02, -6.0313e-02,  4.5105e-01, -6.1081e-01,  1.6661e-01,\n",
      "        -5.6043e-01, -8.9234e-01,  5.6514e-01, -2.8369e-01, -3.6496e-01,\n",
      "        -6.8911e-02, -1.5860e-01,  3.6877e-01,  3.4028e-01,  2.8743e-01,\n",
      "         4.5682e-01,  4.2846e-01, -4.2322e-02, -6.5769e-01,  1.1935e-01,\n",
      "         9.9699e-02, -4.1079e-02,  2.7283e-01, -3.2018e-01, -4.6368e-01,\n",
      "         1.3201e-01, -8.2185e-02,  1.9470e-01, -5.7835e-02,  4.3911e-01,\n",
      "        -1.3807e-01, -2.3853e-01, -3.7620e-01, -2.9464e-01, -6.3872e-01,\n",
      "         2.5846e-02, -1.8810e-01, -2.9801e-02,  4.2445e-02,  2.4750e-01,\n",
      "        -2.6224e-01, -7.5918e-02, -7.8489e-01,  9.7470e-02,  2.6440e-01,\n",
      "         1.7325e-01,  6.8349e-02,  4.0710e-02,  3.2174e-01,  1.2556e-01,\n",
      "         3.0729e-01,  1.2236e-01, -3.8904e-01, -3.6383e-01,  7.0438e-01,\n",
      "         1.5773e-01,  5.8385e-02, -9.4967e-02,  1.0412e-01, -1.6978e-01,\n",
      "        -4.3805e-01,  5.2400e-02,  1.1518e-01, -1.3587e-01, -3.6024e-01,\n",
      "        -3.5981e-02,  4.0408e-01, -1.8622e-01, -3.6597e-01, -3.3114e-01,\n",
      "        -1.0354e-01, -1.2983e-01,  2.8746e-01,  4.0044e-01,  1.4278e-01,\n",
      "         1.6496e-01, -1.8322e-01,  2.3008e-01, -6.1341e-01,  1.2438e-01,\n",
      "         3.4095e-01, -2.8255e-01,  2.7946e-01, -1.3543e-01,  8.7735e-02,\n",
      "        -1.7296e-01,  5.9780e-02, -4.5454e-01, -3.6079e-01,  5.3612e-01,\n",
      "         2.2445e-01,  3.9964e-01,  3.0471e-01, -2.0949e-01, -1.8725e-01,\n",
      "         5.5506e-01,  4.7531e-01,  4.0857e-01, -3.2856e-01, -2.3361e-01,\n",
      "         1.7009e-01,  3.4802e-01,  9.6245e-02, -2.5761e-01, -3.1953e-01,\n",
      "        -3.7889e-01, -7.3107e-01, -3.4587e-01, -2.6663e-02,  1.9312e-01,\n",
      "         1.0366e-01, -4.9127e-02,  9.4884e-01, -5.3620e-02,  4.1409e-02,\n",
      "        -3.2374e-01,  1.2147e-01,  2.9242e-01, -2.6563e-01,  1.2504e-01,\n",
      "         1.4043e-01, -1.6390e-01,  9.2337e-01, -3.4896e-01, -2.9312e-01,\n",
      "        -5.3111e-01,  1.6673e-01, -5.4462e-02, -3.8489e-01,  2.3250e-01,\n",
      "         4.3461e-01, -1.3404e-01, -1.1798e-01,  4.5585e-01,  1.7216e-01,\n",
      "         4.6039e-01, -3.5657e-01,  8.1588e-02,  1.9224e-01, -5.7205e-01,\n",
      "         5.0630e-01,  4.2592e-01, -2.8883e-01, -1.5953e-01,  1.2187e-01,\n",
      "        -6.3983e-01, -4.3136e-01,  5.4363e-01, -2.5029e-01, -2.4980e-01,\n",
      "         3.0971e-01,  4.0705e-02, -4.0995e-01,  1.0064e-01,  2.5685e-01,\n",
      "         2.4683e-01,  2.0002e-01,  6.0834e-01,  1.0556e-01,  2.2514e-01,\n",
      "         1.0655e-01, -7.5594e-01, -2.6010e-02,  8.0192e-01, -4.4729e-01,\n",
      "         2.0163e-01,  7.2457e-01,  2.3160e-01, -3.3954e-01, -1.3197e-01,\n",
      "         6.3800e-01,  3.1789e-01,  1.4679e-01, -4.7861e-01,  4.6846e-01,\n",
      "        -1.0820e-01, -8.9922e-01,  4.2295e-01, -1.0191e-01,  1.5997e-01,\n",
      "         5.5171e-01,  5.6225e-01,  2.5793e-01, -3.0428e-01,  3.6141e-01,\n",
      "         1.3105e-01,  8.0103e-03,  2.9239e-01, -4.7124e-01, -1.6296e-01,\n",
      "         2.7797e-01, -5.5053e-01,  8.8109e-01, -1.0607e-01,  4.1543e-02,\n",
      "         7.4458e-02,  4.4502e-01, -5.5218e-02, -4.3612e-01, -6.2494e-01,\n",
      "        -2.2478e-01, -1.8902e-01, -7.2432e-02,  2.8385e-01, -2.9767e-01,\n",
      "         4.2841e-02, -1.7963e-01,  6.3701e-02, -3.2295e-01,  2.7983e-01,\n",
      "        -3.5963e-01,  1.3104e-01,  5.5484e-01,  9.7810e-02, -4.7670e-02,\n",
      "        -8.8698e-02, -2.0080e-01,  2.7175e-01,  1.4703e-01, -3.6471e-03,\n",
      "        -6.3344e-02,  2.0821e-01,  4.1005e-01, -5.9397e-02, -5.0304e-01,\n",
      "         1.1896e-01,  6.1584e-01, -4.7379e-01, -9.1199e-04,  1.1540e-01,\n",
      "         1.8869e-01, -7.4269e-02, -8.1787e-03, -5.2807e-01,  6.1719e-01,\n",
      "        -1.1161e-01,  5.7842e-02,  6.2635e-01, -5.6275e-01,  1.2824e-01,\n",
      "        -1.0305e-01,  8.5391e-01, -2.8774e-02,  1.1784e-01,  1.2576e-01,\n",
      "         2.6101e-01, -6.1350e-01, -7.0841e-02,  7.7872e-02, -2.6469e-01,\n",
      "        -1.9464e-01, -4.5032e-01, -5.6252e-02,  1.8341e-01,  2.3236e-01,\n",
      "         6.7288e-01, -2.5467e-01, -1.3055e-01, -1.4951e-01, -2.0518e-01,\n",
      "        -3.1752e-01, -2.4024e-01, -8.3699e-02,  5.5854e-01,  8.1890e-02,\n",
      "         6.0711e-02,  3.0419e-01, -5.8726e-01, -4.2472e-01, -3.0327e-01,\n",
      "        -2.8526e-01, -3.6327e-01, -1.5052e-01, -3.5696e-01, -1.2458e-01,\n",
      "         2.3077e-01,  3.4972e-01,  6.3818e-02, -1.1369e-01,  3.0840e-01,\n",
      "        -2.8244e-01, -1.4500e-01,  6.3813e-02,  7.7186e-01,  6.0387e-02,\n",
      "         1.4579e-01,  1.0660e-01,  1.9163e-01, -2.8060e-01,  2.3193e-01,\n",
      "        -5.5106e-01,  7.1951e-02, -9.2079e-01, -1.2788e-01, -7.5112e-01,\n",
      "         7.5058e-01, -4.1475e-01, -5.4497e-01,  1.0319e-01, -1.6401e-01,\n",
      "        -2.1206e-02, -1.8113e-01, -1.7913e-01,  4.9521e-01,  1.0312e-01,\n",
      "         1.3485e-01, -4.4441e-01, -4.2597e-01, -4.1872e-01,  3.4988e-01,\n",
      "         6.9875e-02,  9.9786e-02, -1.2160e-01,  2.0734e-01, -3.5227e-01,\n",
      "         1.0458e-02,  5.1187e-02, -5.9303e-01, -1.6061e-01, -1.1044e-01,\n",
      "        -1.4898e-01, -5.8292e-01, -4.1244e-02,  7.7860e-03,  5.1018e-01,\n",
      "         7.8669e-02,  1.4643e-01,  1.0187e-02,  1.0331e-01,  4.8954e-01,\n",
      "         3.3892e-01, -3.8891e-01,  3.2370e-01, -1.1641e-01,  7.9777e-01,\n",
      "         6.6203e-01, -2.1937e-01,  2.3835e-01, -8.0929e-01,  4.0859e-02,\n",
      "        -3.1843e-01,  1.2462e-01, -1.6154e-01,  1.8771e-01,  4.4978e-01,\n",
      "        -4.5293e-01,  6.1484e-01, -4.3187e-01, -8.9082e-02,  2.2796e-01,\n",
      "         1.2345e-02,  3.7725e-01, -2.1309e-01, -1.7434e-01, -3.4449e-01,\n",
      "        -3.4802e-01,  4.1725e-01, -1.6759e-01,  6.7741e-01,  3.8928e-02,\n",
      "        -2.6210e-01, -1.7495e-01, -3.8161e-01, -3.1744e-01,  1.2507e-01,\n",
      "        -4.3552e-01, -3.0059e-01, -2.1062e-01,  1.4873e-01, -4.5504e-01,\n",
      "        -7.7543e-02, -9.7993e-03,  3.3721e-01, -1.1891e-01,  3.9752e-01,\n",
      "        -1.9826e-01, -4.6760e-01, -8.6620e-02,  3.2473e-01, -1.7168e-02,\n",
      "         4.3118e-02, -4.3718e-01, -1.0992e-01, -1.4642e-01,  1.5831e-02,\n",
      "         2.5798e-01,  3.9592e-01, -3.1009e-02, -1.9837e-01,  1.7349e-01,\n",
      "        -6.0389e-02, -5.0292e-01, -2.8729e-02,  2.1473e-01, -3.5557e-01,\n",
      "        -1.0184e-01,  1.9605e-01, -3.7997e-02,  6.7213e-02, -2.7133e-01,\n",
      "         7.0248e-02,  1.8652e-01,  4.7599e-01,  2.9954e-01, -5.1923e-01,\n",
      "         2.7751e-01,  1.4805e-01, -1.3199e-01,  4.0948e-01,  2.9695e-02,\n",
      "        -2.4466e-01, -2.9927e-01,  5.2188e-01,  5.0932e-01, -1.4935e-01,\n",
      "         2.1214e-01, -1.7123e-01, -7.6195e-01, -5.9214e-01,  3.7285e-01,\n",
      "         1.5892e-01, -1.1013e-01, -1.8788e-01, -4.0573e-02,  3.4847e-01,\n",
      "         3.9372e-02, -7.7701e-04, -1.3485e-01,  2.8763e-01,  4.1323e-01,\n",
      "        -2.0741e-01, -3.4440e-02,  7.8303e-01,  3.0936e-01, -9.9075e-02,\n",
      "         2.9030e-02, -4.4980e-02, -3.1664e-01, -2.2946e-01, -6.1382e-03,\n",
      "        -4.7920e-01, -6.4984e-01, -4.2487e-01, -1.0908e-02, -4.9571e-02,\n",
      "        -1.1260e-01,  1.0797e-01,  8.6998e-02, -2.4572e-01, -9.1834e-01,\n",
      "        -2.4952e-01,  4.2243e-01, -2.8947e-01,  1.9903e-01,  2.0037e-01,\n",
      "        -3.7959e-02,  6.5945e-02, -2.7929e-01,  4.5433e-01, -6.0481e-01,\n",
      "        -2.4749e-01, -9.5401e-02,  5.2140e-01,  2.8620e-01, -6.2581e-01,\n",
      "        -3.7466e-01,  1.0769e-01, -7.4089e-01,  5.3126e-01, -3.9271e-01,\n",
      "         6.0989e-02,  4.8614e-01,  4.4191e-01,  2.7365e-01, -5.2173e-02,\n",
      "        -6.2054e-02,  6.8328e-01,  4.1116e-01,  1.3062e-01, -2.6868e-01,\n",
      "         1.2705e-01, -1.4292e-01,  2.0633e-01, -1.4962e-01,  1.0491e-01,\n",
      "         2.8550e-01, -4.2297e-01,  7.9489e-01,  6.0488e-01, -1.0575e-01,\n",
      "         3.1239e-01,  1.7160e-01,  1.0572e-01,  3.4008e-01, -2.0233e-02,\n",
      "         3.3910e-01,  9.8892e-02])\n",
      "Embedding of the fifth token:          tensor([ 4.8886e-01,  1.4461e-01, -4.0788e-02,  2.7679e-01, -2.0026e-01,\n",
      "         1.4097e-01,  3.8162e-02,  2.0747e-01,  4.9142e-01,  3.2416e-01,\n",
      "         3.2110e-01, -2.5050e-01,  3.3150e-01, -1.3793e-01, -3.0423e-01,\n",
      "         3.2976e-01,  1.3500e-01, -6.6550e-02,  2.7661e-02,  2.9213e-01,\n",
      "        -5.1999e-01, -2.0942e-01,  5.3501e-01, -7.2629e-01, -3.0731e-01,\n",
      "         1.1250e-01, -5.2685e-01,  1.1315e-01, -9.4448e-02, -8.7108e-02,\n",
      "         7.4342e-01, -1.2618e-01,  5.3864e-01, -4.1059e-01, -2.8997e-01,\n",
      "         1.5315e-01,  1.6992e-01, -1.2583e-01, -2.1990e-01, -5.4901e-01,\n",
      "         1.4430e-01, -2.4296e-01, -5.9790e-01, -8.2447e-01,  5.6698e-01,\n",
      "         2.1527e-03,  3.0253e-01, -1.7048e-01, -1.5606e-01, -9.4450e-02,\n",
      "        -3.5311e-01, -4.5790e-02,  1.6711e-02, -4.0010e-01, -1.8353e-01,\n",
      "        -2.2330e-01, -1.0783e-01, -6.4145e-01,  1.8956e-01,  1.6117e-03,\n",
      "        -2.0740e-01,  2.9334e-01,  1.2523e-01, -1.9108e-01,  7.2327e-01,\n",
      "         3.5398e-01,  5.8835e-01,  2.3655e-01, -3.6452e-01, -2.1121e-01,\n",
      "        -8.4559e-02, -1.9852e-01, -3.7776e-01,  2.8950e-01, -1.1254e-01,\n",
      "        -3.4470e-01,  7.9529e-01, -8.1227e-01, -7.3551e-02,  1.7640e-01,\n",
      "        -4.5904e-02, -1.4390e-01,  4.8293e-01,  2.9189e-01, -4.7673e-01,\n",
      "         4.5374e-01, -1.2997e-01,  7.6827e-01, -4.1976e-01, -2.6248e-01,\n",
      "         1.0889e-02, -3.3361e-01,  2.2405e-02, -6.4547e-01, -3.7729e-03,\n",
      "         5.9124e-01,  4.7734e-02,  7.9606e-01, -9.3942e-03,  1.4581e-01,\n",
      "         2.4222e-01, -1.3084e-01,  1.2165e-01, -5.5045e-02, -6.6889e-01,\n",
      "         2.2393e-01, -1.6279e-01,  5.6833e-01, -1.9348e-01, -1.7430e-01,\n",
      "         3.4857e-01,  1.0178e-01,  1.3743e-01, -7.8109e-02, -1.8490e-01,\n",
      "        -1.8286e-01,  3.2759e-01, -2.8534e-01, -4.9975e-01, -1.7796e-01,\n",
      "        -6.4600e-02,  9.9260e-02, -5.1496e-01,  8.2429e-01, -2.0669e-02,\n",
      "        -2.3188e-01,  4.1123e-02,  1.1738e+00, -1.2170e-01,  1.3382e-01,\n",
      "         1.3547e-01,  3.2464e-02,  5.0048e-01, -4.8703e-01, -7.3783e-01,\n",
      "         1.2644e-01, -2.2754e-02,  2.6677e-01, -5.7815e-01, -8.6468e-01,\n",
      "        -9.0943e-02, -3.2121e-01, -2.8061e-01,  3.2022e-01, -1.3861e-01,\n",
      "         3.1062e-01, -7.0431e-02, -3.2237e-01,  1.0185e-01,  2.1265e-02,\n",
      "         1.9168e-01, -5.2159e-01,  3.0109e-01,  3.4900e-01, -3.3870e-01,\n",
      "        -2.1030e-01,  3.0148e-01,  7.6125e-01, -2.0951e-01, -2.2003e-01,\n",
      "        -2.8936e-01, -1.6974e-01, -2.3593e-01,  2.9935e-01,  3.1862e-01,\n",
      "        -4.8058e-01,  3.0001e-02,  4.2528e-01,  2.4442e-01,  4.4709e-01,\n",
      "        -5.0101e-01,  4.1814e-01, -1.0808e-01,  6.6476e-02,  3.2243e-01,\n",
      "        -1.6903e-01,  1.1680e-02,  5.8085e-01, -3.6137e-01,  2.6396e-01,\n",
      "        -1.7483e-01,  6.5515e-01, -4.5164e-02, -2.4770e-01,  1.5982e-01,\n",
      "        -3.8309e-01,  6.1308e-01,  4.5614e-01, -2.6651e-01, -8.5931e-02,\n",
      "         2.8665e-01, -4.9093e-01,  1.2067e-01, -3.6282e-01, -2.4307e-01,\n",
      "         6.9078e-01,  1.8311e-01,  4.8444e-02, -4.5159e-01, -4.9579e-02,\n",
      "         1.7694e-01,  8.3663e-02,  6.1450e-02, -1.8659e-01, -1.3217e-01,\n",
      "         3.1522e-02,  2.5989e-01, -1.5035e-01, -2.7969e-01,  6.5364e-02,\n",
      "         1.5555e-01, -2.6528e-01, -2.4140e-01,  1.7335e-01,  1.1936e-01,\n",
      "         3.3963e-01,  2.4171e-01, -1.6360e-01, -6.2033e-02,  5.3254e-01,\n",
      "         1.5670e-02,  4.9569e-01, -1.1004e-01,  3.1844e-01, -4.8336e-01,\n",
      "         1.6425e-01, -6.0830e-01,  1.4951e-01, -2.2647e-03, -1.2623e-01,\n",
      "        -4.3721e-01, -3.2106e-01, -4.4814e-01, -2.0345e-01, -2.5627e-01,\n",
      "         3.0508e-01,  4.2714e-01,  3.5705e-01, -3.8839e-02, -2.0901e-01,\n",
      "         5.6945e-03,  1.3256e-01, -5.4744e-01, -4.1235e-01,  5.2506e-01,\n",
      "         4.0321e-01,  2.3269e-01, -1.8363e-02,  2.2970e-01, -4.6667e-01,\n",
      "        -5.4835e-01,  5.4504e-01,  4.3232e-01, -5.4021e-01, -2.8871e-01,\n",
      "        -3.6496e-01, -2.9379e-01, -4.0411e-01,  1.4814e-01, -4.0853e-01,\n",
      "        -3.0186e-01, -6.0117e-01, -4.6348e-01,  6.7209e-01, -3.4237e-01,\n",
      "        -1.5060e-01, -1.3398e-01, -4.3567e-01,  3.8758e-01,  2.3111e-01,\n",
      "         3.4376e-02, -4.7240e-02, -6.9798e-02, -8.2256e-01,  2.4785e-01,\n",
      "         8.6814e-01, -3.0500e-01,  6.1666e-01, -8.8030e-04, -3.1767e-01,\n",
      "         4.9395e-01,  3.4519e-01, -1.5609e-02, -3.0791e-01, -1.5275e-01,\n",
      "        -5.0917e-02, -4.0602e-01,  1.4496e-01, -8.8005e-01, -8.4387e-02,\n",
      "         5.0780e-01, -1.1884e-01,  1.1489e+00, -2.2823e-01,  3.3204e-02,\n",
      "        -2.5040e-01, -4.9491e-01, -6.6297e-02,  5.8687e-01,  3.8890e-02,\n",
      "         2.8899e-01, -5.0803e-01,  1.5470e-01, -5.0258e-01,  2.4108e-01,\n",
      "         4.0258e-01,  3.3800e-01, -4.4136e-01, -1.8874e-01,  2.0076e-01,\n",
      "        -2.9130e-01, -9.8853e-02, -7.4542e-01,  2.7019e-01, -2.8935e-01,\n",
      "         1.6835e-01, -2.7611e-01, -2.1728e-01,  7.8214e-01,  2.5915e-01,\n",
      "         2.6617e-01, -3.8884e-01, -5.2278e-01, -2.2348e-01,  1.5336e-01,\n",
      "         6.1410e-02,  2.9485e-01,  3.6109e-01,  2.0070e-01,  3.8997e-01,\n",
      "         5.6838e-01,  1.4211e-01, -4.1659e-01, -1.4390e-01,  1.5033e-01,\n",
      "         1.9493e-01,  4.7123e-01, -1.1421e-01,  3.1458e-01,  3.7663e-01,\n",
      "        -1.6933e-01, -3.6124e-01, -1.7989e-01, -8.2913e-01, -2.7064e-01,\n",
      "        -9.7675e-02, -7.3909e-02, -2.8937e-01, -3.5338e-01, -3.9048e-01,\n",
      "        -1.4322e-01,  7.6431e-01, -3.3667e-01, -6.3345e-04,  5.8217e-01,\n",
      "         4.5247e-01,  2.3239e-01, -4.8891e-01,  7.7092e-03,  7.7546e-02,\n",
      "        -3.7570e-01,  1.3697e-01, -2.4052e-01, -1.3053e-01, -1.2908e-01,\n",
      "        -4.2558e-01,  6.4587e-03, -1.1419e-02, -4.7267e-01, -3.3459e-01,\n",
      "        -3.3827e-01,  7.0941e-01, -2.3663e-01, -1.1501e-01,  1.6123e-01,\n",
      "         5.2450e-02,  3.6966e-01,  1.6392e-01, -7.5767e-02, -4.4295e-01,\n",
      "         1.3145e-01, -1.0957e-01,  7.7277e-01,  3.4581e-01,  1.1210e-01,\n",
      "         3.5365e-01,  1.8652e-01,  2.2779e-01, -1.3775e-01, -1.0261e-01,\n",
      "        -3.1687e-01,  2.3765e-01, -4.9891e-01,  1.1782e-01,  2.1399e-01,\n",
      "         1.6351e-01,  2.1764e-01, -2.1970e-02, -2.4776e-01, -4.9617e-02,\n",
      "         1.5840e-01, -2.2346e-02, -4.6717e-01, -3.7220e-01, -2.3782e-01,\n",
      "        -5.5991e-01, -7.0027e-01,  7.0936e-02,  4.2870e-01,  3.1180e-02,\n",
      "         9.2264e-02, -9.0905e-01,  2.7665e-01, -1.2141e-01, -3.4103e-01,\n",
      "         4.7206e-01,  1.1966e-01,  5.7461e-02, -1.0096e-01, -2.7745e-01,\n",
      "        -4.8039e-01, -8.0549e-02,  9.3576e-02,  5.9210e-01, -1.8529e-01,\n",
      "        -1.9914e-01, -4.1671e-02,  5.5229e-01,  2.0773e-01, -1.9724e-01,\n",
      "        -3.9415e-01,  2.2479e-01, -4.4116e-01, -2.4316e-02, -7.3986e-02,\n",
      "         2.7426e-03,  2.9905e-01, -1.0353e-01, -2.8914e-01, -3.3447e-01,\n",
      "        -2.0671e-01,  1.4384e-01, -2.8016e-01,  4.5383e-01, -1.6548e-01,\n",
      "         4.9355e-01,  2.0525e-01, -3.7150e-01, -6.6594e-03, -3.0237e-01,\n",
      "        -3.0805e-02,  6.2141e-01, -3.2394e-01,  7.7456e-02,  1.3611e-01,\n",
      "        -3.5918e-01, -3.6336e-02, -3.8019e-02, -2.3537e-02, -4.8004e-01,\n",
      "        -2.6616e-01,  5.6931e-01, -8.0391e-01, -8.9407e-02, -5.1537e-02,\n",
      "        -6.4458e-02, -4.6940e-01,  2.9787e-01, -6.8360e-02,  7.8496e-01,\n",
      "         3.8671e-01, -2.7168e-02,  1.9636e-01,  5.1116e-01,  1.6478e-01,\n",
      "         6.7274e-02,  1.9343e-01,  2.2725e-02,  6.0771e-01,  4.2051e-01,\n",
      "        -8.5094e-02,  3.2621e-01,  2.4471e-01, -2.7222e-03,  2.7870e-01,\n",
      "         2.0882e-01,  5.6612e-01,  1.4462e-01,  3.1047e-02, -3.4091e-01,\n",
      "         8.6287e-03,  3.2699e-01, -2.6603e-01, -4.5068e-01, -2.3754e-01,\n",
      "        -1.6645e-01,  8.2975e-02, -1.6202e-01,  1.1704e-01, -1.0441e-01,\n",
      "         2.8260e-01, -3.4899e-01,  3.7029e-01,  5.0484e-01,  2.9152e-01,\n",
      "         5.7794e-02, -2.8371e-01,  8.0880e-02, -2.2200e-01,  2.9299e-01,\n",
      "        -5.3745e-01,  1.1196e-01])\n",
      "Embedding of the sixth token:          tensor([ 4.0670e-01, -1.5957e-02, -5.5749e-02, -1.8664e-01, -1.0637e-01,\n",
      "         5.7734e-01, -2.4321e-01, -8.5970e-02,  9.5050e-02, -1.1381e-01,\n",
      "         1.5501e-01,  1.0555e-01,  2.7701e-01,  2.5504e-02, -1.9787e-01,\n",
      "        -1.7055e-01,  9.1745e-02, -2.2283e-01,  4.0530e-01,  1.9252e-01,\n",
      "         1.5587e-01,  1.6234e-01, -3.9525e-01,  9.1326e-02, -2.3556e-01,\n",
      "         4.4534e-01,  1.7157e-01, -1.9360e-01, -3.1534e-01, -1.1223e-02,\n",
      "        -2.0934e-02, -4.6897e-02,  4.9836e-01, -3.3545e-01,  9.2799e-01,\n",
      "        -7.6156e-02, -1.2663e-01, -6.2433e-01, -1.7831e-01, -1.8997e-01,\n",
      "        -4.3208e-01, -4.1477e-01,  2.3899e-01, -4.8116e-01,  7.7639e-01,\n",
      "         1.4690e-01,  5.5217e-03, -4.9951e-02, -8.5100e-01, -2.3178e-01,\n",
      "        -5.0207e-01, -6.0413e-01, -2.2787e-01,  9.3521e-02,  1.6129e-01,\n",
      "        -3.8025e-01,  1.0918e-01, -2.7538e-01, -2.1413e-01,  2.3499e-01,\n",
      "         5.1228e-01,  4.2274e-01, -1.4833e-01, -4.7724e-01, -5.2911e-01,\n",
      "        -3.7841e-01, -7.0353e-02,  6.3963e-02,  3.6678e-01,  3.4366e-01,\n",
      "        -8.2382e-01,  4.3758e-02,  5.6116e-02,  2.0212e-01,  1.2389e-02,\n",
      "        -7.1507e-02,  2.5590e-01, -3.3381e-01, -2.2684e-01, -8.3416e-02,\n",
      "         1.4881e-01, -7.9717e-01,  8.9007e-04,  7.8261e-02, -2.3971e-01,\n",
      "         3.5234e-01,  2.9692e-02,  3.0852e-01,  3.4436e-01,  5.2066e-02,\n",
      "         2.7341e-01,  1.3088e-01,  4.3501e-01, -1.4901e-01,  3.3127e-01,\n",
      "         4.3066e-01,  1.1211e-01, -2.0999e-02,  3.5129e-02, -1.4621e-01,\n",
      "         1.6524e-01,  3.6189e-01, -2.9175e-02,  1.6231e-05, -3.7822e-01,\n",
      "         4.7937e-02,  3.0615e-01,  3.3866e-01, -1.1831e-01,  4.3766e-01,\n",
      "         3.5951e-01,  3.7069e-02, -1.6713e-01, -1.0990e-01,  1.1708e-01,\n",
      "        -2.8177e-01, -5.6091e-02,  5.4106e-01,  1.8168e-01,  3.2311e-01,\n",
      "         2.0874e-01, -3.4966e-01,  3.3507e-01,  4.8278e-01,  5.5446e-02,\n",
      "         6.3965e-01, -2.4496e-01,  2.2218e-01,  3.0579e-01, -3.1892e-01,\n",
      "        -1.0092e-01,  4.8657e-01, -1.8435e-01, -3.0592e-02,  1.3080e-01,\n",
      "         3.3949e-01,  1.6451e-01,  2.4988e-01, -3.6652e-01,  4.4014e-01,\n",
      "        -3.0610e-01, -2.8368e-01, -1.7330e-01, -6.7473e-02, -7.4575e-02,\n",
      "        -2.3131e-02, -4.2902e-01,  5.7595e-01,  1.8863e-01, -2.1791e-01,\n",
      "         4.7984e-01, -1.1300e-01,  5.5985e-03, -1.9554e-02, -3.8705e-01,\n",
      "         5.7992e-01,  1.3118e-02,  2.3326e-01, -2.3116e-01,  5.6244e-01,\n",
      "        -1.8920e-01, -2.5921e-01, -8.0713e-02,  1.3712e-01, -1.3358e-01,\n",
      "        -1.3086e-01, -8.3402e-02,  3.3194e-01, -3.4486e-01, -1.1949e-01,\n",
      "        -2.7640e-01, -8.1734e-02,  1.9406e-02,  6.9622e-02,  2.3648e-01,\n",
      "        -6.7830e-01,  2.3965e-01, -7.7178e-02, -1.7703e-01, -9.2114e-02,\n",
      "         2.0714e-01,  1.0432e-01,  2.7478e-01,  2.1638e-01,  3.0326e-01,\n",
      "         2.0281e-01, -3.3971e-01,  2.5975e-01, -3.8451e-01, -2.4495e-01,\n",
      "        -7.6318e-01, -5.7553e-01, -1.0312e-01, -4.0933e-01,  3.7117e-03,\n",
      "        -3.3323e-02,  7.4315e-01, -1.7003e-01,  1.5699e-01, -4.0482e-01,\n",
      "         1.1082e-01,  2.5465e-01,  3.6210e-02, -2.3230e-01,  1.7884e-02,\n",
      "        -2.2758e-01, -3.4929e-01,  4.4169e-01,  3.8027e-03, -3.4421e-01,\n",
      "         2.3887e-01, -7.2662e-02, -1.3953e-01, -1.7768e-01, -4.9235e-01,\n",
      "         6.1224e-03, -1.6383e-01, -2.6523e-01, -4.1281e-01, -4.1013e-01,\n",
      "        -6.2190e-01, -2.0783e-01,  8.7022e-03, -5.6296e-02,  2.4020e-01,\n",
      "        -3.3345e-02,  1.3580e-01,  1.6431e-01, -1.4922e-01, -6.6402e-01,\n",
      "         9.6496e-02, -1.2135e-01, -3.0730e-01,  1.1307e-01,  9.0471e-02,\n",
      "        -2.2129e-01, -5.7122e-02,  5.8439e-01, -5.1863e-01, -7.6608e-01,\n",
      "        -2.9449e-01,  4.4689e-01, -5.7290e-01, -1.8438e-01, -5.4240e-01,\n",
      "         3.0496e-01, -5.9948e-01, -5.2631e-01, -2.8587e-01, -3.8569e-03,\n",
      "         8.4470e-02,  7.5754e-01,  2.7085e-01, -3.4533e-01, -1.3407e-01,\n",
      "        -1.0697e-01, -1.9086e-01, -2.2230e-01,  2.3744e-01,  4.3447e-01,\n",
      "         4.7896e-02, -4.7437e-01,  8.9067e-02, -1.2447e-01,  5.6608e-02,\n",
      "        -2.1424e-01, -3.3449e-01,  3.1168e-01, -4.6917e-01,  1.0005e+00,\n",
      "        -3.2450e-02, -4.2734e-01,  1.9612e-02, -1.8352e-01, -1.0035e-02,\n",
      "        -3.1918e-02,  2.5927e-01,  5.0404e-01,  1.3789e-02,  3.3130e-01,\n",
      "         2.0692e-01,  5.4815e-01, -3.6912e-01, -1.6883e-02, -2.3442e-02,\n",
      "         1.0689e-01, -1.7760e-01, -5.4775e-01, -1.4502e-01,  8.2747e-02,\n",
      "         5.5065e-01, -5.9420e-02,  2.1388e-01, -1.2078e-01, -4.9107e-02,\n",
      "        -5.4391e-01,  3.4265e-01, -1.5923e-01,  8.4173e-02,  1.9680e-01,\n",
      "         6.7727e-01, -6.8459e-02, -4.1469e-01, -5.2518e-01,  6.7260e-01,\n",
      "        -2.0578e-01,  2.0595e-01,  2.1605e-01, -1.4526e-01,  9.5677e-02,\n",
      "         7.2519e-02, -1.0435e-01,  6.9709e-03,  1.2174e-01, -9.0040e-04,\n",
      "         1.3301e-01, -1.4832e-02, -8.0783e-01, -2.9309e-01, -7.1559e-02,\n",
      "        -3.4871e-01, -8.9276e-02, -7.5974e-01,  9.9474e-02, -4.5627e-02,\n",
      "         1.4342e-01, -1.2292e-01, -9.9865e-02,  2.1314e-01,  1.0375e-01,\n",
      "         5.0280e-01, -5.6149e-01,  1.2787e-02, -3.4573e-01, -2.6323e-01,\n",
      "        -1.7019e-01, -3.3329e-01,  6.9095e-02, -1.3044e-01,  1.2043e-01,\n",
      "         2.9199e-01,  1.9296e-01,  1.2907e-01, -9.5630e-02, -3.5232e-02,\n",
      "         2.8806e-01,  3.6533e-01, -1.7255e-02, -3.6842e-01,  5.0425e-01,\n",
      "        -1.3617e-01,  1.7926e-01, -5.8294e-01, -2.0157e-01, -4.2022e-01,\n",
      "        -9.6511e-02,  1.8133e-01, -2.9389e-01,  1.6294e-01,  4.2224e-01,\n",
      "        -2.9205e-01,  9.1789e-02, -1.2650e-01, -3.0457e-02, -2.2136e-01,\n",
      "        -6.3845e-01, -1.1280e-01, -8.7672e-02, -3.2197e-02,  4.9587e-01,\n",
      "         4.7781e-04,  6.6928e-01, -2.5589e-01, -4.5322e-02,  3.1456e-01,\n",
      "         2.1774e-01,  3.4597e-02,  2.1648e-01,  4.7900e-01, -5.8520e-01,\n",
      "         9.8518e-02,  4.8287e-01,  3.5469e-01,  1.6499e-01,  1.8661e-01,\n",
      "         7.3341e-02,  6.9801e-01,  1.5953e-01, -5.7986e-02, -2.4259e-01,\n",
      "         1.8378e-02,  1.1614e-01, -8.5704e-01, -2.5529e-01,  7.8681e-01,\n",
      "        -3.6348e-01, -7.4781e-01,  2.1726e-01,  8.7009e-03,  3.5702e-01,\n",
      "         1.7167e-01, -8.1453e-02,  1.1027e-01, -2.0847e-01,  3.3582e-01,\n",
      "        -1.0094e-01,  3.2979e-01, -2.2406e-01, -1.1935e-01,  3.1715e-01,\n",
      "         5.3982e-01,  9.8872e-02, -4.7452e-01, -2.1976e-01, -1.6789e-01,\n",
      "         1.5743e-01,  6.5609e-01, -9.9577e-02, -7.0020e-01, -5.2133e-01,\n",
      "         9.7719e-03,  7.7674e-02, -4.5740e-01,  1.0129e-01,  4.6044e-01,\n",
      "        -2.4311e-01, -3.3818e-01, -8.0234e-02,  5.8843e-02, -3.0127e-01,\n",
      "         6.4116e-01,  2.6722e-01,  2.5212e-02,  1.5157e-02,  8.7056e-02,\n",
      "        -6.0771e-01,  2.0048e-01,  3.5350e-01,  2.7784e-01,  1.8485e-01,\n",
      "        -1.4609e-02,  8.1302e-01, -1.0789e-02, -3.6465e-03,  4.0283e-01,\n",
      "         2.7683e-01,  4.9662e-01,  7.0118e-02, -2.3932e-02,  5.0379e-01,\n",
      "         2.3817e-01,  2.6765e-02, -6.0828e-01, -1.9020e-01,  4.1242e-01,\n",
      "        -1.8677e-01, -3.3031e-01,  2.9025e-01, -2.6222e-02, -2.4593e-01,\n",
      "         3.5729e-01,  2.4310e-01, -1.6475e-01,  9.9383e-03, -4.0004e-02,\n",
      "         2.7082e-01, -2.6061e-01,  2.0546e-01,  2.5865e-01, -4.7154e-01,\n",
      "        -7.6739e-02, -2.0430e-01, -2.0377e-01, -4.3046e-01, -2.0975e-02,\n",
      "         1.3256e-02,  6.8779e-01, -2.6021e-01, -8.4631e-02,  2.0163e-01,\n",
      "        -4.7832e-01, -2.0157e-01, -2.3301e-01,  3.7850e-01,  2.0039e-01,\n",
      "         3.6820e-02, -1.4715e-01,  1.3690e-01,  8.1306e-01, -4.3738e-01,\n",
      "        -4.1261e-01,  4.7262e-01, -1.2655e-01,  1.2846e-01,  5.6988e-01,\n",
      "         1.5482e-01, -1.6831e-01, -8.0843e-01, -5.5702e-02, -2.6079e-01,\n",
      "         6.8620e-01,  3.9320e-01, -3.2550e-01, -1.8152e-01, -1.2570e-01,\n",
      "        -4.2128e-02, -6.0933e-02, -3.4130e-01, -4.6909e-02, -1.7160e-01,\n",
      "         2.5038e-01, -3.4182e-01])\n",
      "Embedding of the twenty-fifth token:   tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Embedding of the fortieth token:       tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Embedding of the fiftieth token:       tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "sequence = TrainTweetsDataset[0][0]\n",
    "sequence_embeddings = pretrained_embeddings_layer(sequence)\n",
    "\n",
    "print('Embedding of the first token:          {}'.format(sequence_embeddings[0]))\n",
    "print('Embedding of the second token:         {}'.format(sequence_embeddings[1]))\n",
    "print('Embedding of the third token:          {}'.format(sequence_embeddings[2]))\n",
    "print('Embedding of the fourth token:         {}'.format(sequence_embeddings[3]))\n",
    "print('Embedding of the fifth token:          {}'.format(sequence_embeddings[4]))\n",
    "print('Embedding of the sixth token:          {}'.format(sequence_embeddings[5]))\n",
    "print('Embedding of the twenty-fifth token:   {}'.format(sequence_embeddings[24]))\n",
    "print('Embedding of the fortieth token:       {}'.format(sequence_embeddings[39]))\n",
    "print('Embedding of the fiftieth token:       {}'.format(sequence_embeddings[49]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LSTM Neural Network with Custom Pre-trained Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:50.418593600Z",
     "start_time": "2023-12-21T15:34:50.412589100Z"
    }
   },
   "outputs": [],
   "source": [
    "TrainTweetsDataset_SkipGram = TweetsDataset(tweets_train, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_SkipGram, batch_size = 128, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_SkipGram = TweetsDataset(tweets_test, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TestTweetsDataset_SkipGram, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Initialize the network, loss function, and optimizer\\ndevice = set_device()\\ncustomPreTrainedLSTM = CustomLSTM(word2vec_model = skipgram_model,\\n                                  hidden_size = 64, \\n                                  output_size = 1, \\n                                  num_layers = 1, \\n                                  bidirectional = True,\\n                                  freeze_embeddings = True).to(device)\\n\\ncriterion = torch.nn.BCEWithLogitsLoss()\\noptimizer = torch.optim.Adam(customPreTrainedLSTM.parameters(), lr = 1e-2, weight_decay = 1e-5)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM = CustomLSTM(word2vec_model = skipgram_model,\n",
    "                                  hidden_size = 64, \n",
    "                                  output_size = 1, \n",
    "                                  num_layers = 1, \n",
    "                                  bidirectional = True,\n",
    "                                  freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM.parameters(), lr = 1e-2, weight_decay = 1e-5)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 8, device = device)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 8, device = device)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Initialize the network, loss function, and optimizer\\ndevice = set_device()\\ncustomPreTrainedLSTM_Attention = CustomLSTM_Attention(word2vec_model = skipgram_model, \\n                                                      hidden_size = 64, \\n                                                      output_size = 1, \\n                                                      num_layers = 1, \\n                                                      bidirectional = True,\\n                                                      freeze_embeddings = False).to(device)\\n\\ncriterion = torch.nn.BCEWithLogitsLoss()\\noptimizer = torch.optim.Adam(customPreTrainedLSTM_Attention.parameters(), lr = 1e-4, weight_decay = 1e-4)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM_Attention = CustomLSTM_Attention(word2vec_model = skipgram_model, \n",
    "                                                      hidden_size = 64, \n",
    "                                                      output_size = 1, \n",
    "                                                      num_layers = 1, \n",
    "                                                      bidirectional = True,\n",
    "                                                      freeze_embeddings = False).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM_Attention.parameters(), lr = 1e-4, weight_decay = 1e-4)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM_Attention, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM_Attention, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "\n",
    "customPreTrainedLSTM_MultiheadAttention = CustomLSTM_MultiHeadAttention(word2vec_model = skipgram_model,\n",
    "                                                                        hidden_size = 512, \n",
    "                                                                        output_size = 1, \n",
    "                                                                        dropout = 0.3,\n",
    "                                                                        num_layers = 3, \n",
    "                                                                        bidirectional = True,\n",
    "                                                                        freeze_embeddings = True,\n",
    "                                                                        num_heads = 32).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM_MultiheadAttention.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5624 | Accuracy = 73.77% | F1-Score = 60.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:14<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6985\n",
      "Training Accuracy = 71.80%\n",
      "Training F1-Score = 63.39%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4775 | Accuracy = 77.78% | F1-Score = 75.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5670\n",
      "Test Accuracy = 70.76%\n",
      "Test F1-Score = 59.85%\n",
      "\n",
      "Epoch 2/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3682 | Accuracy = 85.25% | F1-Score = 78.05% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4666\n",
      "Training Accuracy = 78.44%\n",
      "Training F1-Score = 70.97%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.8283 | Accuracy = 73.02% | F1-Score = 63.83% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.1060\n",
      "Test Accuracy = 66.47%\n",
      "Test F1-Score = 38.68%\n",
      "\n",
      "Epoch 3/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4320 | Accuracy = 88.52% | F1-Score = 86.27% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4341\n",
      "Training Accuracy = 79.93%\n",
      "Training F1-Score = 73.04%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3611 | Accuracy = 85.71% | F1-Score = 83.64% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5205\n",
      "Test Accuracy = 75.08%\n",
      "Test F1-Score = 65.80%\n",
      "\n",
      "Epoch 4/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4379 | Accuracy = 77.05% | F1-Score = 73.08% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3996\n",
      "Training Accuracy = 82.07%\n",
      "Training F1-Score = 76.23%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.9073 | Accuracy = 71.43% | F1-Score = 59.09% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2772\n",
      "Test Accuracy = 64.57%\n",
      "Test F1-Score = 30.02%\n",
      "\n",
      "Epoch 5/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4097 | Accuracy = 75.41% | F1-Score = 61.54% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3763\n",
      "Training Accuracy = 83.04%\n",
      "Training F1-Score = 77.81%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4195 | Accuracy = 84.13% | F1-Score = 83.87% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5260\n",
      "Test Accuracy = 76.31%\n",
      "Test F1-Score = 71.08%\n",
      "\n",
      "Epoch 6/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2440 | Accuracy = 90.16% | F1-Score = 85.71% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3317\n",
      "Training Accuracy = 85.42%\n",
      "Training F1-Score = 81.41%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3774 | Accuracy = 84.13% | F1-Score = 82.14% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6336\n",
      "Test Accuracy = 75.64%\n",
      "Test F1-Score = 65.02%\n",
      "\n",
      "Epoch 7/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3533 | Accuracy = 83.61% | F1-Score = 72.22% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3135\n",
      "Training Accuracy = 87.00%\n",
      "Training F1-Score = 83.75%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5292 | Accuracy = 76.19% | F1-Score = 77.61% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6661\n",
      "Test Accuracy = 70.52%\n",
      "Test F1-Score = 66.71%\n",
      "\n",
      "Epoch 8/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3126 | Accuracy = 90.16% | F1-Score = 84.21% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2659\n",
      "Training Accuracy = 89.11%\n",
      "Training F1-Score = 86.49%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 1.1528 | Accuracy = 69.84% | F1-Score = 76.54% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.4692\n",
      "Test Accuracy = 58.01%\n",
      "Test F1-Score = 65.75%\n",
      "\n",
      "Epoch 9/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2357 | Accuracy = 86.89% | F1-Score = 83.33% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2316\n",
      "Training Accuracy = 90.95%\n",
      "Training F1-Score = 88.89%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4825 | Accuracy = 79.37% | F1-Score = 77.97% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6680\n",
      "Test Accuracy = 75.88%\n",
      "Test F1-Score = 68.33%\n",
      "\n",
      "Epoch 10/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3413 | Accuracy = 91.80% | F1-Score = 87.80% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1978\n",
      "Training Accuracy = 92.83%\n",
      "Training F1-Score = 91.30%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4632 | Accuracy = 87.30% | F1-Score = 87.10% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.7174\n",
      "Test Accuracy = 75.82%\n",
      "Test F1-Score = 70.61%\n",
      "\n",
      "Epoch 11/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2428 | Accuracy = 95.08% | F1-Score = 93.88% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1719\n",
      "Training Accuracy = 93.55%\n",
      "Training F1-Score = 92.23%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4933 | Accuracy = 82.54% | F1-Score = 80.70% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.7661\n",
      "Test Accuracy = 76.37%\n",
      "Test F1-Score = 67.97%\n",
      "\n",
      "Epoch 12/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1828 | Accuracy = 91.80% | F1-Score = 88.37% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1400\n",
      "Training Accuracy = 95.02%\n",
      "Training F1-Score = 94.04%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5994 | Accuracy = 82.54% | F1-Score = 81.36% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9739\n",
      "Test Accuracy = 74.20%\n",
      "Test F1-Score = 65.12%\n",
      "\n",
      "Epoch 13/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1083 | Accuracy = 95.08% | F1-Score = 94.34% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1353\n",
      "Training Accuracy = 95.26%\n",
      "Training F1-Score = 94.35%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7543 | Accuracy = 76.19% | F1-Score = 79.45% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2962\n",
      "Test Accuracy = 66.41%\n",
      "Test F1-Score = 68.65%\n",
      "\n",
      "Epoch 14/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0752 | Accuracy = 98.36% | F1-Score = 98.11% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1154\n",
      "Training Accuracy = 95.93%\n",
      "Training F1-Score = 95.17%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5657 | Accuracy = 84.13% | F1-Score = 83.87% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.8379\n",
      "Test Accuracy = 73.43%\n",
      "Test F1-Score = 69.89%\n",
      "\n",
      "Epoch 15/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2908 | Accuracy = 90.16% | F1-Score = 88.46% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.39it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1114\n",
      "Training Accuracy = 96.30%\n",
      "Training F1-Score = 95.62%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4305 | Accuracy = 85.71% | F1-Score = 86.15% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.8328\n",
      "Test Accuracy = 75.11%\n",
      "Test F1-Score = 69.10%\n",
      "\n",
      "Epoch 16/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0701 | Accuracy = 98.36% | F1-Score = 97.96% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0933\n",
      "Training Accuracy = 96.73%\n",
      "Training F1-Score = 96.14%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6089 | Accuracy = 80.95% | F1-Score = 82.86% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2021\n",
      "Test Accuracy = 69.26%\n",
      "Test F1-Score = 69.50%\n",
      "\n",
      "Epoch 17/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0732 | Accuracy = 96.72% | F1-Score = 95.83% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0872\n",
      "Training Accuracy = 96.97%\n",
      "Training F1-Score = 96.43%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5130 | Accuracy = 84.13% | F1-Score = 82.14% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9023\n",
      "Test Accuracy = 75.64%\n",
      "Test F1-Score = 66.92%\n",
      "\n",
      "Epoch 18/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0175 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0809\n",
      "Training Accuracy = 96.93%\n",
      "Training F1-Score = 96.37%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4539 | Accuracy = 90.48% | F1-Score = 90.32% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9198\n",
      "Test Accuracy = 75.64%\n",
      "Test F1-Score = 69.94%\n",
      "\n",
      "Epoch 19/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0238 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0754\n",
      "Training Accuracy = 97.54%\n",
      "Training F1-Score = 97.11%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6550 | Accuracy = 85.71% | F1-Score = 85.25% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.0661\n",
      "Test Accuracy = 75.64%\n",
      "Test F1-Score = 69.51%\n",
      "\n",
      "Epoch 20/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0936 | Accuracy = 96.72% | F1-Score = 96.15% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0752\n",
      "Training Accuracy = 97.48%\n",
      "Training F1-Score = 97.02%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4276 | Accuracy = 85.71% | F1-Score = 85.25% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9331\n",
      "Test Accuracy = 75.57%\n",
      "Test F1-Score = 70.67%\n",
      "\n",
      "Epoch 21/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0791 | Accuracy = 98.36% | F1-Score = 98.04% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0690\n",
      "Training Accuracy = 97.52%\n",
      "Training F1-Score = 97.09%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3776 | Accuracy = 87.30% | F1-Score = 85.71% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9045\n",
      "Test Accuracy = 77.17%\n",
      "Test F1-Score = 69.63%\n",
      "\n",
      "Epoch 22/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1595 | Accuracy = 95.08% | F1-Score = 92.68% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.41it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0679\n",
      "Training Accuracy = 97.68%\n",
      "Training F1-Score = 97.27%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4727 | Accuracy = 84.13% | F1-Score = 84.85% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9727\n",
      "Test Accuracy = 73.61%\n",
      "Test F1-Score = 70.16%\n",
      "\n",
      "Epoch 23/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0568 | Accuracy = 98.36% | F1-Score = 98.04% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0715\n",
      "Training Accuracy = 97.35%\n",
      "Training F1-Score = 96.87%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6123 | Accuracy = 84.13% | F1-Score = 82.76% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.0172\n",
      "Test Accuracy = 76.77%\n",
      "Test F1-Score = 68.86%\n",
      "\n",
      "Epoch 24/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0833 | Accuracy = 95.08% | F1-Score = 93.02% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0572\n",
      "Training Accuracy = 97.89%\n",
      "Training F1-Score = 97.52%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5123 | Accuracy = 82.54% | F1-Score = 81.97% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.8611\n",
      "Test Accuracy = 75.67%\n",
      "Test F1-Score = 69.51%\n",
      "\n",
      "Epoch 25/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0060 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0581\n",
      "Training Accuracy = 97.83%\n",
      "Training F1-Score = 97.45%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5688 | Accuracy = 84.13% | F1-Score = 82.76% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2058\n",
      "Test Accuracy = 75.48%\n",
      "Test F1-Score = 67.13%\n",
      "\n",
      "Epoch 26/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0273 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0547\n",
      "Training Accuracy = 97.87%\n",
      "Training F1-Score = 97.50%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5981 | Accuracy = 85.71% | F1-Score = 84.21% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.1294\n",
      "Test Accuracy = 75.39%\n",
      "Test F1-Score = 68.69%\n",
      "\n",
      "Epoch 27/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0997 | Accuracy = 95.08% | F1-Score = 94.12% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0597\n",
      "Training Accuracy = 97.70%\n",
      "Training F1-Score = 97.29%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5586 | Accuracy = 84.13% | F1-Score = 84.85% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.1134\n",
      "Test Accuracy = 73.64%\n",
      "Test F1-Score = 70.77%\n",
      "\n",
      "Epoch 28/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0262 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0611\n",
      "Training Accuracy = 97.66%\n",
      "Training F1-Score = 97.25%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5414 | Accuracy = 87.30% | F1-Score = 85.71% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9450\n",
      "Test Accuracy = 75.85%\n",
      "Test F1-Score = 65.86%\n",
      "\n",
      "Epoch 29/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0424 | Accuracy = 98.36% | F1-Score = 97.78% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0618\n",
      "Training Accuracy = 97.71%\n",
      "Training F1-Score = 97.31%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4516 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.0469\n",
      "Test Accuracy = 77.32%\n",
      "Test F1-Score = 71.36%\n",
      "\n",
      "Epoch 30/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1100 | Accuracy = 95.08% | F1-Score = 94.55% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.38it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0552\n",
      "Training Accuracy = 97.87%\n",
      "Training F1-Score = 97.50%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4598 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9010\n",
      "Test Accuracy = 75.15%\n",
      "Test F1-Score = 68.75%\n",
      "\n",
      "Epoch 31/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2348 | Accuracy = 95.08% | F1-Score = 95.38% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0730\n",
      "Training Accuracy = 97.50%\n",
      "Training F1-Score = 97.07%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3804 | Accuracy = 87.30% | F1-Score = 86.67% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.0632\n",
      "Test Accuracy = 75.30%\n",
      "Test F1-Score = 69.54%\n",
      "\n",
      "Epoch 32/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0175 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0538\n",
      "Training Accuracy = 97.87%\n",
      "Training F1-Score = 97.51%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4633 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.0419\n",
      "Test Accuracy = 74.72%\n",
      "Test F1-Score = 68.69%\n",
      "\n",
      "Epoch 33/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0194 | Accuracy = 98.36% | F1-Score = 98.46% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0491\n",
      "Training Accuracy = 98.02%\n",
      "Training F1-Score = 97.67%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4925 | Accuracy = 88.89% | F1-Score = 88.14% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.1047\n",
      "Test Accuracy = 76.62%\n",
      "Test F1-Score = 70.35%\n",
      "\n",
      "Epoch 34/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0176 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0464\n",
      "Training Accuracy = 98.10%\n",
      "Training F1-Score = 97.76%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.8141 | Accuracy = 85.71% | F1-Score = 84.21% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.3463\n",
      "Test Accuracy = 75.97%\n",
      "Test F1-Score = 66.52%\n",
      "\n",
      "Epoch 35/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0647 | Accuracy = 96.72% | F1-Score = 95.83% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.43it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0470\n",
      "Training Accuracy = 98.00%\n",
      "Training F1-Score = 97.65%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5026 | Accuracy = 87.30% | F1-Score = 86.67% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2097\n",
      "Test Accuracy = 73.58%\n",
      "Test F1-Score = 70.03%\n",
      "\n",
      "Epoch 36/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1035 | Accuracy = 96.72% | F1-Score = 95.45% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0516\n",
      "Training Accuracy = 97.87%\n",
      "Training F1-Score = 97.50%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6675 | Accuracy = 85.71% | F1-Score = 85.71% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2931\n",
      "Test Accuracy = 73.95%\n",
      "Test F1-Score = 70.71%\n",
      "\n",
      "Epoch 37/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0598 | Accuracy = 98.36% | F1-Score = 97.96% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.41it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0428\n",
      "Training Accuracy = 98.20%\n",
      "Training F1-Score = 97.88%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.8586 | Accuracy = 82.54% | F1-Score = 83.58% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.5763\n",
      "Test Accuracy = 71.84%\n",
      "Test F1-Score = 70.38%\n",
      "\n",
      "Epoch 38/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0809 | Accuracy = 95.08% | F1-Score = 93.88% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0539\n",
      "Training Accuracy = 97.71%\n",
      "Training F1-Score = 97.31%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7370 | Accuracy = 85.71% | F1-Score = 85.25% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2250\n",
      "Test Accuracy = 75.79%\n",
      "Test F1-Score = 69.62%\n",
      "\n",
      "Epoch 39/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0957 | Accuracy = 96.72% | F1-Score = 94.74% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0528\n",
      "Training Accuracy = 97.82%\n",
      "Training F1-Score = 97.44%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6494 | Accuracy = 87.30% | F1-Score = 87.50% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2974\n",
      "Test Accuracy = 74.16%\n",
      "Test F1-Score = 69.75%\n",
      "\n",
      "Epoch 40/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0799 | Accuracy = 96.72% | F1-Score = 95.83% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.44it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0510\n",
      "Training Accuracy = 97.86%\n",
      "Training F1-Score = 97.48%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5965 | Accuracy = 84.13% | F1-Score = 83.87% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.1839\n",
      "Test Accuracy = 74.69%\n",
      "Test F1-Score = 70.37%\n",
      "\n",
      "Epoch 41/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1038 | Accuracy = 96.72% | F1-Score = 95.65% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0411\n",
      "Training Accuracy = 98.29%\n",
      "Training F1-Score = 97.99%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5115 | Accuracy = 84.13% | F1-Score = 82.14% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.1272\n",
      "Test Accuracy = 76.25%\n",
      "Test F1-Score = 67.86%\n",
      "\n",
      "Epoch 42/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0384 | Accuracy = 98.36% | F1-Score = 97.67% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.43it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0577\n",
      "Training Accuracy = 97.56%\n",
      "Training F1-Score = 97.12%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5031 | Accuracy = 90.48% | F1-Score = 90.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.1245\n",
      "Test Accuracy = 75.36%\n",
      "Test F1-Score = 70.16%\n",
      "\n",
      "Epoch 43/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0773 | Accuracy = 98.36% | F1-Score = 97.96% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.40it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0439\n",
      "Training Accuracy = 98.15%\n",
      "Training F1-Score = 97.82%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5429 | Accuracy = 87.30% | F1-Score = 87.50% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.2219\n",
      "Test Accuracy = 72.11%\n",
      "Test F1-Score = 70.30%\n",
      "\n",
      "Epoch 44/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0298 | Accuracy = 100.00% | F1-Score = 100.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0447\n",
      "Training Accuracy = 97.94%\n",
      "Training F1-Score = 97.57%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5473 | Accuracy = 87.30% | F1-Score = 86.67% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.0512\n",
      "Test Accuracy = 74.84%\n",
      "Test F1-Score = 70.29%\n",
      "\n",
      "Epoch 45/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0370 | Accuracy = 98.36% | F1-Score = 98.18% | Batch ID = 60 : 100%|██████████| 60/60 [00:13<00:00,  4.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0426\n",
      "Training Accuracy = 98.16%\n",
      "Training F1-Score = 97.84%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4625 | Accuracy = 87.30% | F1-Score = 86.67% | Batch ID = 26 : 100%|██████████| 26/26 [00:02<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.3284\n",
      "Test Accuracy = 74.38%\n",
      "Test F1-Score = 68.81%\n",
      "\n",
      "Epoch 46/64\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0348 | Accuracy = 97.66% | F1-Score = 97.48% | Batch ID = 44 :  73%|███████▎  | 44/60 [00:10<00:03,  4.27it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, train_f1s, test_losses, test_f1s \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcustomPreTrainedLSTM_MultiheadAttention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTrainDataLoader_SkipGram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTestDataLoader_SkipGram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 270\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, optimizer, loss_func, epochs, device, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    268\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 270\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m predicted \u001b[38;5;241m=\u001b[39m (output \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    273\u001b[0m correct_batch \u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m target)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(model = customPreTrainedLSTM_MultiheadAttention, \n",
    "                                                       train_loader = TrainDataLoader_SkipGram, \n",
    "                                                       test_loader = TestDataLoader_SkipGram, \n",
    "                                                       optimizer = optimizer, \n",
    "                                                       loss_func = criterion, \n",
    "                                                       epochs = 64, \n",
    "                                                       device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(enumerate(TrainDataLoader_SkipGram), total=len(TrainDataLoader_SkipGram))\n",
    "bidirectional = True\n",
    "hidden_size = 128\n",
    "num_heads = 8\n",
    "\n",
    "for batch_idx, (data, target) in pbar:\n",
    "    data = data\n",
    "    target = target\n",
    "\n",
    "    x = torch.nn.Embedding.from_pretrained(torch.FloatTensor(skipgram_model.wv.vectors), freeze = True)(data)\n",
    "    output, _ = torch.nn.LSTM(skipgram_model.vector_size, hidden_size, 1, batch_first = True, bidirectional = bidirectional)(x)\n",
    "    attn_output, attn_weights = torch.nn.MultiheadAttention(embed_dim = hidden_size * (2 if bidirectional else 1), num_heads = num_heads, batch_first = True)(output, output, output)\n",
    "\n",
    "    # Flatten the multihead attention outputs across the sequence dimension to go from a shape (batch_size, seq_len, embedding_dim) to (batch_size, seq_len * embedding_dim)\n",
    "    flattened_output = attn_output.reshape(attn_output.size(0), -1)\n",
    "\n",
    "    logits = torch.nn.Linear(flattened_output.size(1), 1)(flattened_output)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_CBOW = TweetsDataset(tweets_train, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_CBOW, batch_size = 128, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_CBOW = TweetsDataset(tweets_test, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TestTweetsDataset_CBOW, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM = CustomLSTM(word2vec_model = cbow_model,\n",
    "                                  hidden_size = 256, \n",
    "                                  output_size = 1, \n",
    "                                  num_layers = 3, \n",
    "                                  bidirectional = True,\n",
    "                                  freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6731 | Accuracy = 62.30% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6861\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6969 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 40.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6842\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 2/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6877 | Accuracy = 55.74% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6833\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7035 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6838\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 3/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7004 | Accuracy = 50.82% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6836\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7000 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6836\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 4/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6784 | Accuracy = 59.02% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6834\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6990 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6837\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 5/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7045 | Accuracy = 49.18% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6838\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6991 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 40.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6837\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 6/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6866 | Accuracy = 55.74% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6838\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6983 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6838\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 7/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6823 | Accuracy = 57.38% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6835\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7006 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 40.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6836\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 8/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6998 | Accuracy = 50.82% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6836\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6996 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 40.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6836\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 8, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM_Attention = CustomLSTM_Attention(word2vec_model = cbow_model, \n",
    "                                                      hidden_size = 256, \n",
    "                                                      output_size = 1, \n",
    "                                                      num_layers = 3, \n",
    "                                                      bidirectional = True,\n",
    "                                                      freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4845 | Accuracy = 77.05% | F1-Score = 58.82% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6515\n",
      "Training Accuracy = 58.33%\n",
      "Training F1-Score = 6.43%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4120 | Accuracy = 84.13% | F1-Score = 80.77% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5274\n",
      "Test Accuracy = 73.83%\n",
      "Test F1-Score = 61.00%\n",
      "\n",
      "Epoch 2/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5151 | Accuracy = 72.13% | F1-Score = 63.83% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4761\n",
      "Training Accuracy = 77.49%\n",
      "Training F1-Score = 69.17%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3149 | Accuracy = 88.89% | F1-Score = 87.72% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4681\n",
      "Test Accuracy = 77.63%\n",
      "Test F1-Score = 68.45%\n",
      "\n",
      "Epoch 3/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5320 | Accuracy = 75.41% | F1-Score = 63.41% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4355\n",
      "Training Accuracy = 79.99%\n",
      "Training F1-Score = 72.83%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3117 | Accuracy = 90.48% | F1-Score = 89.66% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4572\n",
      "Test Accuracy = 77.47%\n",
      "Test F1-Score = 67.61%\n",
      "\n",
      "Epoch 4/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2277 | Accuracy = 93.44% | F1-Score = 92.31% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4039\n",
      "Training Accuracy = 82.08%\n",
      "Training F1-Score = 76.10%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3188 | Accuracy = 88.89% | F1-Score = 88.14% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4546\n",
      "Test Accuracy = 78.46%\n",
      "Test F1-Score = 70.12%\n",
      "\n",
      "Epoch 5/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4525 | Accuracy = 78.69% | F1-Score = 60.61% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3801\n",
      "Training Accuracy = 83.59%\n",
      "Training F1-Score = 78.33%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3313 | Accuracy = 88.89% | F1-Score = 88.14% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4599\n",
      "Test Accuracy = 78.88%\n",
      "Test F1-Score = 71.66%\n",
      "\n",
      "Epoch 6/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2912 | Accuracy = 88.52% | F1-Score = 86.79% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3468\n",
      "Training Accuracy = 84.91%\n",
      "Training F1-Score = 80.13%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3818 | Accuracy = 87.30% | F1-Score = 86.67% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4954\n",
      "Test Accuracy = 79.04%\n",
      "Test F1-Score = 73.34%\n",
      "\n",
      "Epoch 7/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3543 | Accuracy = 86.89% | F1-Score = 80.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3137\n",
      "Training Accuracy = 86.96%\n",
      "Training F1-Score = 83.31%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3736 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 40.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5078\n",
      "Test Accuracy = 77.93%\n",
      "Test F1-Score = 71.22%\n",
      "\n",
      "Epoch 8/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2430 | Accuracy = 91.80% | F1-Score = 91.80% | Batch ID = 60 : 100%|██████████| 60/60 [00:03<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2741\n",
      "Training Accuracy = 89.26%\n",
      "Training F1-Score = 86.39%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3686 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 26 : 100%|██████████| 26/26 [00:00<00:00, 41.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5246\n",
      "Test Accuracy = 78.21%\n",
      "Test F1-Score = 71.46%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM_Attention, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 8, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GRU Neural Network with Custom Pre-trained Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_SkipGram = TweetsDataset(tweets_train, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_SkipGram, batch_size = 128, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_SkipGram = TweetsDataset(tweets_test, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TestTweetsDataset_SkipGram, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU = CustomGRU(word2vec_model = skipgram_model, \n",
    "                                hidden_size = 256, \n",
    "                                output_size = 1, \n",
    "                                num_layers = 3, \n",
    "                                bidirectional = True,\n",
    "                                freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6638 | Accuracy = 63.93% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:39<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6843\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7076 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:05<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6849\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 2/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6979 | Accuracy = 52.46% | F1-Score = 0.00% | Batch ID = 60 : 100%|██████████| 60/60 [00:39<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6845\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7045 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 26 : 100%|██████████| 26/26 [00:05<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6840\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 3/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6854 | Accuracy = 58.59% | F1-Score = 0.00% | Batch ID = 17 :  28%|██▊       | 17/60 [00:11<00:29,  1.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, train_f1s, test_losses, test_f1s \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustomPreTrainedGRU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainDataLoader_SkipGram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTestDataLoader_SkipGram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 265\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, test_loader, optimizer, loss_func, epochs, device, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    264\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 265\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, target)\n\u001b[1;32m    267\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 384\u001b[0m, in \u001b[0;36mCustomGRU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    383\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m--> 384\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])  \u001b[38;5;66;03m# Use the last time step's output\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1106\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 8, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU_Attention = CustomGRU_Attention(word2vec_model = skipgram_model, \n",
    "                                                    hidden_size = 256, \n",
    "                                                    output_size = 1, \n",
    "                                                    num_layers = 3, \n",
    "                                                    bidirectional = True,\n",
    "                                                    freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5972 | Accuracy = 66.14% | F1-Score = 39.62% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6553\n",
      "Training Accuracy = 58.26%\n",
      "Training F1-Score = 5.59%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5561 | Accuracy = 67.54% | F1-Score = 56.34% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 65.22%\n",
      "Test F1-Score = 33.97%\n",
      "\n",
      "Epoch 2/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 55.03% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 58.30%\n",
      "Training F1-Score = 5.81%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 3/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 54.50% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 4/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 52.91% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 5/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 59.26% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 6/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 47.62% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 7/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 60.85% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 8/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 54.50% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU_Attention, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 8, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_CBOW = TweetsDataset(tweets_train, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_CBOW, batch_size = 128, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_CBOW = TweetsDataset(tweets_test, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TestTweetsDataset_CBOW, batch_size = 128, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU = CustomGRU(word2vec_model = cbow_model, \n",
    "                                hidden_size = 256, \n",
    "                                output_size = 1, \n",
    "                                num_layers = 3, \n",
    "                                bidirectional = True,\n",
    "                                freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 57.67% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 2/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 59.79% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 3/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 56.61% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 4/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 63.49% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 5/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 60.32% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 6/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 61.90% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 7/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 59.26% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 8/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 55.56% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 8, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU_Attention = CustomGRU_Attention(word2vec_model = cbow_model, \n",
    "                                                    hidden_size = 256, \n",
    "                                                    output_size = 1, \n",
    "                                                    num_layers = 3, \n",
    "                                                    bidirectional = True,\n",
    "                                                    freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 58.20% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 2/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 58.73% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 3/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 52.91% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 4/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 52.38% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 5/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 55.56% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 6/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 62.96% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 7/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 59.79% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 8/8\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 56.61% | F1-Score = 0.00% | Batch ID = 30 : 100%|██████████| 30/30 [00:06<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = nan\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = nan | Accuracy = 48.17% | F1-Score = 0.00% | Batch ID = 13 : 100%|██████████| 13/13 [00:01<00:00, 11.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = nan\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU_Attention, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 8, device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
