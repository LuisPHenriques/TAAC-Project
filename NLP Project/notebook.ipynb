{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Custom Functions & Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T23:10:35.149706Z",
     "start_time": "2023-12-29T23:10:30.436532800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "import re\n",
    "import math\n",
    "import spacy \n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertTokenizer, DistilBertForSequenceClassification, BertTokenizer, BertForSequenceClassification, \\\n",
    "                         RobertaTokenizer, RobertaForSequenceClassification, AutoModel, AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup, \\\n",
    "                         PreTrainedTokenizerFast\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Ignore RuntimeWarning and UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T23:10:37.072317200Z",
     "start_time": "2023-12-29T23:10:36.877905600Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub('http\\S*', ' ', text)\n",
    "    \n",
    "    # remove non-alphabetic\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # make lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove one character word\n",
    "    text = re.sub(\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    text = re.sub(\"^[a-zA-Z]\\s+\", '', text)\n",
    "    \n",
    "    # replace double space to one space\n",
    "    text = re.sub(\"\\s+\", ' ', text)\n",
    "    \n",
    "    # tokenize, lemmatize, remove stop words\n",
    "    doc = nlp(text)\n",
    "    text = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "class BytePairEncoding():\n",
    "    def __init__(self, corpus_df, vocab_size, min_frequency, maxlen):\n",
    "        self.corpus = corpus_df.tolist()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.min_frequency = min_frequency\n",
    "        self.maxlen = maxlen\n",
    "        self.tokenizer = None\n",
    "\n",
    "    def train(self):\n",
    "        # Initialize a tokenizer\n",
    "        self.tokenizer = Tokenizer(BPE())\n",
    "        # Initialize a pre-tokenizer\n",
    "        self.tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "        # Train the tokenizer on the corpus\n",
    "        trainer = BpeTrainer(vocab_size = self.vocab_size, min_frequency = self.min_frequency, special_tokens = [\"[PAD]\"])\n",
    "        self.tokenizer.train_from_iterator(iterator = self.corpus, trainer = trainer)\n",
    "\n",
    "        fast_tokenizer = PreTrainedTokenizerFast(tokenizer_object = self.tokenizer, pad_token = '[PAD]', truncation = True, padding = True)\n",
    "\n",
    "        self.tokenizer = fast_tokenizer\n",
    "\n",
    "    \n",
    "    def tokenize(self, corpus_df):\n",
    "        corpus = corpus_df.tolist()\n",
    "        input_ids = []\n",
    "        attn_masks_corpus = []\n",
    "        tokenized_corpus = []\n",
    "        for tweet in corpus:\n",
    "            # Tokenize the tweet\n",
    "            tokenized_tweet = self.tokenizer.encode_plus(tweet, max_length = self.maxlen, truncation=True, padding='max_length', return_tensors='pt')\n",
    "            # Retrieve the input sequence\n",
    "            input_ids.append(tokenized_tweet['input_ids'])\n",
    "            # Retrieve the attention mask\n",
    "            attn_masks_corpus.append(tokenized_tweet['attention_mask'])\n",
    "            # Retrieve the tokenized tweet\n",
    "            tokenized_corpus.append(self.tokenizer.convert_ids_to_tokens(tokenized_tweet['input_ids'].squeeze()))\n",
    "            \n",
    "        return tokenized_corpus, input_ids, attn_masks_corpus\n",
    "\n",
    "\n",
    "def tokenize_text(tokenizer, df, text_column):\n",
    "    # Extract the text from the specified column\n",
    "    texts = df[text_column].tolist()\n",
    "\n",
    "    # Tokenize the text in the DataFrame using the pre-trained tokenizer and remove \"Ġ\" character\n",
    "    df[text_column + '_tokenized'] = [[token.replace(\"Ġ\", \"\") for token in tokenizer.encode(text).tokens] for text in texts]\n",
    "\n",
    "\n",
    "\n",
    "def get_tfidf_matrix(df, vectorizer):\n",
    "    \n",
    "    # Convert the TF-IDF matrix to a dense NumPy array\n",
    "    matrix = df.todense()\n",
    "\n",
    "    # Convert the dense matrix to a DataFrame\n",
    "    matrix = pd.DataFrame(matrix, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# The sequences being in the formar ['word1', 'word2', 'word3', ...], preprocess it\n",
    "def string2embedding_idx(tokens, model):\n",
    "    \"\"\"\n",
    "    Convert a list of tokens to their corresponding embedding indices.\n",
    "\n",
    "    Args:\n",
    "    - tokens (list): List of tokens.\n",
    "    - model (Word2Vec): Gensim Word2Vec model.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of embedding indices.\n",
    "    \"\"\"\n",
    "    # Filter out tokens not in the vocabulary\n",
    "    #tokens = [token for token in tokens if token in model.wv.key_to_index]\n",
    "\n",
    "    # Convert tokens to their embedding indices\n",
    "    embedding_indices = [model.wv.key_to_index[token] for token in tokens]\n",
    "\n",
    "    return embedding_indices\n",
    "\n",
    "\n",
    "def TSNE_10ClosestWords(model, word, size):\n",
    "    \n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    close_words = model.wv.similar_by_word(word)\n",
    "    arr = np.append(arr, np.array([model.wv[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "            \n",
    "    tsne = TSNE(n_components=2, random_state=0, perplexity = 10)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class TweetsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, word2vec_model):\n",
    "        self.df = df\n",
    "        self.word2vec_model = word2vec_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.df.iloc[idx, -1 if self.word2vec_model == 'skipgram' else -2]\n",
    "        label = self.df.iloc[idx, 1]\n",
    "\n",
    "        # Convert sequence to a 1D tensor\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.long)\n",
    "\n",
    "        # Convert label to a 1D tensor (scalar)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return sequence_tensor, label_tensor\n",
    "    \n",
    "\n",
    "class TweetsDatasetEncoderTransformer(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, word2vec_model, attn_masks):\n",
    "        self.df = df\n",
    "        self.word2vec_model = word2vec_model\n",
    "        self.attn_masks = attn_masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.df.iloc[idx, -1 if self.word2vec_model == 'skipgram' else -2]\n",
    "        label = self.df.iloc[idx, 1]\n",
    "        attn_mask = self.attn_masks[idx]\n",
    "\n",
    "        # Convert sequence to a 1D tensor\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.long)\n",
    "\n",
    "        # Convert label to a 1D tensor (scalar)\n",
    "        label_tensor = torch.tensor(label)\n",
    "\n",
    "        # Convert attention mask to a 1D tensor (scalar)\n",
    "        attn_mask_tensor = attn_mask.flatten().bool()\n",
    "\n",
    "        return sequence_tensor, attn_mask_tensor, label_tensor\n",
    "\n",
    "\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "def TokenizeBERT(tokenizer, df, batch_size = 32, shuffle = True):\n",
    "    # Tokenize training data\n",
    "    encodings = tokenizer(df['clean_text'].tolist(), add_special_tokens = True, truncation = True, padding = True, return_tensors = \"pt\")\n",
    "\n",
    "    # Convert labels to PyTorch tensors\n",
    "    labels = torch.tensor(df['target'].tolist())\n",
    "\n",
    "    # Create a DataLoader for training data\n",
    "    dataset = torch.utils.data.TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], labels)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def TokenizeBERTweet(tokenizer, df, batch_size = 32, shuffle = True, tokenizer_normalizeTweet = None):\n",
    "\n",
    "    # Normalize the text\n",
    "    if tokenizer_normalizeTweet is not None:\n",
    "        normalized_tweets = df['text'].apply(lambda x: tokenizer_normalizeTweet.normalizeTweet(x))\n",
    "    else:\n",
    "        normalized_tweets = df['text'].apply(lambda x: tokenizer.normalizeTweet(x))\n",
    "\n",
    "    # Tokenize training data\n",
    "    encodings = tokenizer(normalized_tweets.tolist(), add_special_tokens = True, truncation = True, padding = True, return_tensors = \"pt\")\n",
    "\n",
    "    # Convert labels to PyTorch tensors\n",
    "    labels = torch.tensor(df['target'].tolist())\n",
    "\n",
    "    # Create a DataLoader for training data\n",
    "    dataset = torch.utils.data.TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], labels)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def train(model, train_loader, test_loader, optimizer, loss_func, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - loss_func (torch.nn.Module): The loss function used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    loss_fn = kwargs.get('loss_fn', loss_func)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            predicted = (output > 0.0).float()\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in pbar:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predicted = (output > 0.0).float()\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "\n",
    "def train_BERT(model, train_loader, test_loader, optimizer, scheduler, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, data in pbar:\n",
    "            input_ids = data[0].to(device)\n",
    "            attn_mask = data[1].to(device)\n",
    "            target = data[2].to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(input_ids, attention_mask=attn_mask, labels=target)\n",
    "            logits = output.logits.squeeze(-1)\n",
    "\n",
    "            loss = output.loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in pbar:\n",
    "                input_ids = data[0].to(device)\n",
    "                attn_mask = data[1].to(device)\n",
    "                target = data[2].to(device)\n",
    "                model.zero_grad()\n",
    "                output = model(input_ids, attention_mask=attn_mask, labels=target)\n",
    "                logits = output.logits.squeeze(-1)\n",
    "\n",
    "                loss = output.loss\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "\n",
    "def train_BERTweet(model, train_loader, test_loader, optimizer, scheduler, loss_func, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    loss_fn = kwargs.get('loss_func', loss_func)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, data in pbar:\n",
    "            input_ids = data[0].to(device)\n",
    "            attn_mask = data[1].to(device)\n",
    "            target = data[2].float().unsqueeze(1).to(device)\n",
    "            model.zero_grad()\n",
    "            logits, bertweet_output = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "            loss = loss_fn(logits, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            predicted = (logits > 0.0).float()\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in pbar:\n",
    "                input_ids = data[0].to(device)\n",
    "                attn_mask = data[1].to(device)\n",
    "                target = data[2].float().unsqueeze(1).to(device)\n",
    "                model.zero_grad()\n",
    "                logits, bertweet_output = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "                loss = loss_fn(logits, target)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predicted = (logits > 0.0).float()\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "\n",
    "def train_EncoderTransformer(model, train_loader, test_loader, optimizer, scheduler, loss_func, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    loss_fn = kwargs.get('loss_func', loss_func)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, data in pbar:\n",
    "            input_ids = data[0].to(device)\n",
    "            attn_mask = data[1].to(device)\n",
    "            target = data[2].float().unsqueeze(1).to(device)\n",
    "            model.zero_grad()\n",
    "            logits = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "            loss = loss_fn(logits, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            predicted = (logits > 0.0).float()\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in pbar:\n",
    "                input_ids = data[0].to(device)\n",
    "                attn_mask = data[1].to(device)\n",
    "                target = data[2].float().unsqueeze(1).to(device)\n",
    "                model.zero_grad()\n",
    "                logits = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "                loss = loss_fn(logits, target)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predicted = (logits > 0.0).float()\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings\n",
    "class CustomLSTM(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embeddings = torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.fc(output[:, -1, :])  # Use the last time step's output\n",
    "        return output\n",
    "\n",
    "\n",
    "# GRU model with pre-trained Word2Vec embeddings\n",
    "class CustomGRU(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomGRU, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embeddings = torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.fc(output[:, -1, :])  # Use the last time step's output\n",
    "        return output\n",
    "\n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, output):\n",
    "        # lstm_output = [batch size, seq_len, hidden_dim]\n",
    "        attention_scores = self.attn(output)\n",
    "\n",
    "        return torch.nn.functional.softmax(attention_scores, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# GRU model with pre-trained Word2Vec embeddings and attention mechanism\n",
    "class CustomGRU_Attention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomGRU_Attention, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "        self.attention = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.gru(x)\n",
    "        attention_weights = torch.nn.functional.softmax(self.attention(output), dim = 1)\n",
    "        output = torch.sum(attention_weights * output, dim = 1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings and attention mechanism\n",
    "class CustomLSTM_Attention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomLSTM_Attention, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.attention = Attention(hidden_size * (2 if bidirectional else 1))\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the embedding of each token in the sequence\n",
    "        x = self.embedding(x)\n",
    "        # Apply LSTM to the sequence of embeddings\n",
    "        output, _ = self.lstm(x)\n",
    "        # Apply the attention mechanism and get attention weights\n",
    "        attn_weights = self.attention(output)\n",
    "        # Compute the weighted sum of the hidden states\n",
    "        output = torch.sum(attn_weights * output, dim = 1)\n",
    "        # Compute the logits\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings and multi-head attention mechanism\n",
    "class CustomLSTM_MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, dropout=0.1, num_layers=1, bidirectional=False, freeze_embeddings=True, num_heads=8):\n",
    "        super(CustomLSTM_MultiHeadAttention, self).__init__()\n",
    "\n",
    "        # Word embedding layer\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze=freeze_embeddings)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.sequence_size = 49\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # Multi-Head Attention layer\n",
    "        self.multihead_attention = torch.nn.MultiheadAttention(embed_dim=hidden_size * (2 if bidirectional else 1), num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Fully-connected layers for classification head\n",
    "        self.fc1 = torch.nn.Linear(hidden_size * (2 if bidirectional else 1) * self.sequence_size, hidden_size * (2 if bidirectional else 1))\n",
    "        self.fc2 = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.bn = torch.nn.BatchNorm1d(hidden_size * (2 if bidirectional else 1))\n",
    "        self.classification_head = torch.nn.Sequential(self.fc1, self.relu, self.bn, self.dropout, self.fc2)\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization\n",
    "        for layer in self.classification_head:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(layer.weight, nonlinearity = 'relu')\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization for the multi-head attention\n",
    "        torch.nn.init.kaiming_uniform_(self.multihead_attention.in_proj_weight, nonlinearity = 'relu')\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization for the LSTM\n",
    "        for layer in self.lstm._all_weights:\n",
    "            for param_name in layer:\n",
    "                if 'weight' in param_name:\n",
    "                    torch.nn.init.kaiming_uniform_(getattr(self.lstm, param_name), nonlinearity = 'relu')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the embedding of each token in the sequence\n",
    "        embed = self.embedding(x)\n",
    "        # Apply LSTM to the sequence of embeddings\n",
    "        hx, cx = self.lstm(embed)\n",
    "        # Apply multihead attention and get attention weights\n",
    "        attn_output, attn_weights = self.multihead_attention(hx, hx, hx)\n",
    "        # Flatten or pool the multihead attention outputs across the sequence dimension\n",
    "        flattened_output = attn_output.reshape(attn_output.size(0), -1)\n",
    "        # Compute the logits considering the weighted values (V) of the multihead attention\n",
    "        logits = self.classification_head(flattened_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        self.positional_encoding = torch.zeros((1, max_len, d_model))\n",
    "        self.positional_encoding[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        self.positional_encoding[0, :, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.positional_encoding[:, :x.size(1), :]\n",
    "    \n",
    "\n",
    "# FCNN model to be used with the TF-IDF features\n",
    "class CustomFCNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate=0.1):\n",
    "        super(CustomFCNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.outlayer = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.bn = torch.nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn(self.relu(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn(self.relu(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.outlayer(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class EncoderTransformer(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout = 0.1, freeze_embeddings = True):\n",
    "        super(EncoderTransformer, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.position_embeddings = torch.nn.Embedding(max_seq_length, d_model)\n",
    "\n",
    "        self.LayerNorm = torch.nn.LayerNorm(d_model, eps = 1e-8, elementwise_affine = True)\n",
    "        self.BatchNorm = torch.nn.BatchNorm1d(d_model * 2)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "        self.encoder_layer = torch.nn.TransformerEncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "        self.encoder = torch.nn.TransformerEncoder(self.encoder_layer, num_layers, norm = self.LayerNorm)\n",
    "\n",
    "        self.dense = torch.nn.Linear(d_model * max_seq_length, d_model * 2)\n",
    "        self.classifier = torch.nn.Linear(d_model * 2, 1)\n",
    "\n",
    "        self.ReLU = torch.nn.ReLU()\n",
    "        self.Tanh = torch.nn.Tanh()\n",
    "        self.LeakyReLU = torch.nn.LeakyReLU()\n",
    "\n",
    "\n",
    "    def forward(self, tweet, attention_mask):\n",
    "    \n",
    "        # Get the embeddings of the tokens\n",
    "        embeddings = self.embeddings(tweet)\n",
    "        # Get the positional embeddings\n",
    "        position_ids = torch.arange(tweet.size(1)).unsqueeze(0).to(tweet.device)\n",
    "        position_embeddings = self.position_embeddings(position_ids)\n",
    "        # Add the positional embeddings to the token embeddings\n",
    "        embeddings += position_embeddings\n",
    "        # Apply layer normalization and dropout\n",
    "        embeddings = self.dropout(self.LayerNorm(embeddings))\n",
    "        # Permute the embeddings to have the shape (seq_length, batch_size, embedding_dim)\n",
    "        embeddings = embeddings.permute(1, 0, 2)\n",
    "\n",
    "        # Apply the transformer encoder\n",
    "        encoder_output = self.encoder(embeddings, src_key_padding_mask = attention_mask)\n",
    "        # Permute the output to have the shape (batch_size, seq_length, embedding_dim)\n",
    "        encoder_output = encoder_output.permute(1, 0, 2)\n",
    "\n",
    "        # Flatten output but keep the batch dimension\n",
    "        flatten_output = encoder_output.reshape(encoder_output.size(0), -1)\n",
    "\n",
    "        # Apply a dense layer followed by a non-linear activation function\n",
    "        output = self.BatchNorm(self.ReLU(self.dense(flatten_output)))\n",
    "        # Apply dropour\n",
    "        output = self.dropout(output)\n",
    "        # Apply the classifier layer\n",
    "        logits = self.classifier(output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class BERTweetForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, bertweet_model, hidden_size, output_size, dropout_rate = 0.1):\n",
    "        super(BERTweetForSequenceClassification, self).__init__()\n",
    "\n",
    "        self.bertweet_model = bertweet_model\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.BatchNorm = torch.nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "        self.dense = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Apply batch normalization to the output of the BERTweet model\n",
    "        berteet_output = self.bertweet_model(input_ids, attention_mask, output_attentions=True)\n",
    "        # Apply batch normalization to the output of the BERTweet model\n",
    "        output = self.BatchNorm(berteet_output.pooler_output)\n",
    "        # Apply dropout\n",
    "        output = self.dropout(output)\n",
    "        # Apply the output layer\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, berteet_output\n",
    "    \n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in pbar:\n",
    "            input_ids = data[0].to(device)\n",
    "            attn_mask = data[1].to(device)\n",
    "            target = data[2].float().flatten().to(device)\n",
    "            model.zero_grad()\n",
    "            logits, bert_output = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "            predicted = (logits > 0.0).float().flatten()\n",
    "\n",
    "            predictions.extend(predicted.tolist())\n",
    "            labels.extend(target.tolist())\n",
    "\n",
    "    return predictions, labels\n",
    "\n",
    "\n",
    "def ComputeConfusionMatrix(labels, preds):\n",
    "    \"\"\"\n",
    "    Computes the confusion matrix for the predicted and ground truth labels.\n",
    "\n",
    "    Args:\n",
    "    - labels_gt (numpy.ndarray): Numpy array containing the ground truth labels.\n",
    "    - labels_pred (numpy.ndarray): Numpy array containing the predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    confusion_table = tabulate(cm,\n",
    "                           headers = ['Predicted ' + cls for cls in ['Not a Disaster', 'Disaster']],\n",
    "                           showindex = ['Actual ' + cls for cls in ['Not a Disaster', 'Disaster']],\n",
    "                           tablefmt=\"fancy_grid\",\n",
    "                           stralign=\"center\",\n",
    "                           numalign=\"center\"\n",
    "                           )\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_table)\n",
    "\n",
    "\n",
    "def ComputeClassificationMetrics(labels, preds):\n",
    "    \"\"\"\n",
    "    Computes the classification metrics for the predicted and ground truth labels.\n",
    "\n",
    "    Args:\n",
    "    - labels_gt (numpy.ndarray): Numpy array containing the ground truth labels.\n",
    "    - labels_pred (numpy.ndarray): Numpy array containing the predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the classification metrics\n",
    "    accuracy = accuracy_score(labels, preds) * 100\n",
    "    precision = precision_score(labels, preds, average='binary') * 100\n",
    "    recall = recall_score(labels, preds, average='binary') * 100\n",
    "    f1 = f1_score(labels, preds, average='binary') * 100\n",
    "\n",
    "    results_table = [\n",
    "            [\"Accuracy\", f\"{accuracy:.2f}%\"],\n",
    "            [\"Weighted Precision\", f\"{precision:.2f}%\"],\n",
    "            [\"Weighted Recall\", f\"{recall:.2f}%\"],\n",
    "            [\"Weighted F1 Score\", f\"{f1:.2f}%\"],\n",
    "        ]\n",
    "\n",
    "    print(tabulate(results_table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\", stralign=\"center\", numalign=\"center\"))\n",
    "\n",
    "\n",
    "def ComputeAttentionMaps(dataset, model, tokenizer, input_id, multiheadlayer_no, head_no):\n",
    "\n",
    "    device = set_device()\n",
    "\n",
    "    # Get all input ids and attention masks from the test dataset\n",
    "    inputs = torch.stack([data[0] for data in dataset]).to(device)\n",
    "    attn_masks = torch.stack([data[1] for data in dataset]).to(device)\n",
    "\n",
    "    logits, berteet_output = model(inputs[input_id].unsqueeze(0), attention_mask=attn_masks[input_id].unsqueeze(0))\n",
    "\n",
    "    attn_weights = berteet_output.attentions\n",
    "    # convert tuple to torch tensor\n",
    "    attn_weights = torch.stack(attn_weights).squeeze(1)\n",
    "    attn_weights = attn_weights[multiheadlayer_no, head_no, :, :].cpu().detach().numpy()\n",
    "\n",
    "    len_seq = sum(attn_masks[input_id]).item()\n",
    "    attention_layer_head = attn_weights[1:len_seq-1, 1:len_seq-1]\n",
    "\n",
    "    sequence = inputs[input_id][1:len_seq-1]\n",
    "    # Get the tokens from the sequence\n",
    "    tokens = tokenizer.convert_ids_to_tokens(sequence.cpu().numpy())\n",
    "\n",
    "    # Create a heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.heatmap(attention_layer_head, cmap=\"binary\", xticklabels=tokens, yticklabels=tokens, annot=False, fmt=\".2f\", cbar=True)\n",
    "    plt.yticks(rotation=0)\n",
    "    ax.xaxis.tick_top() # x axis on top\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:48:51.252105700Z",
     "start_time": "2023-12-29T16:48:49.728914500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0                 Just happened a terrible car crash       1\n",
       "1  Heard about #earthquake is different cities, s...       1\n",
       "2  there is a forest fire at spot pond, geese are...       1\n",
       "3           Apocalypse lighting. #Spokane #wildfires       1\n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_train = pd.read_csv('../data/tweets_data/train.csv')[['text', 'target']].reset_index(drop=True)\n",
    "tweets_test = pd.read_csv('../data/tweets_data/test.csv')[['id', 'text']]\n",
    "tweets_labels = pd.read_csv('../data/tweets_data/test_labels.csv', encoding='latin-1')[['choose_one', 'text']]\n",
    "\n",
    "tweets_labels['target'] = (tweets_labels['choose_one']=='Relevant').astype(int)\n",
    "tweets_labels['id'] = tweets_labels.index\n",
    "\n",
    "tweets_test = pd.merge(left = tweets_test, right = tweets_labels, on='id', how = 'left')[['id', 'text_x', 'target']]\n",
    "tweets_test.rename(columns={'text_x': 'text'}, inplace=True)\n",
    "tweets_test = tweets_test[['text', 'target']]\n",
    "\n",
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text using key-words and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:29:01.782176300Z",
     "start_time": "2023-12-21T15:27:58.466800200Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_train['clean_text'] = tweets_train['text'].apply(preprocess)\n",
    "tweets_test['clean_text'] = tweets_test['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:29:01.798553700Z",
     "start_time": "2023-12-21T15:29:01.785391100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0               deed reason earthquake allah forgive  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident ask shelter place notify officer evac...  \n",
       "3    people receive wildfire evacuation order cal...  \n",
       "4  got send photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \n",
       "0                     happen terrible car crash  \n",
       "1      hear earthquake different city stay safe  \n",
       "2  forest fire spot pond goose flee street save  \n",
       "3          apocalypse lighting spokane wildfire  \n",
       "4            typhoon soudelor kill china taiwan  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-word tokenization with BERT Tokenizer for Byte-Pair Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get an object for Byte Pair Encoding\n",
    "BPETokenizer = BytePairEncoding(corpus_df = tweets_train['clean_text'], vocab_size = 20000, min_frequency = 1, maxlen = 50)\n",
    "# Train the BPE tokenizer on the training data\n",
    "BPETokenizer.train()\n",
    "\n",
    "# Tokenize the training data using the pre-trained tokenizer\n",
    "tokenized_train_corpus, input_ids_train, attn_masks_train = BPETokenizer.tokenize(corpus_df = tweets_train['clean_text'])\n",
    "# Tokenize the test data using the pre-trained tokenizer\n",
    "tokenized_test_corpus, input_ids_test, attn_masks_test = BPETokenizer.tokenize(corpus_df = tweets_test['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column for the tokenized tweets\n",
    "tweets_train['clean_text_tokenized'] = tokenized_train_corpus\n",
    "tweets_test['clean_text_tokenized'] = tokenized_test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[deed, reason, earthquake, allah, forgive, [PA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shelter, place, notify, office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[people, receive, wildfire, evacuation, order,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                clean_text_tokenized  \n",
       "0  [deed, reason, earthquake, allah, forgive, [PA...  \n",
       "1  [forest, fire, near, la, ronge, sask, canada, ...  \n",
       "2  [resident, ask, shelter, place, notify, office...  \n",
       "3  [people, receive, wildfire, evacuation, order,...  \n",
       "4  [got, send, photo, ruby, alaska, smoke, wildfi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, terrible, car, crash, [PAD], [PAD], [...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, pond, go, ose, flee, stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire, [PAD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan, [PAD]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                clean_text_tokenized  \n",
       "0  [happen, terrible, car, crash, [PAD], [PAD], [...  \n",
       "1  [hear, earthquake, different, city, stay, safe...  \n",
       "2  [forest, fire, spot, pond, go, ose, flee, stre...  \n",
       "3  [apocalypse, lighting, spokane, wildfire, [PAD...  \n",
       "4  [typhoon, soudelor, kill, china, taiwan, [PAD]...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text into Input Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:23.476189500Z",
     "start_time": "2023-12-21T15:33:21.430017200Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Filter out [PAD] tokens\n",
    "filtered_tokens = tweets_train['clean_text_tokenized'].apply(lambda tokens: [token for token in tokens if token != '[PAD]'])\n",
    "X_train = vectorizer.fit_transform(filtered_tokens.apply(lambda tokens: ' '.join(tokens)))\n",
    "\n",
    "# Add a new column 'TFIDF' to the original DataFrame with the TF-IDF arrays\n",
    "tweets_train['TFIDF'] = X_train.toarray().tolist()\n",
    "\n",
    "# Filter out [PAD] tokens\n",
    "filtered_tokens = tweets_test['clean_text_tokenized'].apply(lambda tokens: [token for token in tokens if token != '[PAD]'])\n",
    "X_test = vectorizer.fit_transform(filtered_tokens.apply(lambda tokens: ' '.join(tokens)))\n",
    "# Add a new column 'TFIDF' to the original DataFrame with the TF-IDF arrays\n",
    "tweets_test['TFIDF'] = X_test.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:23.661826500Z",
     "start_time": "2023-12-21T15:33:23.626279500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[deed, reason, earthquake, allah, forgive, [PA...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shelter, place, notify, office...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[people, receive, wildfire, evacuation, order,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0  [deed, reason, earthquake, allah, forgive, [PA...   \n",
       "1  [forest, fire, near, la, ronge, sask, canada, ...   \n",
       "2  [resident, ask, shelter, place, notify, office...   \n",
       "3  [people, receive, wildfire, evacuation, order,...   \n",
       "4  [got, send, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                               TFIDF  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, terrible, car, crash, [PAD], [PAD], [...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, pond, go, ose, flee, stre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire, [PAD...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan, [PAD]...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0  [happen, terrible, car, crash, [PAD], [PAD], [...   \n",
       "1  [hear, earthquake, different, city, stay, safe...   \n",
       "2  [forest, fire, spot, pond, go, ose, flee, stre...   \n",
       "3  [apocalypse, lighting, spokane, wildfire, [PAD...   \n",
       "4  [typhoon, soudelor, kill, china, taiwan, [PAD]...   \n",
       "\n",
       "                                               TFIDF  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec (CBOW and Skip-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97446400, 97446400)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbow_model = Word2Vec(sentences = None, vector_size = 512, window = 10, min_count = 1, workers = 4, sg = 0)\n",
    "#cbow_model.wv.key_to_index = BPETokenizer.tokenizer.get_vocab()\n",
    "cbow_model.wv.index_to_key = list(BPETokenizer.tokenizer.get_vocab().keys())\n",
    "# Set the vocabulary and initialize vectors\n",
    "cbow_model.build_vocab([list(BPETokenizer.tokenizer.get_vocab().keys())])\n",
    "cbow_model.train(corpus_iterable = tweets_train['clean_text_tokenized'].tolist(), total_examples = len(tweets_train['clean_text_tokenized']), epochs = 256)\n",
    "\n",
    "skipgram_model = Word2Vec(sentences = None, vector_size = 512, window = 5, min_count = 1, workers = 4, sg = 1)\n",
    "#cbow_model.wv.key_to_index = BPETokenizer.tokenizer.get_vocab()\n",
    "skipgram_model.wv.index_to_key = list(BPETokenizer.tokenizer.get_vocab().keys())\n",
    "# Set the vocabulary and initialize vectors\n",
    "skipgram_model.build_vocab([list(BPETokenizer.tokenizer.get_vocab().keys())])\n",
    "skipgram_model.train(corpus_iterable = tweets_train['clean_text_tokenized'].tolist(), total_examples = len(tweets_train['clean_text_tokenized']), epochs = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the string2embedding_idx function to create a new column\n",
    "tweets_train['CBOW_sequences'] = tweets_train['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, cbow_model))\n",
    "tweets_train['SkipGram_sequences'] = tweets_train['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, skipgram_model))\n",
    "tweets_test['CBOW_sequences'] = tweets_test['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, cbow_model))\n",
    "tweets_test['SkipGram_sequences'] = tweets_test['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, skipgram_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:36.442786700Z",
     "start_time": "2023-12-21T15:34:36.381065300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "      <th>CBOW_sequences</th>\n",
       "      <th>SkipGram_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[deed, reason, earthquake, allah, forgive, [PA...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[8596, 15612, 2284, 5661, 2759, 10484, 10484, ...</td>\n",
       "      <td>[8596, 15612, 2284, 5661, 2759, 10484, 10484, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[772, 18384, 13107, 15557, 10213, 8126, 10802,...</td>\n",
       "      <td>[772, 18384, 13107, 15557, 10213, 8126, 10802,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shelter, place, notify, office...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[202, 19604, 16965, 10451, 9410, 15409, 3216, ...</td>\n",
       "      <td>[202, 19604, 16965, 10451, 9410, 15409, 3216, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[people, receive, wildfire, evacuation, order,...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[6026, 17302, 5968, 3216, 17305, 13368, 10484,...</td>\n",
       "      <td>[6026, 17302, 5968, 3216, 17305, 13368, 10484,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[9467, 6587, 9409, 1270, 17599, 18729, 5968, 3...</td>\n",
       "      <td>[9467, 6587, 9409, 1270, 17599, 18729, 5968, 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0  [deed, reason, earthquake, allah, forgive, [PA...   \n",
       "1  [forest, fire, near, la, ronge, sask, canada, ...   \n",
       "2  [resident, ask, shelter, place, notify, office...   \n",
       "3  [people, receive, wildfire, evacuation, order,...   \n",
       "4  [got, send, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                               TFIDF  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      CBOW_sequences  \\\n",
       "0  [8596, 15612, 2284, 5661, 2759, 10484, 10484, ...   \n",
       "1  [772, 18384, 13107, 15557, 10213, 8126, 10802,...   \n",
       "2  [202, 19604, 16965, 10451, 9410, 15409, 3216, ...   \n",
       "3  [6026, 17302, 5968, 3216, 17305, 13368, 10484,...   \n",
       "4  [9467, 6587, 9409, 1270, 17599, 18729, 5968, 3...   \n",
       "\n",
       "                                  SkipGram_sequences  \n",
       "0  [8596, 15612, 2284, 5661, 2759, 10484, 10484, ...  \n",
       "1  [772, 18384, 13107, 15557, 10213, 8126, 10802,...  \n",
       "2  [202, 19604, 16965, 10451, 9410, 15409, 3216, ...  \n",
       "3  [6026, 17302, 5968, 3216, 17305, 13368, 10484,...  \n",
       "4  [9467, 6587, 9409, 1270, 17599, 18729, 5968, 3...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "      <th>CBOW_sequences</th>\n",
       "      <th>SkipGram_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, terrible, car, crash, [PAD], [PAD], [...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[14810, 7112, 14198, 11041, 10484, 10484, 1048...</td>\n",
       "      <td>[14810, 7112, 14198, 11041, 10484, 10484, 1048...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[8355, 2284, 12295, 14120, 15931, 5296, 10484,...</td>\n",
       "      <td>[8355, 2284, 12295, 14120, 15931, 5296, 10484,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, pond, go, ose, flee, stre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[772, 18384, 2752, 6145, 11514, 4998, 12319, 3...</td>\n",
       "      <td>[772, 18384, 2752, 6145, 11514, 4998, 12319, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire, [PAD...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[7349, 13838, 3098, 5968, 10484, 10484, 10484,...</td>\n",
       "      <td>[7349, 13838, 3098, 5968, 10484, 10484, 10484,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan, [PAD]...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[118, 10486, 19819, 17261, 12042, 10484, 10484...</td>\n",
       "      <td>[118, 10486, 19819, 17261, 12042, 10484, 10484...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0  [happen, terrible, car, crash, [PAD], [PAD], [...   \n",
       "1  [hear, earthquake, different, city, stay, safe...   \n",
       "2  [forest, fire, spot, pond, go, ose, flee, stre...   \n",
       "3  [apocalypse, lighting, spokane, wildfire, [PAD...   \n",
       "4  [typhoon, soudelor, kill, china, taiwan, [PAD]...   \n",
       "\n",
       "                                               TFIDF  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      CBOW_sequences  \\\n",
       "0  [14810, 7112, 14198, 11041, 10484, 10484, 1048...   \n",
       "1  [8355, 2284, 12295, 14120, 15931, 5296, 10484,...   \n",
       "2  [772, 18384, 2752, 6145, 11514, 4998, 12319, 3...   \n",
       "3  [7349, 13838, 3098, 5968, 10484, 10484, 10484,...   \n",
       "4  [118, 10486, 19819, 17261, 12042, 10484, 10484...   \n",
       "\n",
       "                                  SkipGram_sequences  \n",
       "0  [14810, 7112, 14198, 11041, 10484, 10484, 1048...  \n",
       "1  [8355, 2284, 12295, 14120, 15931, 5296, 10484,...  \n",
       "2  [772, 18384, 2752, 6145, 11514, 4998, 12319, 3...  \n",
       "3  [7349, 13838, 3098, 5968, 10484, 10484, 10484,...  \n",
       "4  [118, 10486, 19819, 17261, 12042, 10484, 10484...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:38.609225400Z",
     "start_time": "2023-12-21T15:34:37.441115300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(cbow_model, 'earthquake', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:39.868591200Z",
     "start_time": "2023-12-21T15:34:39.426708900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(skipgram_model, 'earthquake', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:40.997210400Z",
     "start_time": "2023-12-21T15:34:40.562299400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(cbow_model, 'disaster', 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:42.087371100Z",
     "start_time": "2023-12-21T15:34:41.642630900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(skipgram_model, 'disaster', 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Testing our Pre-Trained Embeddings to the PyTorch's Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:46.149953400Z",
     "start_time": "2023-12-21T15:34:46.078377300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-5.0731e-01,  7.5852e-02, -1.1329e-01,  ..., -4.4345e-01,\n",
       "          3.6930e-01,  7.5587e-02],\n",
       "        [ 3.1537e-02, -2.5761e-02, -6.0394e-02,  ...,  7.5270e-03,\n",
       "          1.0388e-01, -7.0228e-02],\n",
       "        [-2.8784e-01, -1.2370e-01, -1.8160e-03,  ..., -2.6632e-01,\n",
       "         -8.1540e-02,  1.0816e-01],\n",
       "        ...,\n",
       "        [-1.3160e-03, -4.5204e-04,  5.7964e-04,  ..., -8.5001e-04,\n",
       "          9.7234e-04,  1.9003e-03],\n",
       "        [-2.0624e-01, -2.0519e-02,  2.6044e-02,  ...,  8.5239e-02,\n",
       "          1.5685e-01,  7.6616e-02],\n",
       "        [-1.8469e-01,  4.5949e-02,  1.4662e-01,  ..., -3.0854e-01,\n",
       "         -1.4936e-01, -3.3686e-02]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding layer with pre-trained weights\n",
    "pretrained_embeddings_layer = torch.nn.Embedding.from_pretrained(torch.FloatTensor(skipgram_model.wv.vectors))\n",
    "# check weights of the pre-trained embedding layer\n",
    "pretrained_embeddings_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:46.893954100Z",
     "start_time": "2023-12-21T15:34:46.867690500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10567, 17090, 17411, 12887,  6705, 12356, 12356, 12356, 12356, 12356,\n",
       "         12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356,\n",
       "         12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356,\n",
       "         12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356,\n",
       "         12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356, 12356]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainTweetsDataset = TweetsDataset(tweets_train, 'skipgram')\n",
    "TrainTweetsDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:48.356003700Z",
     "start_time": "2023-12-21T15:34:48.329539400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding of the first token:          tensor([-3.9371e-01, -1.1980e-01,  1.1813e-01, -2.8433e-01, -7.5813e-02,\n",
      "        -4.2028e-01,  3.1487e-01, -2.3130e-02, -2.3645e-01, -1.4021e-01,\n",
      "        -2.4358e-01, -2.4396e-01, -4.7679e-02, -3.0591e-01,  5.4786e-02,\n",
      "        -3.1441e-02, -7.2947e-01,  1.9720e-01,  3.6674e-01,  2.2637e-02,\n",
      "        -2.6352e-01, -2.6901e-01, -2.1950e-01, -2.3007e-02, -4.4575e-01,\n",
      "        -4.0512e-01, -5.1890e-02,  1.7410e-01,  1.3925e-01,  2.1854e-01,\n",
      "         1.0626e-01, -1.4575e-01,  1.7065e-01,  1.9407e-01,  4.9148e-02,\n",
      "        -1.9354e-01,  1.3097e-01,  5.3276e-02,  3.9240e-02, -1.9900e-04,\n",
      "         9.7612e-03,  4.3491e-02, -7.3982e-02,  2.5682e-02,  1.1152e-01,\n",
      "        -3.8208e-02, -2.0727e-01,  3.7191e-01,  1.2214e-01, -2.8391e-01,\n",
      "         7.0827e-02, -1.3308e-01, -4.1310e-01, -1.8449e-01, -3.9741e-01,\n",
      "        -8.3091e-02,  1.6264e-01, -2.8553e-01, -5.9275e-02, -1.4996e-02,\n",
      "         3.7002e-01,  4.0950e-01, -4.8001e-03,  2.4244e-02, -1.2979e-01,\n",
      "        -1.0511e-01, -2.6302e-01, -1.8477e-01, -9.0162e-02, -6.1414e-02,\n",
      "         4.3911e-02,  3.0256e-01,  2.4366e-02, -3.5996e-02, -3.7669e-03,\n",
      "        -5.6711e-02, -5.7067e-02,  5.1336e-01, -1.3873e-01, -3.7994e-01,\n",
      "         1.1686e-02, -2.3412e-01, -1.8529e-01,  1.2872e-01, -3.3212e-02,\n",
      "        -8.4163e-03, -3.0649e-02, -6.2348e-02, -3.1172e-02,  3.3331e-02,\n",
      "         1.1795e-01, -4.6612e-02, -3.2230e-01, -1.4410e-01,  1.5001e-01,\n",
      "        -8.2309e-02, -3.2232e-02, -5.0491e-02, -1.4001e-01, -3.1539e-01,\n",
      "        -5.4330e-02,  7.3366e-02, -8.8960e-02, -1.1886e-01,  3.4364e-01,\n",
      "        -2.5519e-01,  2.1927e-01,  6.0497e-02,  4.2019e-02,  1.3579e-01,\n",
      "        -2.4538e-01,  7.1228e-02,  1.1174e-01,  1.1585e-01,  3.7800e-02,\n",
      "         2.9486e-02, -1.3519e-01,  2.8950e-01,  1.2530e-01, -1.9786e-01,\n",
      "        -7.4543e-02, -2.4796e-02,  1.2715e-01,  3.0212e-01,  7.1372e-02,\n",
      "        -1.5228e-02,  1.6775e-01,  2.0364e-02, -7.3691e-02,  1.8218e-02,\n",
      "         1.0563e-01, -7.4879e-02,  1.3248e-01, -1.8287e-02, -4.1433e-04,\n",
      "         3.4605e-02, -1.2427e-01, -2.4629e-02,  2.7399e-01, -6.5340e-02,\n",
      "         1.1366e-01, -2.2596e-01,  1.1838e-01,  6.9051e-03,  7.4093e-02,\n",
      "         9.0145e-02,  2.0488e-01,  2.3073e-01,  3.4596e-01,  1.1953e-01,\n",
      "         1.6917e-01,  3.1729e-01,  2.7866e-01, -2.6624e-01, -1.8585e-01,\n",
      "         1.7154e-01,  5.4121e-02,  4.0046e-01, -5.8891e-02, -1.8194e-01,\n",
      "         1.3057e-01, -1.6062e-01,  3.8594e-02, -5.0015e-02,  2.8520e-01,\n",
      "        -2.8009e-01, -4.3453e-02,  3.9233e-02, -3.3118e-01, -1.6004e-01,\n",
      "         4.8436e-02,  2.0983e-01,  8.5848e-02,  1.3016e-01, -8.7658e-02,\n",
      "         2.1644e-01, -1.3878e-01, -1.9527e-01, -6.9879e-02,  1.4734e-01,\n",
      "        -1.6084e-01,  2.0154e-02,  1.9413e-01, -4.8370e-02, -1.6506e-01,\n",
      "         1.3545e-01, -2.5221e-01, -5.5176e-02,  3.9294e-02,  8.4238e-02,\n",
      "         1.7837e-01,  3.9403e-01,  8.0283e-03,  4.3885e-01, -1.3574e-01,\n",
      "        -2.2628e-01,  2.2928e-01,  1.1586e-03,  1.5932e-01,  9.3592e-03,\n",
      "         1.6090e-01, -1.6678e-01, -2.4486e-01, -3.1871e-01, -5.2609e-02,\n",
      "         7.8809e-02, -1.3223e-01, -6.7644e-02,  2.7957e-01, -1.2416e-02,\n",
      "         3.0884e-01, -9.1906e-02, -5.9404e-02, -1.9800e-01,  1.4609e-01,\n",
      "        -2.3219e-01,  1.0614e-01, -1.1528e-01, -1.3702e-02,  2.7709e-03,\n",
      "         1.2346e-02, -1.1256e-02,  1.4913e-01,  1.3421e-01,  9.3848e-02,\n",
      "        -3.1444e-01, -1.3934e-02,  2.2432e-01,  3.1908e-04,  6.2197e-02,\n",
      "         4.9416e-02,  1.4136e-01, -1.3488e-01,  3.0388e-01, -1.4064e-01,\n",
      "        -1.7100e-02, -3.6816e-01, -3.4560e-03,  1.0799e-01, -1.9603e-01,\n",
      "        -1.5230e-01, -6.0667e-02,  3.0189e-02,  2.3711e-01, -2.1275e-02,\n",
      "         7.2902e-02, -2.0988e-01, -1.6165e-02,  5.8038e-02, -3.6078e-01,\n",
      "         4.7466e-03, -5.5086e-02,  1.5866e-01, -2.1624e-01, -2.1334e-01,\n",
      "         1.5398e-01, -1.5119e-01,  9.8332e-02, -9.0171e-02, -2.6636e-01,\n",
      "         8.2899e-02, -5.4997e-02,  2.8476e-01, -9.7640e-02,  7.6473e-02,\n",
      "        -2.0659e-01,  5.3419e-02,  7.8696e-02,  8.0115e-02,  7.4026e-02,\n",
      "         3.3431e-02, -2.6063e-01,  3.4343e-02,  2.7044e-01, -4.4733e-02,\n",
      "         1.5026e-01,  1.6450e-01,  6.2991e-02, -1.2138e-01, -1.5149e-01,\n",
      "         5.1994e-02,  1.1049e-01, -8.6898e-02, -1.9140e-01,  3.1442e-01,\n",
      "        -3.0537e-02,  2.2161e-01,  1.8417e-01,  1.6173e-01, -2.8067e-01,\n",
      "         1.5584e-01,  1.2379e-01,  2.1767e-01, -1.8524e-01, -1.2053e-01,\n",
      "         8.6635e-02,  3.4654e-02,  2.8696e-01, -1.3945e-01, -3.1698e-02,\n",
      "         1.8138e-01, -3.8685e-02,  2.5850e-02, -1.4246e-01,  1.2247e-01,\n",
      "         1.0489e-01,  1.7636e-01, -1.9918e-02,  2.7086e-01,  1.1989e-01,\n",
      "         3.2286e-01, -1.9351e-01,  5.8541e-02,  2.3863e-01,  1.5153e-01,\n",
      "         8.7618e-02, -1.7820e-01,  3.4503e-02, -1.2963e-01,  3.2500e-01,\n",
      "        -1.6073e-01, -1.2833e-01, -1.7822e-01, -1.6746e-01,  8.8169e-02,\n",
      "        -1.1419e-01,  1.2569e-01, -2.7392e-01,  3.3681e-01, -1.9802e-01,\n",
      "         1.1818e-01, -1.6436e-02, -6.0319e-02, -7.4947e-02,  7.3571e-02,\n",
      "        -5.0374e-02, -1.1688e-01, -5.3500e-02,  2.1505e-01, -4.1380e-01,\n",
      "         7.9682e-02, -1.3507e-01,  3.0444e-02, -1.7380e-02,  2.2797e-03,\n",
      "        -1.3878e-01, -1.9204e-01, -3.5653e-01, -1.3982e-01, -2.7241e-02,\n",
      "        -2.7884e-02, -2.7440e-01, -8.4746e-02, -1.2606e-01, -1.0253e-01,\n",
      "         3.4218e-01, -2.1857e-01,  1.0948e-01, -9.5236e-02, -3.5051e-01,\n",
      "         8.3217e-02,  2.4193e-02,  1.3334e-01, -1.5510e-01, -3.1771e-02,\n",
      "        -1.2744e-01, -1.2896e-01,  2.4917e-02,  1.1668e-01,  1.9382e-01,\n",
      "         2.1733e-01,  3.2032e-01, -2.2035e-01, -1.5690e-01,  3.0553e-01,\n",
      "         8.6525e-02, -2.2966e-01, -4.0272e-02,  3.6639e-05,  1.4360e-01,\n",
      "        -2.1480e-03,  1.7345e-01,  2.3102e-01, -7.8231e-02,  2.6349e-01,\n",
      "        -9.5431e-03,  2.1114e-01,  4.5274e-02,  3.3064e-01, -7.8475e-02,\n",
      "         5.7151e-02,  3.4173e-01,  1.7329e-01, -2.2461e-01, -2.3126e-01,\n",
      "        -3.9186e-02,  3.5847e-02, -2.1098e-01,  8.7273e-02,  2.8787e-02,\n",
      "         2.4707e-01,  9.2340e-02,  2.2928e-01, -2.5392e-02, -1.1907e-01,\n",
      "         2.6775e-01, -8.4903e-02, -3.1108e-01, -1.6755e-01, -3.3051e-02,\n",
      "        -1.6803e-01, -1.8032e-01, -1.1589e-01, -2.7006e-01, -1.1550e-01,\n",
      "         1.0406e-01, -2.5911e-01,  6.2868e-02,  1.9997e-02,  4.7422e-03,\n",
      "         1.9301e-01, -3.5847e-01,  1.3131e-01,  2.8150e-01, -2.2066e-02,\n",
      "        -4.4261e-02, -1.7197e-01,  3.2093e-01, -4.1421e-01, -2.1327e-02,\n",
      "        -3.8961e-01, -1.8825e-01, -9.6193e-03, -1.0584e-01, -1.0978e-01,\n",
      "         1.0694e-01,  3.2672e-01,  2.4498e-01,  5.1601e-01, -1.6834e-02,\n",
      "        -1.2425e-01,  2.6505e-02,  5.9536e-02, -1.9245e-01,  3.1963e-02,\n",
      "         9.2785e-02, -3.5873e-02, -1.2895e-02, -3.9343e-01, -4.5531e-01,\n",
      "         2.2171e-01,  2.1914e-03,  4.5584e-02,  4.0518e-01, -5.4186e-02,\n",
      "        -3.9569e-01, -1.0922e-01,  2.7514e-01,  1.8855e-01,  3.7035e-01,\n",
      "        -9.3184e-02,  4.5893e-02, -1.2226e-02,  5.7800e-02,  2.9207e-01,\n",
      "         2.0733e-01, -6.7453e-02, -2.3149e-01,  1.9775e-02, -6.8451e-02,\n",
      "         1.0082e-01,  3.1432e-01, -2.7448e-01, -4.0144e-01,  3.0866e-02,\n",
      "         1.5167e-01, -7.8782e-02, -4.5688e-01,  3.9019e-01, -3.5385e-03,\n",
      "         7.0092e-01,  5.0276e-02, -2.6343e-01, -3.3500e-01,  2.8511e-01,\n",
      "        -3.8385e-01, -3.3710e-01,  4.5034e-01, -2.6188e-01, -3.9126e-01,\n",
      "        -1.8151e-01,  1.1994e-01,  7.1899e-02,  1.1003e-01, -1.6816e-01,\n",
      "         2.2369e-01,  9.0867e-03,  3.2128e-01,  3.6735e-01,  3.0539e-01,\n",
      "        -7.5525e-02,  4.1609e-02,  1.5224e-02, -6.3055e-03, -1.1414e-02,\n",
      "         4.1525e-01, -2.1688e-01, -3.6087e-02,  1.2070e-01, -1.4570e-01,\n",
      "         6.5238e-03, -4.1248e-02])\n",
      "Embedding of the second token:         tensor([-0.3469,  0.0676,  0.2920, -0.5002,  0.7767, -0.9008,  0.2419, -0.2355,\n",
      "        -0.1814,  0.3286,  0.0168, -0.4332, -0.0317,  0.2354,  0.4144, -0.3866,\n",
      "        -0.6704,  0.0651,  0.5296,  0.4631,  0.1342,  0.1827, -0.0908, -0.1758,\n",
      "         0.0287, -0.4466, -0.4293, -0.2413,  0.0793, -0.1404,  0.2673, -0.0331,\n",
      "         0.1661,  0.3112,  0.0021, -0.6212,  0.3083,  0.3195,  0.3608, -0.3620,\n",
      "         0.0520,  0.0465, -0.0082,  0.2367, -0.1339, -0.3572, -0.0460,  0.1968,\n",
      "         0.1733,  0.1476,  0.2113,  0.3547, -0.1090,  0.3144, -0.2383,  0.6438,\n",
      "         0.8062, -0.5538,  0.2733,  0.1876,  1.1043,  0.4970,  0.5150, -0.0170,\n",
      "         0.0892, -0.1259, -0.0035, -0.0344, -0.6251,  0.4360, -0.2189, -0.2122,\n",
      "        -0.3479,  0.3714, -0.1287,  0.1722, -0.0804,  0.4114,  0.0770,  0.0308,\n",
      "         0.3067, -0.2237, -0.4316,  0.1690, -0.4286, -0.9510,  0.3575, -0.9092,\n",
      "         0.8333, -0.2733, -0.0945,  0.2007,  0.6551, -0.5425, -0.2923,  0.2309,\n",
      "        -0.0437, -0.2726, -0.1162, -0.3148, -0.4982, -0.4189, -0.4257, -0.5251,\n",
      "         0.1579, -0.7910, -0.1615, -0.3701, -0.1188,  0.0172, -0.7701, -0.3344,\n",
      "        -0.3457,  0.2463,  0.2026, -0.1100, -0.1224,  0.2888,  0.3644, -0.3554,\n",
      "         0.4036,  0.6660, -0.5090,  0.0904,  0.2652,  0.2815, -0.1120, -0.1971,\n",
      "         0.0585, -0.1271, -0.1230, -0.5157,  0.1622,  0.8612,  0.5240, -0.0867,\n",
      "        -1.1714, -0.1664,  0.4006, -0.0168,  0.5157, -0.3241,  0.1384,  0.2291,\n",
      "         0.5040,  0.2175,  0.1145,  0.3384,  0.3828,  0.6251,  0.5943,  0.3804,\n",
      "         0.0135, -0.4189,  0.3100, -0.3140,  0.1281,  0.0928,  0.1984, -0.1454,\n",
      "         0.1936, -0.8756,  0.6328, -0.3388,  1.2295,  0.2617, -0.1528, -0.1474,\n",
      "        -0.5219,  0.4308,  0.7229,  0.4932,  0.1197,  0.3975, -0.4104,  0.7339,\n",
      "        -0.0955, -0.6964, -0.3557, -0.1201, -0.0190, -0.0272, -0.0783, -0.4985,\n",
      "        -0.6304, -0.0462, -0.7037,  0.2303, -0.2164, -0.6499, -0.0423,  0.6905,\n",
      "         0.0593,  0.1021, -0.0716, -0.8309, -0.0236, -0.2060, -0.2387,  0.2699,\n",
      "         0.3062, -0.4156, -0.2746, -1.1875,  0.0142,  0.5188, -0.2115, -0.1864,\n",
      "         0.8399, -0.0551,  0.4295,  0.1095,  1.1475, -0.5400,  0.4364, -0.5814,\n",
      "        -0.1868,  0.0917,  0.5270,  0.5797, -0.2036, -0.5952, -0.0116, -0.4306,\n",
      "         0.0300, -0.4887,  0.2112, -0.2127,  0.0175,  0.3924,  0.2370, -0.0851,\n",
      "        -0.2718,  0.7045, -0.3775, -0.0934, -0.4460, -0.3511, -0.0069, -0.4998,\n",
      "         0.2737, -0.1745, -0.1995,  0.2957,  0.3633,  0.1828, -0.1465,  0.4755,\n",
      "        -0.2828, -0.1703,  0.7316,  0.2707, -0.2032, -0.5346, -0.7999,  0.2289,\n",
      "        -0.6584,  0.3030, -0.7075, -0.5926, -0.4754,  0.2600,  0.0950, -0.6159,\n",
      "        -0.1297, -0.2706,  0.2338,  0.4759, -0.4677,  0.3031, -0.2260, -0.8013,\n",
      "        -0.3036,  0.2001, -0.7093,  0.5536, -0.4994, -0.3517, -0.2927, -0.5119,\n",
      "        -0.0515,  0.3982,  0.0471, -0.2502,  0.0570,  0.3561,  0.0571,  0.1230,\n",
      "         0.5299, -0.4715,  0.3391, -0.2867,  0.5172, -0.6776, -0.6060, -0.3624,\n",
      "         0.1543,  0.6476, -0.5701,  0.4806, -0.0853,  0.4818, -0.0228, -0.5472,\n",
      "         0.1549, -0.0961,  0.3589, -0.4936,  0.2601, -0.1282, -0.0610, -0.2390,\n",
      "        -0.2384,  0.0997,  0.0917,  0.4865, -0.2874,  0.5119, -0.5767, -0.0943,\n",
      "         0.2113, -0.0805, -0.3695,  0.0766,  0.2972,  0.4166, -0.2436, -0.6838,\n",
      "        -0.3590,  0.3658, -0.3697, -0.5932,  0.0286,  0.2904, -0.8370, -0.6783,\n",
      "        -0.2997,  0.3980,  0.1155, -0.4252, -0.8151,  0.1703,  0.1389,  0.1752,\n",
      "         0.3643, -0.2068, -0.2050, -0.4425,  0.3497, -0.3480, -0.0745, -0.1984,\n",
      "         0.3492, -0.7728, -0.5656,  0.4356,  0.4792, -0.0229, -0.0941, -0.0186,\n",
      "        -0.4857,  0.1903,  0.2901, -0.4335, -0.0385, -0.0745,  0.1814,  0.2202,\n",
      "        -0.0950,  0.1873,  0.4130,  0.4355, -0.0488, -0.7661,  0.3951,  0.7281,\n",
      "        -0.7628, -0.5893, -0.4123, -0.1902,  0.6947,  0.2751,  0.3844, -0.3987,\n",
      "         0.9224, -0.4019, -0.0656,  0.0763,  0.5347, -0.1967,  0.1986,  0.9248,\n",
      "         1.1375, -0.6969,  0.1604,  0.0457,  0.2358,  0.0977, -0.1480, -0.1763,\n",
      "         0.1533, -0.2250, -0.4700,  0.1557, -0.5988,  0.2091, -0.0121, -0.8547,\n",
      "        -0.5809, -0.3051, -0.2018, -0.4334, -0.3659, -0.0786, -0.5292,  0.2270,\n",
      "        -0.6211, -0.1883,  0.3341, -0.4942,  0.5829, -0.3673, -0.5281,  0.4560,\n",
      "        -0.1616,  0.5754, -0.1892, -0.1253, -0.2302, -0.1566,  0.0106, -0.3944,\n",
      "        -0.6738,  0.0839, -0.1305,  0.0973, -0.2500,  0.3967,  0.7505, -0.5102,\n",
      "        -0.3909, -0.5869, -0.0271, -0.2274, -0.0879, -0.3385, -0.5280,  0.6582,\n",
      "        -0.5126, -0.6393, -0.1669,  0.3135,  0.3865,  0.6810,  0.0296, -0.0826,\n",
      "         0.5543,  0.0821, -0.3050, -0.0143, -0.4426,  0.4875, -0.3707, -0.6304,\n",
      "         0.4387,  0.2576,  0.5348, -0.2654, -0.0259, -0.2420, -0.4128, -0.0034,\n",
      "        -1.2858, -0.6336,  0.6562,  0.0269, -0.5494, -0.7374,  0.6519, -0.0224,\n",
      "         0.9157, -0.1824, -0.6402, -0.7269,  0.7041, -0.7598, -0.2396,  0.6658,\n",
      "        -0.0066, -0.5949, -0.0722, -0.1237,  0.1080, -0.2252, -0.2095,  0.1222,\n",
      "        -0.1600, -0.1601,  0.9281,  0.6495, -0.5046, -0.0995, -0.5764,  0.2486,\n",
      "         0.0432,  0.0576, -0.0399,  0.0739,  0.2286, -0.0849,  0.6853,  0.7350])\n",
      "Embedding of the third token:          tensor([ 0.3331, -0.2620, -0.3063, -0.5439,  0.8106, -0.4460,  1.0239, -0.6775,\n",
      "        -0.4734, -0.5606, -0.3795, -0.1544, -0.3464, -0.8751, -0.5137,  0.1951,\n",
      "         0.0213, -0.6724,  0.0666, -0.4933,  0.6685,  0.0364,  0.2395,  0.1205,\n",
      "        -0.1533, -0.0316, -0.0341,  0.5771, -0.3612,  0.4541,  0.3556,  0.0157,\n",
      "         1.1209,  0.1963,  0.2112, -0.5041,  0.2594, -0.0656,  0.3035, -0.6089,\n",
      "         0.0758, -0.4115,  0.1515, -0.2266,  0.2931, -0.7615,  0.0069,  0.5591,\n",
      "         0.3641, -0.3545, -0.0189, -0.5971, -0.0730,  0.0633, -0.5460,  0.0995,\n",
      "        -0.6591, -0.4547, -0.0869, -0.2660,  0.5757,  0.7158,  0.1510, -0.5002,\n",
      "        -0.0524, -0.2304,  0.1845, -0.3542,  0.1543, -0.0710,  0.5154,  1.0097,\n",
      "        -0.1523, -0.1009,  0.8945, -0.1043, -0.0835,  0.2364,  0.3929, -0.3225,\n",
      "        -0.2808, -0.0475, -0.2264,  1.0498, -0.2833,  0.1256, -0.0264, -0.0516,\n",
      "         0.6142,  0.5408, -0.1407,  0.4647,  0.5439, -0.4959, -0.3515, -0.0633,\n",
      "        -0.6112, -0.4391, -0.1610, -0.1392, -0.6934,  0.1987, -0.1883, -0.2487,\n",
      "         0.2530, -0.2703,  0.0961, -0.1240,  0.4625,  0.2580, -0.7035, -0.2144,\n",
      "         0.2286, -0.0114, -0.2783, -0.6601, -0.0240,  0.3302,  0.3343,  0.1939,\n",
      "         0.2161,  0.0833, -0.7662, -0.5521, -0.2194, -0.3101,  0.8647, -0.1874,\n",
      "        -0.1513, -0.5095, -0.3232, -0.0719,  0.0658,  0.3446, -0.6260,  0.0280,\n",
      "        -0.2457, -0.6825,  0.4528, -0.0144,  0.2911, -0.6128,  0.0694, -0.4801,\n",
      "         0.5754,  0.0126, -0.2084,  0.7834,  0.0980, -0.1105,  0.0055,  0.7244,\n",
      "         0.5433, -0.3520, -0.1667,  0.6089,  0.9216,  0.4707,  0.4225, -0.2153,\n",
      "        -0.7032, -0.2076, -0.3525,  0.0307,  0.5283, -0.4214,  0.0522, -0.0416,\n",
      "        -0.7793, -0.5933, -0.3718,  1.2716,  0.0487, -0.3561, -0.3261,  0.7382,\n",
      "        -0.4508, -0.2626,  0.1532, -0.1941,  0.2061, -0.5317,  0.0261, -0.5156,\n",
      "        -0.8815,  0.5057, -0.1631, -0.2799,  0.3800,  0.3446,  0.4959,  0.6540,\n",
      "        -0.0427,  0.2100, -0.1214, -0.5776,  0.4401, -0.0130,  0.2312,  0.1966,\n",
      "         0.9126,  0.1927,  0.0515, -0.3712, -0.1628, -0.1941, -0.4149, -0.1727,\n",
      "         0.1532, -0.4074,  0.0277,  1.0066, -0.1065, -0.0537,  0.2684, -0.3354,\n",
      "         0.2712, -0.2990,  0.4885, -0.1801, -0.6239, -0.0439,  0.4698, -0.5002,\n",
      "        -0.0683,  0.6168,  0.2656, -0.0071,  0.0150, -0.1124, -0.4586, -0.2400,\n",
      "        -0.1953,  0.6174, -0.3787,  0.3311, -0.3980,  0.2271, -0.3037,  0.2817,\n",
      "        -0.1474, -0.2255, -0.5001, -0.3096,  0.0894,  0.5421, -0.1089, -0.6424,\n",
      "         0.0580, -0.1203,  0.1222,  0.7457,  0.0418, -0.6495, -0.1687, -0.2811,\n",
      "        -0.7522,  0.3527, -0.4241, -0.7004, -0.5621, -0.3011,  0.5176,  0.0108,\n",
      "         0.5358, -0.5472,  0.8274,  0.0959, -0.3284,  0.0293, -0.0163, -0.5545,\n",
      "         0.5192,  0.1233, -0.4879, -0.6926, -0.4156,  0.2635, -0.4502, -0.0656,\n",
      "        -0.2131, -0.0268, -0.5123, -0.8367,  0.3606, -0.4018,  0.4246,  0.3756,\n",
      "        -0.1113, -0.1386,  0.0658, -0.2037,  0.1330, -0.8612,  0.2820, -0.0561,\n",
      "         0.0118,  0.2379, -0.3212,  0.7229, -0.0806, -0.5222,  0.1934,  0.2042,\n",
      "         0.0695, -0.1040, -0.0668,  0.3854, -0.1953,  0.3257,  0.3393, -0.4048,\n",
      "         0.0074,  0.2307,  0.9652, -0.2604, -0.6872,  0.6596,  0.2264,  0.3557,\n",
      "        -0.9440, -0.0184, -0.3526, -0.4125, -0.1959, -0.8787,  0.2339,  0.2365,\n",
      "         0.6923, -0.5813,  0.1975,  0.5842,  0.2069, -0.5515,  0.5526, -0.7294,\n",
      "        -0.3563, -0.7417, -0.2674, -1.0351, -0.0739,  0.4488, -0.0061,  0.1699,\n",
      "        -0.1696, -0.9579, -0.4783, -0.4755, -0.2853,  0.0737, -0.5087, -0.1490,\n",
      "        -0.8204, -0.4560,  0.3135,  1.1205,  0.1392,  0.0845,  0.2417, -0.1143,\n",
      "        -0.3269,  0.1323, -0.2460, -0.7989, -0.6591,  0.3644, -0.7646, -0.2693,\n",
      "        -0.1076,  0.1995,  0.4647,  0.6372, -0.3102,  0.1171,  0.6310, -0.2128,\n",
      "        -0.5902, -0.1747, -0.4125, -0.6306, -0.3171,  0.1489,  0.1701,  0.4692,\n",
      "         0.3772,  0.0372,  0.9656, -0.3417,  0.8213, -0.5035, -0.6291,  0.4913,\n",
      "         0.3061, -0.1256, -0.2568,  0.1345, -1.1085, -0.3577, -0.1250,  0.0027,\n",
      "         0.9355,  0.1850, -0.6219, -0.6595,  0.4012,  0.8228, -0.0126,  0.8176,\n",
      "        -0.3083, -0.0217,  0.0316, -0.6498,  0.3061, -0.4961,  0.2898,  0.1267,\n",
      "        -0.4188, -0.2416, -0.1918,  0.4386,  0.3444, -0.1187,  0.1336,  0.4606,\n",
      "        -0.1912, -0.1160,  0.1509,  0.4231, -0.8350,  0.2926,  0.2277, -0.1501,\n",
      "         0.4754, -0.2172,  0.1880, -0.2701,  0.2190,  0.5155,  0.0900,  0.2422,\n",
      "        -0.5339,  0.1440, -0.2519,  0.0800,  0.0864, -0.1673, -0.3816, -0.2752,\n",
      "        -0.3093, -0.3974, -0.2039, -0.4161, -0.0754,  0.7653,  0.0094, -0.7052,\n",
      "         0.0299, -0.1890,  0.1190,  0.5422,  0.2352,  0.1791, -0.2142,  0.8668,\n",
      "         1.0497,  0.3273,  0.0172, -0.0258, -0.3256,  0.4954,  0.9494,  0.4798,\n",
      "        -0.6083, -0.4803,  0.4568,  0.5727, -0.3947, -0.7241, -0.0334, -0.0058,\n",
      "         0.7818, -0.2235, -0.1147,  0.0482,  0.6321,  0.1422, -0.6277,  0.0937,\n",
      "        -0.8542, -0.4716, -0.5613, -0.0273,  0.7190, -0.2274, -0.5217, -0.1899,\n",
      "         0.3168,  0.2987, -0.1376,  0.9553, -0.1156, -0.0685,  0.0290, -0.0856,\n",
      "         0.0778, -0.0777, -0.3529,  0.6018,  0.7136, -0.5033, -0.3459,  0.6840])\n",
      "Embedding of the fourth token:         tensor([-2.3612e-01, -1.8942e-01,  5.3950e-02, -6.2365e-01, -2.3148e-01,\n",
      "        -9.9448e-01,  9.4195e-01, -1.8332e-01,  3.7333e-02, -4.4000e-02,\n",
      "        -4.8188e-01, -3.2986e-01, -1.7622e-02, -3.1655e-01, -3.8145e-01,\n",
      "        -3.0411e-02, -7.9571e-01,  2.1917e-01,  1.3038e-01,  1.5951e-02,\n",
      "        -8.6027e-02, -7.9237e-02, -1.7374e-02, -8.0302e-03,  5.4692e-02,\n",
      "        -2.6634e-01, -4.7464e-01,  4.9183e-01, -3.1783e-01,  6.5485e-02,\n",
      "        -2.2099e-01,  3.7033e-02,  3.3136e-01, -1.8262e-01,  4.8159e-01,\n",
      "        -5.9304e-01,  3.2286e-01,  8.1917e-02,  7.5661e-02, -1.6478e-01,\n",
      "         2.1804e-01, -4.1819e-02, -2.1919e-01, -6.3573e-02, -7.1458e-02,\n",
      "         2.9954e-01, -1.1784e-01,  1.6410e-01,  1.1527e-01, -2.9021e-01,\n",
      "         3.0821e-01, -1.3829e-01,  1.4537e-01, -2.9233e-01, -3.9539e-01,\n",
      "         3.2309e-01, -1.3407e-01, -4.5807e-01, -1.1021e-01,  3.3921e-01,\n",
      "         1.8619e-02,  4.2482e-01,  1.5214e-01, -1.8999e-01,  1.9527e-02,\n",
      "        -3.3814e-01, -5.9186e-01, -5.9487e-01, -4.3428e-02, -8.2150e-02,\n",
      "        -2.3700e-01,  5.1430e-01,  1.5343e-01,  5.3241e-02, -2.1566e-01,\n",
      "        -2.9733e-01,  2.2224e-01,  5.0850e-01,  1.0039e-01, -6.4851e-01,\n",
      "         1.4747e-01, -2.2359e-01, -1.6699e-01,  1.3596e-01,  1.1596e-02,\n",
      "         2.3212e-01,  5.1456e-01,  1.3598e-01,  1.3279e-01,  1.3865e-01,\n",
      "         1.0850e-01,  1.4317e-02,  1.2502e-01, -8.2380e-01,  3.5883e-02,\n",
      "         3.9454e-01, -3.7468e-01, -5.9672e-02, -4.3821e-01, -3.0587e-01,\n",
      "        -5.7169e-01, -1.4618e-01, -3.4006e-02, -1.6739e-01,  3.8306e-01,\n",
      "        -5.1185e-01,  4.5700e-01, -1.9102e-01, -3.0691e-01,  3.0258e-01,\n",
      "        -7.6415e-01, -6.6102e-01, -1.5515e-01,  3.2676e-01,  7.0205e-02,\n",
      "        -2.6790e-01, -3.5332e-01,  2.0327e-01,  5.7843e-01,  2.4578e-01,\n",
      "         2.6567e-01,  2.2850e-01, -1.4730e-01,  8.9715e-02,  2.6186e-01,\n",
      "        -9.3738e-02,  4.2928e-02,  1.9609e-01, -1.0088e-01,  3.1883e-03,\n",
      "         3.0351e-01, -5.2520e-01,  4.7698e-01, -2.7404e-01,  2.6831e-01,\n",
      "         1.4763e-01, -4.2746e-01, -1.9409e-01,  3.4930e-01, -1.7383e-01,\n",
      "         7.6204e-02, -4.9636e-01,  4.8407e-01,  2.0949e-01,  1.9890e-01,\n",
      "         4.9123e-01,  3.9593e-01,  5.8943e-01,  3.5141e-01, -4.6505e-01,\n",
      "         1.1314e-01,  9.1550e-02, -2.1617e-01, -2.3173e-01, -1.8956e-01,\n",
      "         4.7205e-02,  4.0743e-02,  7.1442e-02, -1.9793e-01, -4.6918e-01,\n",
      "        -4.2462e-01, -3.3880e-01,  3.7865e-01,  1.5319e-01,  4.5409e-01,\n",
      "        -6.9070e-02,  6.9761e-02,  3.9800e-01, -4.5817e-01, -4.7889e-01,\n",
      "         2.7272e-01,  5.7595e-01,  4.4710e-01, -1.2855e-01, -1.9523e-01,\n",
      "        -9.3700e-02, -5.7226e-01, -3.6688e-01,  1.2549e-01,  7.1780e-02,\n",
      "        -2.2806e-01,  1.7524e-03,  5.7712e-01, -6.1080e-01, -3.8635e-01,\n",
      "         4.5638e-02,  4.2222e-01, -2.9230e-01, -2.0557e-01, -3.5527e-01,\n",
      "         3.1229e-01,  2.0803e-01, -3.2425e-01,  9.4215e-02, -3.8129e-04,\n",
      "        -2.2672e-01,  3.4439e-01,  2.8179e-01,  7.8637e-02, -1.0421e-01,\n",
      "         5.3450e-01,  1.9820e-01, -1.9832e-01, -3.1363e-01,  4.2476e-01,\n",
      "         7.2282e-02, -5.2482e-01,  8.8971e-02,  5.2961e-01,  1.0714e-01,\n",
      "         4.2281e-01,  1.7776e-01, -3.2822e-02, -5.3771e-01,  2.3683e-01,\n",
      "        -1.6456e-01, -1.2543e-01,  1.0455e-01,  3.1772e-01, -2.0409e-03,\n",
      "         5.6017e-02,  2.6980e-03,  4.2910e-04, -1.3696e-01,  1.0648e-01,\n",
      "        -3.9401e-01, -1.1648e-01,  3.3896e-01,  1.4735e-01,  3.9615e-01,\n",
      "         1.9727e-02,  1.9707e-01, -1.2013e-01,  8.7218e-02, -4.0701e-01,\n",
      "        -3.0893e-02, -1.0775e-01, -1.4964e-01, -1.6832e-01,  4.4353e-01,\n",
      "        -1.6435e-01, -2.1350e-01, -1.0646e-01,  2.7356e-01, -2.2307e-03,\n",
      "        -1.3851e-01, -6.0612e-01,  2.8105e-01, -6.1041e-02, -4.6253e-01,\n",
      "        -1.9870e-01, -3.7073e-01,  1.9520e-02, -3.3832e-01, -1.0951e-01,\n",
      "         2.8885e-01,  3.0532e-01, -1.7244e-01,  4.9248e-02, -6.4885e-01,\n",
      "        -1.2633e-01, -2.5026e-01,  3.2654e-01,  3.6494e-02,  9.7247e-02,\n",
      "        -3.1264e-01,  1.1885e-01,  2.7275e-01, -2.4235e-01,  9.4643e-02,\n",
      "         2.9588e-01, -5.7868e-01,  3.0859e-01,  2.8543e-01,  2.8855e-01,\n",
      "        -1.4769e-01,  1.8235e-01,  1.8908e-01, -2.2347e-01, -5.1766e-01,\n",
      "         6.4412e-02, -5.1274e-01, -1.8640e-01,  5.6707e-01,  1.7794e-02,\n",
      "        -2.9587e-01,  1.1681e-01,  3.6603e-01,  6.2482e-02, -6.4384e-01,\n",
      "         1.7928e-02,  1.1538e-01,  3.9431e-01, -7.1984e-01,  5.0264e-01,\n",
      "         2.3489e-01, -9.1409e-02,  3.0969e-01, -1.2950e-01, -3.1255e-01,\n",
      "         4.3394e-01,  2.9957e-01,  1.1476e-01,  7.0993e-02,  2.5026e-02,\n",
      "        -9.1863e-02,  4.4275e-01,  1.0854e-01,  2.0187e-01, -1.2399e-03,\n",
      "         5.7614e-01, -5.1287e-02,  3.5876e-01,  4.0109e-01,  7.5093e-02,\n",
      "        -2.6580e-01, -3.6926e-01,  5.5107e-01, -4.6667e-01,  1.2459e-01,\n",
      "        -1.6389e-01, -1.2550e-01, -1.0540e-01, -4.0448e-01,  3.5873e-02,\n",
      "        -1.6957e-01,  2.2560e-02,  2.1133e-01, -3.3195e-02, -9.8663e-02,\n",
      "         5.3579e-02, -4.1971e-02, -2.0120e-01,  1.3073e-01,  1.1372e-01,\n",
      "         3.4796e-01, -7.4880e-01,  3.9749e-02,  4.4876e-01, -4.0800e-01,\n",
      "         2.9097e-01, -2.4966e-02, -1.0659e-01, -2.0717e-02, -3.3239e-01,\n",
      "        -3.4934e-01, -1.5817e-02, -7.5289e-01, -2.1893e-01,  2.4843e-01,\n",
      "         3.3365e-01, -1.2591e-01,  2.8731e-01,  1.2711e-01,  1.2512e-01,\n",
      "         5.5414e-01, -2.0887e-01, -6.4136e-02, -4.1304e-01, -6.1288e-01,\n",
      "        -6.3049e-02,  4.9010e-02,  4.5016e-02, -1.7453e-01,  1.9864e-01,\n",
      "        -2.2297e-01,  1.5721e-01,  2.4619e-01, -3.0447e-02,  5.5250e-02,\n",
      "        -7.4040e-02, -2.0243e-01, -3.8133e-01, -3.9808e-01,  1.0297e-01,\n",
      "         1.3639e-02, -3.0427e-01,  3.8257e-01, -1.1167e-01,  7.8346e-02,\n",
      "         7.5485e-03,  2.8276e-01,  8.4183e-01, -6.4050e-02,  4.9021e-01,\n",
      "         2.8116e-01,  1.3975e-01,  4.0766e-01,  1.7529e-01,  4.0071e-02,\n",
      "        -1.1481e-01,  5.7538e-02,  1.9763e-01, -6.7492e-01,  4.2668e-02,\n",
      "        -1.7170e-01,  3.8572e-01, -2.0391e-01,  2.0045e-01, -2.2275e-01,\n",
      "         4.2087e-01,  7.4726e-02,  3.0045e-01,  2.3292e-01, -9.0567e-02,\n",
      "         7.4276e-01,  2.3301e-01, -2.1850e-01, -6.2267e-01,  6.5710e-02,\n",
      "         1.0704e-01, -6.6616e-02,  2.2800e-01, -3.1646e-02, -3.2205e-01,\n",
      "         3.8414e-01, -3.8999e-01,  1.5362e-01,  1.8878e-01,  2.3556e-01,\n",
      "         2.4032e-01, -4.7375e-01, -3.9769e-02,  7.0354e-01,  3.5769e-01,\n",
      "         3.4411e-01, -5.8001e-02,  3.3535e-01, -6.6371e-01, -1.2277e-01,\n",
      "         3.5330e-02, -3.7649e-01,  2.4173e-01, -5.3192e-01, -6.2533e-01,\n",
      "        -4.6472e-02,  3.7009e-01,  3.2136e-01,  7.2270e-01, -2.5761e-02,\n",
      "        -1.7400e-01,  1.1991e-01, -3.0944e-01, -1.5370e-01,  2.1295e-01,\n",
      "        -1.5385e-01, -2.5248e-01, -3.8098e-02, -5.4895e-01, -8.8825e-01,\n",
      "         1.7136e-01,  4.9291e-01,  3.5882e-01,  1.0463e-01, -2.9504e-01,\n",
      "        -6.4014e-01, -2.4630e-01,  3.2595e-01,  4.7254e-02, -1.1460e-01,\n",
      "        -1.4440e-01,  2.7160e-01,  1.3647e-01,  9.4767e-03,  1.7150e-01,\n",
      "         1.8989e-01,  1.0130e-01, -4.8114e-01, -2.4605e-01, -4.2095e-01,\n",
      "         9.5732e-02, -7.3388e-02,  1.4776e-01, -3.5995e-01, -2.6694e-02,\n",
      "         3.1305e-01, -3.8268e-01, -3.3334e-01,  9.9196e-03, -4.0838e-01,\n",
      "         1.3626e-01,  1.0704e-01, -1.6161e-01, -2.6829e-01,  4.4456e-01,\n",
      "        -2.2477e-01, -2.5188e-01,  3.7629e-01,  1.0065e-01,  3.3116e-02,\n",
      "        -3.9075e-02,  1.5545e-01,  1.6138e-01,  9.0295e-03,  9.3665e-02,\n",
      "        -1.5335e-02,  3.1135e-01, -1.8291e-01,  8.1895e-01,  3.0505e-01,\n",
      "        -1.8019e-01, -1.3208e-01, -1.7643e-01, -4.5036e-03, -3.1228e-01,\n",
      "         4.4814e-01,  3.4694e-01,  8.2748e-02,  2.8009e-01, -6.1785e-02,\n",
      "         2.6555e-01, -1.0731e-01])\n",
      "Embedding of the fifth token:          tensor([ 6.5353e-03,  1.0530e-01,  2.0694e-01, -2.8327e-01,  3.8333e-02,\n",
      "        -6.5962e-01,  5.8342e-01,  1.5648e-01, -1.4024e-01,  1.3889e-01,\n",
      "        -2.7393e-01, -2.6412e-01, -2.2530e-02, -1.3766e-01, -3.3079e-01,\n",
      "        -1.2314e-02, -6.0573e-01, -1.8378e-01, -9.2155e-02,  2.9450e-01,\n",
      "        -6.5520e-02, -2.5540e-01, -1.5659e-01, -9.5264e-02, -4.9506e-02,\n",
      "        -1.9102e-01,  1.2348e-01,  4.2129e-01, -6.2711e-02,  2.6615e-01,\n",
      "        -1.6393e-01,  6.3226e-02,  2.3958e-01,  4.5401e-02, -1.8763e-01,\n",
      "        -2.4649e-01, -1.7720e-01, -1.1588e-01,  1.5835e-01,  7.2457e-02,\n",
      "        -1.4719e-01, -2.0871e-03, -2.4871e-01,  3.9449e-01,  2.3077e-02,\n",
      "        -1.7890e-01, -3.3120e-01, -1.1063e-01,  1.9404e-01, -1.8189e-01,\n",
      "         3.6442e-01,  1.0741e-01, -2.6766e-01, -3.0482e-01, -2.8682e-01,\n",
      "         1.8597e-02,  2.4410e-01, -2.2239e-01, -8.1524e-02,  1.4830e-01,\n",
      "         1.1611e-01,  5.3671e-01,  6.1772e-02,  4.8027e-02, -1.0724e-01,\n",
      "         2.0951e-01, -1.1897e-01, -2.6693e-01, -3.3617e-02, -2.5043e-02,\n",
      "        -1.0738e-01,  5.6707e-02, -6.4886e-02,  4.0177e-01,  1.5906e-02,\n",
      "         2.2814e-01,  1.5764e-02,  1.7893e-01,  3.8642e-02, -3.0460e-01,\n",
      "        -6.1610e-02,  2.2828e-01,  1.0192e-01,  2.9203e-01, -1.1477e-02,\n",
      "         4.7556e-01, -1.2861e-01,  1.3266e-01, -1.0355e-01,  4.8470e-01,\n",
      "        -3.1390e-02, -3.9748e-01, -1.2747e-01, -2.3307e-01,  2.1445e-01,\n",
      "         1.6783e-01, -1.8124e-01, -1.0606e-01, -3.4613e-01, -2.4870e-01,\n",
      "        -3.1852e-01,  8.1227e-02,  3.2381e-01, -2.1372e-01,  2.7977e-01,\n",
      "        -4.1864e-01,  3.0652e-01, -1.0629e-03, -3.4127e-03,  6.1509e-02,\n",
      "        -5.5688e-01, -3.8640e-01,  3.2454e-01, -9.9492e-02,  2.5456e-02,\n",
      "        -1.5857e-01, -1.1711e-02, -1.4081e-01,  4.0028e-01, -1.7234e-01,\n",
      "        -6.7671e-02,  1.6670e-01, -4.2900e-02,  5.3827e-03,  6.5357e-02,\n",
      "         1.3464e-01,  3.5174e-01, -5.1641e-02, -4.5528e-01,  1.1010e-01,\n",
      "         5.7050e-01, -4.5795e-01,  3.9706e-01,  1.5094e-01, -4.1333e-02,\n",
      "        -1.9631e-01, -1.9982e-01, -2.3572e-01,  2.1976e-01,  8.1949e-04,\n",
      "         2.7487e-01, -1.9977e-01,  1.5517e-01,  1.7528e-01,  3.0903e-02,\n",
      "         1.0288e-01,  1.3336e-01,  3.9422e-01,  3.2791e-01, -4.3589e-02,\n",
      "        -4.1839e-02, -1.8083e-03,  1.8013e-01, -1.7211e-01,  3.2659e-01,\n",
      "        -1.8237e-01, -1.2356e-01,  8.2543e-02,  3.2095e-01, -3.7693e-01,\n",
      "        -9.8445e-02, -4.1347e-01,  4.7000e-02,  1.1310e-01,  2.4411e-01,\n",
      "        -3.0770e-01,  1.5861e-01, -8.3637e-02, -4.4800e-01, -1.5277e-01,\n",
      "         1.0772e-01,  5.9898e-01,  4.6290e-01,  2.9650e-01, -2.9010e-01,\n",
      "         3.4341e-01, -4.4880e-01, -9.3115e-02, -1.7506e-01, -1.9143e-01,\n",
      "        -2.6586e-01, -6.0086e-03, -3.7469e-02, -1.5456e-01, -3.2778e-01,\n",
      "         3.7411e-01,  9.3874e-02, -1.3589e-01,  1.0658e-01, -2.4925e-02,\n",
      "         7.4583e-02, -6.0890e-03, -1.1567e-01,  5.9551e-01,  1.9921e-02,\n",
      "        -3.9064e-01,  8.9530e-02,  1.5019e-01,  2.6147e-01, -2.2074e-01,\n",
      "         2.7997e-01, -1.2289e-01, -3.0710e-01, -3.4052e-01, -2.6620e-01,\n",
      "        -4.3599e-02, -2.4006e-01,  8.2609e-02,  1.9431e-01, -4.0131e-01,\n",
      "         3.1820e-01, -1.5857e-01,  8.7313e-02, -9.1381e-02,  2.3675e-01,\n",
      "        -4.9302e-01,  2.3549e-01,  1.6526e-01,  3.1106e-01,  1.9320e-01,\n",
      "         1.9493e-01, -2.9868e-02,  9.9630e-02, -2.5611e-01,  2.0167e-01,\n",
      "        -4.9769e-01, -7.4745e-02,  7.4257e-02,  1.0974e-01,  3.0368e-01,\n",
      "         1.2012e-01,  2.2523e-01, -3.1590e-01,  6.6861e-01, -3.9270e-01,\n",
      "         3.1000e-01, -5.4359e-01, -1.5069e-01,  1.3563e-01,  9.8366e-02,\n",
      "        -2.6072e-01, -3.6909e-01,  7.6112e-02,  2.9544e-01, -2.3780e-01,\n",
      "         2.3711e-01, -3.7170e-01, -1.0412e-01, -1.5040e-01, -2.0976e-01,\n",
      "        -1.8511e-01, -3.8705e-01,  1.7739e-01, -2.2011e-01, -1.5035e-01,\n",
      "        -1.5324e-02, -9.4920e-02,  8.6627e-02, -1.5843e-01, -4.0303e-01,\n",
      "         6.1643e-02, -3.6164e-02, -6.2834e-02,  3.1023e-02,  1.4721e-01,\n",
      "        -1.2282e-01,  1.8248e-01,  1.0860e-01,  9.7682e-02,  4.1257e-01,\n",
      "        -2.5741e-01, -6.5022e-01,  7.7702e-03,  4.6730e-02, -1.3709e-01,\n",
      "        -7.0805e-02,  2.3759e-02,  3.5226e-01, -3.8639e-03, -1.8925e-01,\n",
      "        -6.7740e-02,  1.3800e-01, -2.7615e-01,  5.3746e-02,  4.6807e-01,\n",
      "        -1.9535e-01, -1.3860e-01,  3.3421e-01,  3.7621e-01, -1.6431e-01,\n",
      "        -2.8149e-01, -3.6592e-02,  4.0777e-01, -2.4396e-01,  1.2129e-01,\n",
      "         4.5567e-01, -2.0012e-01,  1.3598e-01, -5.3490e-02,  2.3637e-01,\n",
      "         1.4584e-01,  2.3732e-01, -6.1074e-02,  1.0254e-01, -1.1382e-01,\n",
      "         1.9575e-02,  1.8199e-01, -1.3274e-01,  2.3795e-01,  1.3064e-01,\n",
      "         6.7151e-01, -5.0775e-01,  4.6278e-01,  4.6146e-01,  1.2195e-01,\n",
      "        -1.3172e-01, -2.8987e-01,  6.0855e-01,  1.1229e-01,  3.0321e-01,\n",
      "        -3.9474e-01, -3.2719e-02, -2.7978e-01, -3.0640e-01,  2.1386e-01,\n",
      "        -8.3771e-02,  1.5414e-01, -3.3903e-01,  4.3478e-01, -3.9662e-01,\n",
      "         1.2011e-03,  5.2856e-02, -3.2616e-01,  3.8401e-02, -2.9339e-01,\n",
      "        -2.1435e-01, -1.5309e-01,  2.0165e-01,  5.0021e-01, -1.7775e-01,\n",
      "         2.4552e-01, -4.8510e-02, -2.3090e-01,  1.0587e-01,  1.5288e-01,\n",
      "        -1.3510e-01, -2.0533e-01, -7.7409e-01, -2.6870e-01,  3.1719e-02,\n",
      "         1.4259e-01,  9.6814e-02,  8.3990e-02,  1.9653e-01, -2.2477e-01,\n",
      "         8.2862e-01,  2.0101e-01,  1.3356e-01, -4.7264e-01, -1.1754e-01,\n",
      "        -3.2035e-01,  2.7893e-01,  1.4213e-01, -3.1031e-01, -3.0311e-01,\n",
      "        -3.4970e-01, -4.1018e-01,  3.5237e-01,  1.5555e-01,  3.5677e-01,\n",
      "         2.5926e-01,  9.6389e-02,  3.3509e-03, -3.9559e-01, -1.2689e-01,\n",
      "         1.5994e-01, -5.5636e-01, -3.7270e-01,  9.9115e-02,  1.8943e-01,\n",
      "         2.1483e-01,  4.4472e-01,  7.3921e-01, -2.6421e-01,  2.0046e-01,\n",
      "        -2.0475e-01,  5.3294e-02, -2.3534e-01,  4.1254e-01, -2.3580e-01,\n",
      "        -5.2034e-02,  2.5387e-01,  2.5212e-01, -3.3181e-01,  5.3497e-03,\n",
      "         3.4345e-02, -6.7820e-02,  5.7526e-02,  1.5422e-01,  8.4398e-02,\n",
      "         8.9778e-02,  3.6124e-01,  1.9393e-01,  1.2960e-01, -1.4379e-02,\n",
      "         7.0830e-02,  7.9905e-02, -3.5129e-01, -7.9506e-01,  4.2106e-01,\n",
      "        -4.8812e-01, -1.9220e-01, -1.0802e-01, -4.3687e-01, -2.2330e-01,\n",
      "         1.4538e-01,  6.7424e-02, -2.0197e-01,  9.6227e-02,  1.8175e-01,\n",
      "         1.1562e-01,  3.5314e-02, -1.6472e-01,  2.9572e-01, -4.3273e-02,\n",
      "         5.4439e-02, -5.6302e-02,  2.0110e-01, -4.9642e-01, -1.6450e-01,\n",
      "        -2.6020e-01, -3.3562e-02, -2.6030e-01, -1.2661e-01, -2.8111e-01,\n",
      "         1.1765e-01,  6.0542e-01,  2.6678e-01,  4.2117e-01, -2.1279e-05,\n",
      "         5.1978e-02,  2.8748e-01, -5.4717e-02, -3.2058e-01,  2.8531e-01,\n",
      "         2.1838e-01, -1.5696e-01, -9.4805e-02, -5.0846e-01, -4.8544e-01,\n",
      "         2.4041e-01,  5.4395e-01, -1.1810e-01,  5.8747e-01, -1.7902e-01,\n",
      "        -1.5054e-01, -8.0681e-02,  4.1534e-01,  8.2457e-02,  3.0453e-01,\n",
      "        -8.8712e-02,  2.3773e-01, -7.7485e-07,  3.8184e-01,  2.0498e-02,\n",
      "         4.2463e-01,  8.6346e-02, -2.4502e-01,  5.4246e-02, -1.7383e-01,\n",
      "         3.9362e-01,  2.6157e-03, -2.9438e-01, -4.2049e-01,  2.4852e-01,\n",
      "         3.3695e-01, -3.3998e-01, -1.0680e-01, -4.5202e-02, -5.1116e-01,\n",
      "         5.2292e-01, -6.4511e-01, -3.3521e-01, -1.2393e-01,  2.2509e-01,\n",
      "        -2.3625e-02, -7.3986e-02,  4.9607e-01,  9.7819e-02, -3.6219e-01,\n",
      "        -9.8277e-02, -1.8702e-01, -6.1555e-02, -1.5850e-01, -2.8541e-01,\n",
      "         1.5597e-01, -1.7547e-01,  1.3693e-01,  7.0585e-01,  1.3522e-01,\n",
      "        -8.5137e-02,  5.3894e-02,  2.9945e-01, -1.3193e-02, -1.2259e-01,\n",
      "         4.4587e-01, -9.4485e-02, -2.0004e-01,  1.7769e-01, -6.3311e-02,\n",
      "         5.2169e-02,  1.2363e-01])\n",
      "Embedding of the sixth token:          tensor([-3.7413e+00, -1.7520e+00,  1.0879e+00, -2.6189e-01,  1.2209e+00,\n",
      "        -2.1202e+00,  2.4666e-01, -1.6095e+00, -1.4584e+00, -2.8486e-01,\n",
      "        -4.0003e-02,  5.5437e-01, -3.2988e-01, -1.7677e+00,  1.8240e-02,\n",
      "         7.1387e-01, -2.4287e+00, -5.1276e-01, -1.0957e+00, -1.0621e-01,\n",
      "        -3.9150e-01, -6.3917e-01, -1.6922e+00,  4.6370e-01,  2.7983e+00,\n",
      "        -2.1735e+00,  2.2633e-01, -1.5044e+00,  2.5043e+00,  2.8687e+00,\n",
      "        -5.4855e-01, -1.2493e+00, -1.0729e+00,  4.8591e-01,  6.2581e-01,\n",
      "         7.3945e-01, -2.7724e-01,  3.2579e-01, -3.9838e-01, -1.5016e-01,\n",
      "         4.0103e-01, -1.4956e-01, -1.3609e-01,  1.7004e-01, -3.6427e-01,\n",
      "         2.1721e-01,  6.5192e-02,  8.9158e-01,  1.9804e-01, -7.5707e-01,\n",
      "        -3.0202e-01, -2.5986e-01, -3.5698e+00, -2.7806e-01, -1.1644e+00,\n",
      "        -2.4118e-01, -3.8254e-01,  9.2729e-02,  1.1562e+00, -3.6127e-01,\n",
      "         3.6679e-01, -4.3867e-01, -7.8185e-01, -5.4513e-01,  1.3964e-01,\n",
      "        -7.3291e-01, -6.2211e-01, -2.6527e-01, -1.8252e-01, -1.5734e-01,\n",
      "         8.6029e-01,  1.1440e+00,  2.4581e-01, -5.7757e-01,  1.6544e-02,\n",
      "        -1.2038e-01,  3.0286e-01,  6.6625e-01, -7.7792e-01, -2.0005e-01,\n",
      "         1.6162e-01, -2.8081e-01, -2.4011e-01, -3.9464e-01,  3.5476e-01,\n",
      "        -1.8748e-01,  2.8218e-01, -4.5322e-01, -1.3274e-01, -4.5206e-01,\n",
      "         4.6736e-01,  5.2971e-01,  3.1713e-01, -2.5321e-01,  8.5581e-02,\n",
      "        -2.8297e-01, -7.2676e-01, -2.8202e-02, -7.3362e-01, -9.7544e-01,\n",
      "        -4.3956e-01,  1.7114e-01, -7.3933e-01,  5.1941e-01,  1.0717e+00,\n",
      "        -7.8227e-01,  1.4384e+00,  6.7075e-01, -2.2129e-01,  1.0321e+00,\n",
      "        -4.5814e-01, -5.4777e-01,  7.8797e-03,  7.2205e-01,  5.7920e-01,\n",
      "        -6.2781e-01,  4.7623e-02,  5.9258e-01,  5.4644e-01,  9.5627e-01,\n",
      "         7.7211e-01,  6.6021e-01, -7.4602e-01, -9.2431e-01,  1.4840e-01,\n",
      "        -4.4212e-01,  3.3725e-01,  6.2384e-02, -5.4018e-03,  9.6277e-02,\n",
      "         3.2993e-01, -5.9718e-01,  1.0119e+00,  2.5620e-01,  1.1206e+00,\n",
      "        -7.6352e-01, -8.2646e-01, -4.8976e-01,  7.2192e-01, -1.2910e-01,\n",
      "         3.4164e-01, -6.8374e-01,  7.3341e-01,  9.6608e-01, -5.8582e-01,\n",
      "         1.2115e-01, -4.2796e-02,  5.1138e-01,  4.1575e-01,  5.9013e-01,\n",
      "         6.3282e-01,  2.0153e-01,  2.6146e-01, -3.2249e-01, -5.9907e-01,\n",
      "         4.7676e-01,  3.2556e-01,  5.3057e-01, -7.6710e-02, -6.4532e-01,\n",
      "        -4.8919e-01,  1.9144e-01,  2.0949e-01,  5.0758e-01,  6.0826e-02,\n",
      "         7.0925e-02,  2.9674e-01,  3.8082e-01, -3.2900e-01, -8.4011e-01,\n",
      "         1.0623e-03,  5.4540e-02,  4.0313e-01,  2.6696e-01,  6.9018e-01,\n",
      "         2.3334e-01, -1.4693e-01,  3.9469e-01, -9.0735e-02,  6.1203e-01,\n",
      "         1.1399e-02, -4.8602e-01,  6.0451e-02, -5.1124e-01, -3.3937e-01,\n",
      "        -5.8241e-01, -4.4668e-01, -1.2441e-01,  8.3781e-01,  3.0757e-03,\n",
      "         8.4054e-01, -5.2071e-01, -3.3596e-01,  5.2715e-02, -1.4874e-01,\n",
      "        -2.6059e-02, -5.8843e-02,  5.8849e-02, -3.9703e-01,  3.4632e-01,\n",
      "         1.2173e-01, -3.1256e-01,  6.2137e-01, -5.7000e-01,  2.5655e-01,\n",
      "         4.0296e-01, -8.4895e-01,  3.3583e-01,  8.7760e-01, -3.7603e-01,\n",
      "         3.2345e-01,  9.9356e-01,  1.0282e+00, -8.1056e-01,  7.9826e-01,\n",
      "        -7.5651e-01,  2.5411e-01, -5.1109e-02,  4.4499e-01,  1.8826e-01,\n",
      "        -5.4997e-01, -6.2395e-01, -6.5825e-02, -4.1653e-01, -1.1921e-01,\n",
      "        -1.6639e-01,  2.2670e-01,  5.3948e-02, -1.0959e-01, -4.6128e-01,\n",
      "        -5.8965e-01, -1.5696e-01, -1.3991e-01,  3.1363e-01,  3.1763e-01,\n",
      "         8.8565e-03, -1.2458e-01,  2.0110e-01, -3.0728e-01,  3.3006e-02,\n",
      "        -6.4018e-01, -3.2276e-01, -4.6880e-01,  4.6960e-01, -1.1032e-01,\n",
      "         4.9715e-01, -5.2288e-02, -4.9376e-01, -4.6493e-02,  3.0779e-01,\n",
      "        -1.8611e-01, -2.0577e-01,  4.9825e-01, -2.4776e-01, -2.1613e-01,\n",
      "         7.2030e-01, -4.4467e-02, -4.5000e-02, -3.3078e-01, -1.1163e-01,\n",
      "        -4.0930e-01,  4.9919e-01, -4.2928e-01,  1.1394e-01,  2.9357e-01,\n",
      "        -1.8478e-01,  4.8979e-01,  3.9731e-01,  1.8359e-01,  5.8851e-03,\n",
      "        -1.1300e-01,  5.3262e-01,  1.2057e-01, -5.6521e-02, -4.3332e-01,\n",
      "         5.4306e-03, -1.9340e-01,  2.1756e-01,  3.2480e-01, -4.9140e-01,\n",
      "         3.8860e-01,  1.8530e-01, -1.8853e-01,  4.1961e-01,  5.1867e-01,\n",
      "         8.3060e-01,  4.5078e-01,  5.5106e-01, -8.6119e-02,  1.0205e-01,\n",
      "         4.8085e-01, -4.2561e-01, -3.5402e-01,  1.9525e-01,  3.9231e-01,\n",
      "        -1.7803e-01,  1.9181e-01, -3.3194e-01, -3.6218e-01,  4.5180e-01,\n",
      "        -1.1076e-01,  1.2105e-01,  1.3646e-02, -3.4898e-01, -1.1954e-03,\n",
      "        -3.8473e-01,  8.7495e-02, -4.6495e-01, -3.1510e-01, -3.5296e-01,\n",
      "         5.7931e-01, -3.1476e-01, -9.4901e-02, -3.9190e-01, -6.9694e-01,\n",
      "        -1.0447e-02,  2.3938e-01, -1.7280e-01, -5.3704e-01,  1.0612e+00,\n",
      "         5.0175e-01, -1.1020e-02,  3.8966e-01,  4.2643e-01, -9.9510e-03,\n",
      "         2.0185e-01, -4.3824e-01,  3.2814e-01, -4.8346e-01, -3.2599e-01,\n",
      "         1.8513e-01, -4.6976e-02,  4.5525e-01,  6.4502e-01, -3.2612e-02,\n",
      "         8.7192e-02, -2.1008e-01,  2.8687e-02,  1.1076e-01, -3.0017e-01,\n",
      "        -5.0154e-02,  3.8217e-01,  2.6532e-02,  1.2623e-01,  1.0394e-01,\n",
      "         4.3786e-02, -1.1118e-01,  2.8052e-02, -6.8033e-03, -5.0394e-03,\n",
      "         4.3601e-01,  8.1189e-02, -7.4181e-02, -3.6765e-01, -1.9569e-02,\n",
      "         1.4345e-01,  2.8632e-01, -2.6073e-01,  3.6885e-02, -3.4718e-01,\n",
      "         5.2495e-01,  3.8395e-01,  1.5273e-01, -2.1628e-01,  3.4222e-01,\n",
      "        -3.4717e-01,  1.3506e-01, -2.9593e-01, -4.3897e-01,  6.6618e-02,\n",
      "        -6.0420e-01,  4.6465e-01, -4.1210e-01,  6.5812e-01,  3.3184e-01,\n",
      "         2.2699e-01,  1.5620e-01,  3.7608e-01, -3.8086e-02, -3.2624e-01,\n",
      "        -1.5369e-01, -4.2839e-01, -4.0469e-01, -8.9543e-03, -6.6050e-01,\n",
      "         1.9467e-01,  8.0796e-01, -4.7144e-01, -6.3811e-01,  3.5103e-01,\n",
      "        -3.6293e-01, -2.7268e-01, -3.6439e-01,  5.5532e-02,  1.3991e-01,\n",
      "         8.0138e-01, -5.7100e-01,  1.0608e+00,  2.4445e-01, -7.6118e-01,\n",
      "         2.2254e-02,  1.3983e-02,  6.2986e-01, -7.3683e-02,  8.0212e-01,\n",
      "        -2.8109e-01,  6.6694e-01, -6.7035e-01, -9.6533e-02, -1.9628e-02,\n",
      "         1.3905e-01,  5.9583e-02,  4.8975e-02,  5.6256e-01, -2.9041e-01,\n",
      "         5.6460e-02,  4.1767e-01, -7.3050e-01,  2.9958e-02, -5.7242e-01,\n",
      "         3.7911e-01,  8.6302e-01, -8.6317e-01, -9.3029e-01, -8.1289e-02,\n",
      "        -7.8378e-02, -2.2158e-01, -3.6283e-02,  5.3579e-01, -5.3185e-01,\n",
      "         5.7798e-01,  3.4648e-01,  2.6285e-01, -1.8939e-01, -1.6681e-01,\n",
      "         7.8349e-01,  1.9662e-01,  1.2939e-01, -4.4017e-01,  4.0976e-01,\n",
      "         4.2476e-01, -4.9217e-01,  6.2978e-01, -1.4613e-01, -1.6054e-01,\n",
      "         7.4404e-01,  1.6765e-01, -3.2840e-01,  4.1663e-01,  6.0308e-01,\n",
      "        -1.0861e+00,  5.4388e-01, -9.2215e-01, -4.8429e-01, -1.3947e+00,\n",
      "         2.5982e-01,  1.4184e+00,  3.7120e-01, -9.2127e-01, -1.4159e+00,\n",
      "         1.6531e-02, -6.3792e-01,  5.1167e-01,  3.6167e-01, -1.3585e-01,\n",
      "         6.1094e-01,  2.7156e-01,  4.9552e-01, -1.0393e+00,  2.9700e-01,\n",
      "        -6.7169e-01, -7.1377e-01,  2.5848e-01,  7.3621e-02,  5.0331e-02,\n",
      "         2.2472e-01, -3.8532e-01,  9.9617e-03, -6.7879e-02, -7.7955e-02,\n",
      "        -4.4956e-01,  1.8528e+00,  1.5305e+00,  2.2598e-01, -5.8522e-01,\n",
      "         4.8994e-01,  6.9847e-01, -3.4993e-01,  4.0096e-01,  1.5367e+00,\n",
      "        -1.2456e-01, -9.0872e-01, -4.7142e-01, -1.1398e+00,  1.6423e+00,\n",
      "        -6.9061e-01, -8.8025e-01, -1.3386e+00, -5.0809e-01, -3.1707e-01,\n",
      "         2.0900e-01, -2.8918e-01, -3.6064e-01,  1.5625e-01,  6.1036e-02,\n",
      "        -4.7900e-01,  9.4345e-01,  3.1026e-01, -5.6936e-01,  5.1809e-01,\n",
      "         9.4103e-01, -4.7187e-01])\n",
      "Embedding of the twenty-fifth token:   tensor([-3.7413e+00, -1.7520e+00,  1.0879e+00, -2.6189e-01,  1.2209e+00,\n",
      "        -2.1202e+00,  2.4666e-01, -1.6095e+00, -1.4584e+00, -2.8486e-01,\n",
      "        -4.0003e-02,  5.5437e-01, -3.2988e-01, -1.7677e+00,  1.8240e-02,\n",
      "         7.1387e-01, -2.4287e+00, -5.1276e-01, -1.0957e+00, -1.0621e-01,\n",
      "        -3.9150e-01, -6.3917e-01, -1.6922e+00,  4.6370e-01,  2.7983e+00,\n",
      "        -2.1735e+00,  2.2633e-01, -1.5044e+00,  2.5043e+00,  2.8687e+00,\n",
      "        -5.4855e-01, -1.2493e+00, -1.0729e+00,  4.8591e-01,  6.2581e-01,\n",
      "         7.3945e-01, -2.7724e-01,  3.2579e-01, -3.9838e-01, -1.5016e-01,\n",
      "         4.0103e-01, -1.4956e-01, -1.3609e-01,  1.7004e-01, -3.6427e-01,\n",
      "         2.1721e-01,  6.5192e-02,  8.9158e-01,  1.9804e-01, -7.5707e-01,\n",
      "        -3.0202e-01, -2.5986e-01, -3.5698e+00, -2.7806e-01, -1.1644e+00,\n",
      "        -2.4118e-01, -3.8254e-01,  9.2729e-02,  1.1562e+00, -3.6127e-01,\n",
      "         3.6679e-01, -4.3867e-01, -7.8185e-01, -5.4513e-01,  1.3964e-01,\n",
      "        -7.3291e-01, -6.2211e-01, -2.6527e-01, -1.8252e-01, -1.5734e-01,\n",
      "         8.6029e-01,  1.1440e+00,  2.4581e-01, -5.7757e-01,  1.6544e-02,\n",
      "        -1.2038e-01,  3.0286e-01,  6.6625e-01, -7.7792e-01, -2.0005e-01,\n",
      "         1.6162e-01, -2.8081e-01, -2.4011e-01, -3.9464e-01,  3.5476e-01,\n",
      "        -1.8748e-01,  2.8218e-01, -4.5322e-01, -1.3274e-01, -4.5206e-01,\n",
      "         4.6736e-01,  5.2971e-01,  3.1713e-01, -2.5321e-01,  8.5581e-02,\n",
      "        -2.8297e-01, -7.2676e-01, -2.8202e-02, -7.3362e-01, -9.7544e-01,\n",
      "        -4.3956e-01,  1.7114e-01, -7.3933e-01,  5.1941e-01,  1.0717e+00,\n",
      "        -7.8227e-01,  1.4384e+00,  6.7075e-01, -2.2129e-01,  1.0321e+00,\n",
      "        -4.5814e-01, -5.4777e-01,  7.8797e-03,  7.2205e-01,  5.7920e-01,\n",
      "        -6.2781e-01,  4.7623e-02,  5.9258e-01,  5.4644e-01,  9.5627e-01,\n",
      "         7.7211e-01,  6.6021e-01, -7.4602e-01, -9.2431e-01,  1.4840e-01,\n",
      "        -4.4212e-01,  3.3725e-01,  6.2384e-02, -5.4018e-03,  9.6277e-02,\n",
      "         3.2993e-01, -5.9718e-01,  1.0119e+00,  2.5620e-01,  1.1206e+00,\n",
      "        -7.6352e-01, -8.2646e-01, -4.8976e-01,  7.2192e-01, -1.2910e-01,\n",
      "         3.4164e-01, -6.8374e-01,  7.3341e-01,  9.6608e-01, -5.8582e-01,\n",
      "         1.2115e-01, -4.2796e-02,  5.1138e-01,  4.1575e-01,  5.9013e-01,\n",
      "         6.3282e-01,  2.0153e-01,  2.6146e-01, -3.2249e-01, -5.9907e-01,\n",
      "         4.7676e-01,  3.2556e-01,  5.3057e-01, -7.6710e-02, -6.4532e-01,\n",
      "        -4.8919e-01,  1.9144e-01,  2.0949e-01,  5.0758e-01,  6.0826e-02,\n",
      "         7.0925e-02,  2.9674e-01,  3.8082e-01, -3.2900e-01, -8.4011e-01,\n",
      "         1.0623e-03,  5.4540e-02,  4.0313e-01,  2.6696e-01,  6.9018e-01,\n",
      "         2.3334e-01, -1.4693e-01,  3.9469e-01, -9.0735e-02,  6.1203e-01,\n",
      "         1.1399e-02, -4.8602e-01,  6.0451e-02, -5.1124e-01, -3.3937e-01,\n",
      "        -5.8241e-01, -4.4668e-01, -1.2441e-01,  8.3781e-01,  3.0757e-03,\n",
      "         8.4054e-01, -5.2071e-01, -3.3596e-01,  5.2715e-02, -1.4874e-01,\n",
      "        -2.6059e-02, -5.8843e-02,  5.8849e-02, -3.9703e-01,  3.4632e-01,\n",
      "         1.2173e-01, -3.1256e-01,  6.2137e-01, -5.7000e-01,  2.5655e-01,\n",
      "         4.0296e-01, -8.4895e-01,  3.3583e-01,  8.7760e-01, -3.7603e-01,\n",
      "         3.2345e-01,  9.9356e-01,  1.0282e+00, -8.1056e-01,  7.9826e-01,\n",
      "        -7.5651e-01,  2.5411e-01, -5.1109e-02,  4.4499e-01,  1.8826e-01,\n",
      "        -5.4997e-01, -6.2395e-01, -6.5825e-02, -4.1653e-01, -1.1921e-01,\n",
      "        -1.6639e-01,  2.2670e-01,  5.3948e-02, -1.0959e-01, -4.6128e-01,\n",
      "        -5.8965e-01, -1.5696e-01, -1.3991e-01,  3.1363e-01,  3.1763e-01,\n",
      "         8.8565e-03, -1.2458e-01,  2.0110e-01, -3.0728e-01,  3.3006e-02,\n",
      "        -6.4018e-01, -3.2276e-01, -4.6880e-01,  4.6960e-01, -1.1032e-01,\n",
      "         4.9715e-01, -5.2288e-02, -4.9376e-01, -4.6493e-02,  3.0779e-01,\n",
      "        -1.8611e-01, -2.0577e-01,  4.9825e-01, -2.4776e-01, -2.1613e-01,\n",
      "         7.2030e-01, -4.4467e-02, -4.5000e-02, -3.3078e-01, -1.1163e-01,\n",
      "        -4.0930e-01,  4.9919e-01, -4.2928e-01,  1.1394e-01,  2.9357e-01,\n",
      "        -1.8478e-01,  4.8979e-01,  3.9731e-01,  1.8359e-01,  5.8851e-03,\n",
      "        -1.1300e-01,  5.3262e-01,  1.2057e-01, -5.6521e-02, -4.3332e-01,\n",
      "         5.4306e-03, -1.9340e-01,  2.1756e-01,  3.2480e-01, -4.9140e-01,\n",
      "         3.8860e-01,  1.8530e-01, -1.8853e-01,  4.1961e-01,  5.1867e-01,\n",
      "         8.3060e-01,  4.5078e-01,  5.5106e-01, -8.6119e-02,  1.0205e-01,\n",
      "         4.8085e-01, -4.2561e-01, -3.5402e-01,  1.9525e-01,  3.9231e-01,\n",
      "        -1.7803e-01,  1.9181e-01, -3.3194e-01, -3.6218e-01,  4.5180e-01,\n",
      "        -1.1076e-01,  1.2105e-01,  1.3646e-02, -3.4898e-01, -1.1954e-03,\n",
      "        -3.8473e-01,  8.7495e-02, -4.6495e-01, -3.1510e-01, -3.5296e-01,\n",
      "         5.7931e-01, -3.1476e-01, -9.4901e-02, -3.9190e-01, -6.9694e-01,\n",
      "        -1.0447e-02,  2.3938e-01, -1.7280e-01, -5.3704e-01,  1.0612e+00,\n",
      "         5.0175e-01, -1.1020e-02,  3.8966e-01,  4.2643e-01, -9.9510e-03,\n",
      "         2.0185e-01, -4.3824e-01,  3.2814e-01, -4.8346e-01, -3.2599e-01,\n",
      "         1.8513e-01, -4.6976e-02,  4.5525e-01,  6.4502e-01, -3.2612e-02,\n",
      "         8.7192e-02, -2.1008e-01,  2.8687e-02,  1.1076e-01, -3.0017e-01,\n",
      "        -5.0154e-02,  3.8217e-01,  2.6532e-02,  1.2623e-01,  1.0394e-01,\n",
      "         4.3786e-02, -1.1118e-01,  2.8052e-02, -6.8033e-03, -5.0394e-03,\n",
      "         4.3601e-01,  8.1189e-02, -7.4181e-02, -3.6765e-01, -1.9569e-02,\n",
      "         1.4345e-01,  2.8632e-01, -2.6073e-01,  3.6885e-02, -3.4718e-01,\n",
      "         5.2495e-01,  3.8395e-01,  1.5273e-01, -2.1628e-01,  3.4222e-01,\n",
      "        -3.4717e-01,  1.3506e-01, -2.9593e-01, -4.3897e-01,  6.6618e-02,\n",
      "        -6.0420e-01,  4.6465e-01, -4.1210e-01,  6.5812e-01,  3.3184e-01,\n",
      "         2.2699e-01,  1.5620e-01,  3.7608e-01, -3.8086e-02, -3.2624e-01,\n",
      "        -1.5369e-01, -4.2839e-01, -4.0469e-01, -8.9543e-03, -6.6050e-01,\n",
      "         1.9467e-01,  8.0796e-01, -4.7144e-01, -6.3811e-01,  3.5103e-01,\n",
      "        -3.6293e-01, -2.7268e-01, -3.6439e-01,  5.5532e-02,  1.3991e-01,\n",
      "         8.0138e-01, -5.7100e-01,  1.0608e+00,  2.4445e-01, -7.6118e-01,\n",
      "         2.2254e-02,  1.3983e-02,  6.2986e-01, -7.3683e-02,  8.0212e-01,\n",
      "        -2.8109e-01,  6.6694e-01, -6.7035e-01, -9.6533e-02, -1.9628e-02,\n",
      "         1.3905e-01,  5.9583e-02,  4.8975e-02,  5.6256e-01, -2.9041e-01,\n",
      "         5.6460e-02,  4.1767e-01, -7.3050e-01,  2.9958e-02, -5.7242e-01,\n",
      "         3.7911e-01,  8.6302e-01, -8.6317e-01, -9.3029e-01, -8.1289e-02,\n",
      "        -7.8378e-02, -2.2158e-01, -3.6283e-02,  5.3579e-01, -5.3185e-01,\n",
      "         5.7798e-01,  3.4648e-01,  2.6285e-01, -1.8939e-01, -1.6681e-01,\n",
      "         7.8349e-01,  1.9662e-01,  1.2939e-01, -4.4017e-01,  4.0976e-01,\n",
      "         4.2476e-01, -4.9217e-01,  6.2978e-01, -1.4613e-01, -1.6054e-01,\n",
      "         7.4404e-01,  1.6765e-01, -3.2840e-01,  4.1663e-01,  6.0308e-01,\n",
      "        -1.0861e+00,  5.4388e-01, -9.2215e-01, -4.8429e-01, -1.3947e+00,\n",
      "         2.5982e-01,  1.4184e+00,  3.7120e-01, -9.2127e-01, -1.4159e+00,\n",
      "         1.6531e-02, -6.3792e-01,  5.1167e-01,  3.6167e-01, -1.3585e-01,\n",
      "         6.1094e-01,  2.7156e-01,  4.9552e-01, -1.0393e+00,  2.9700e-01,\n",
      "        -6.7169e-01, -7.1377e-01,  2.5848e-01,  7.3621e-02,  5.0331e-02,\n",
      "         2.2472e-01, -3.8532e-01,  9.9617e-03, -6.7879e-02, -7.7955e-02,\n",
      "        -4.4956e-01,  1.8528e+00,  1.5305e+00,  2.2598e-01, -5.8522e-01,\n",
      "         4.8994e-01,  6.9847e-01, -3.4993e-01,  4.0096e-01,  1.5367e+00,\n",
      "        -1.2456e-01, -9.0872e-01, -4.7142e-01, -1.1398e+00,  1.6423e+00,\n",
      "        -6.9061e-01, -8.8025e-01, -1.3386e+00, -5.0809e-01, -3.1707e-01,\n",
      "         2.0900e-01, -2.8918e-01, -3.6064e-01,  1.5625e-01,  6.1036e-02,\n",
      "        -4.7900e-01,  9.4345e-01,  3.1026e-01, -5.6936e-01,  5.1809e-01,\n",
      "         9.4103e-01, -4.7187e-01])\n",
      "Embedding of the fortieth token:       tensor([-3.7413e+00, -1.7520e+00,  1.0879e+00, -2.6189e-01,  1.2209e+00,\n",
      "        -2.1202e+00,  2.4666e-01, -1.6095e+00, -1.4584e+00, -2.8486e-01,\n",
      "        -4.0003e-02,  5.5437e-01, -3.2988e-01, -1.7677e+00,  1.8240e-02,\n",
      "         7.1387e-01, -2.4287e+00, -5.1276e-01, -1.0957e+00, -1.0621e-01,\n",
      "        -3.9150e-01, -6.3917e-01, -1.6922e+00,  4.6370e-01,  2.7983e+00,\n",
      "        -2.1735e+00,  2.2633e-01, -1.5044e+00,  2.5043e+00,  2.8687e+00,\n",
      "        -5.4855e-01, -1.2493e+00, -1.0729e+00,  4.8591e-01,  6.2581e-01,\n",
      "         7.3945e-01, -2.7724e-01,  3.2579e-01, -3.9838e-01, -1.5016e-01,\n",
      "         4.0103e-01, -1.4956e-01, -1.3609e-01,  1.7004e-01, -3.6427e-01,\n",
      "         2.1721e-01,  6.5192e-02,  8.9158e-01,  1.9804e-01, -7.5707e-01,\n",
      "        -3.0202e-01, -2.5986e-01, -3.5698e+00, -2.7806e-01, -1.1644e+00,\n",
      "        -2.4118e-01, -3.8254e-01,  9.2729e-02,  1.1562e+00, -3.6127e-01,\n",
      "         3.6679e-01, -4.3867e-01, -7.8185e-01, -5.4513e-01,  1.3964e-01,\n",
      "        -7.3291e-01, -6.2211e-01, -2.6527e-01, -1.8252e-01, -1.5734e-01,\n",
      "         8.6029e-01,  1.1440e+00,  2.4581e-01, -5.7757e-01,  1.6544e-02,\n",
      "        -1.2038e-01,  3.0286e-01,  6.6625e-01, -7.7792e-01, -2.0005e-01,\n",
      "         1.6162e-01, -2.8081e-01, -2.4011e-01, -3.9464e-01,  3.5476e-01,\n",
      "        -1.8748e-01,  2.8218e-01, -4.5322e-01, -1.3274e-01, -4.5206e-01,\n",
      "         4.6736e-01,  5.2971e-01,  3.1713e-01, -2.5321e-01,  8.5581e-02,\n",
      "        -2.8297e-01, -7.2676e-01, -2.8202e-02, -7.3362e-01, -9.7544e-01,\n",
      "        -4.3956e-01,  1.7114e-01, -7.3933e-01,  5.1941e-01,  1.0717e+00,\n",
      "        -7.8227e-01,  1.4384e+00,  6.7075e-01, -2.2129e-01,  1.0321e+00,\n",
      "        -4.5814e-01, -5.4777e-01,  7.8797e-03,  7.2205e-01,  5.7920e-01,\n",
      "        -6.2781e-01,  4.7623e-02,  5.9258e-01,  5.4644e-01,  9.5627e-01,\n",
      "         7.7211e-01,  6.6021e-01, -7.4602e-01, -9.2431e-01,  1.4840e-01,\n",
      "        -4.4212e-01,  3.3725e-01,  6.2384e-02, -5.4018e-03,  9.6277e-02,\n",
      "         3.2993e-01, -5.9718e-01,  1.0119e+00,  2.5620e-01,  1.1206e+00,\n",
      "        -7.6352e-01, -8.2646e-01, -4.8976e-01,  7.2192e-01, -1.2910e-01,\n",
      "         3.4164e-01, -6.8374e-01,  7.3341e-01,  9.6608e-01, -5.8582e-01,\n",
      "         1.2115e-01, -4.2796e-02,  5.1138e-01,  4.1575e-01,  5.9013e-01,\n",
      "         6.3282e-01,  2.0153e-01,  2.6146e-01, -3.2249e-01, -5.9907e-01,\n",
      "         4.7676e-01,  3.2556e-01,  5.3057e-01, -7.6710e-02, -6.4532e-01,\n",
      "        -4.8919e-01,  1.9144e-01,  2.0949e-01,  5.0758e-01,  6.0826e-02,\n",
      "         7.0925e-02,  2.9674e-01,  3.8082e-01, -3.2900e-01, -8.4011e-01,\n",
      "         1.0623e-03,  5.4540e-02,  4.0313e-01,  2.6696e-01,  6.9018e-01,\n",
      "         2.3334e-01, -1.4693e-01,  3.9469e-01, -9.0735e-02,  6.1203e-01,\n",
      "         1.1399e-02, -4.8602e-01,  6.0451e-02, -5.1124e-01, -3.3937e-01,\n",
      "        -5.8241e-01, -4.4668e-01, -1.2441e-01,  8.3781e-01,  3.0757e-03,\n",
      "         8.4054e-01, -5.2071e-01, -3.3596e-01,  5.2715e-02, -1.4874e-01,\n",
      "        -2.6059e-02, -5.8843e-02,  5.8849e-02, -3.9703e-01,  3.4632e-01,\n",
      "         1.2173e-01, -3.1256e-01,  6.2137e-01, -5.7000e-01,  2.5655e-01,\n",
      "         4.0296e-01, -8.4895e-01,  3.3583e-01,  8.7760e-01, -3.7603e-01,\n",
      "         3.2345e-01,  9.9356e-01,  1.0282e+00, -8.1056e-01,  7.9826e-01,\n",
      "        -7.5651e-01,  2.5411e-01, -5.1109e-02,  4.4499e-01,  1.8826e-01,\n",
      "        -5.4997e-01, -6.2395e-01, -6.5825e-02, -4.1653e-01, -1.1921e-01,\n",
      "        -1.6639e-01,  2.2670e-01,  5.3948e-02, -1.0959e-01, -4.6128e-01,\n",
      "        -5.8965e-01, -1.5696e-01, -1.3991e-01,  3.1363e-01,  3.1763e-01,\n",
      "         8.8565e-03, -1.2458e-01,  2.0110e-01, -3.0728e-01,  3.3006e-02,\n",
      "        -6.4018e-01, -3.2276e-01, -4.6880e-01,  4.6960e-01, -1.1032e-01,\n",
      "         4.9715e-01, -5.2288e-02, -4.9376e-01, -4.6493e-02,  3.0779e-01,\n",
      "        -1.8611e-01, -2.0577e-01,  4.9825e-01, -2.4776e-01, -2.1613e-01,\n",
      "         7.2030e-01, -4.4467e-02, -4.5000e-02, -3.3078e-01, -1.1163e-01,\n",
      "        -4.0930e-01,  4.9919e-01, -4.2928e-01,  1.1394e-01,  2.9357e-01,\n",
      "        -1.8478e-01,  4.8979e-01,  3.9731e-01,  1.8359e-01,  5.8851e-03,\n",
      "        -1.1300e-01,  5.3262e-01,  1.2057e-01, -5.6521e-02, -4.3332e-01,\n",
      "         5.4306e-03, -1.9340e-01,  2.1756e-01,  3.2480e-01, -4.9140e-01,\n",
      "         3.8860e-01,  1.8530e-01, -1.8853e-01,  4.1961e-01,  5.1867e-01,\n",
      "         8.3060e-01,  4.5078e-01,  5.5106e-01, -8.6119e-02,  1.0205e-01,\n",
      "         4.8085e-01, -4.2561e-01, -3.5402e-01,  1.9525e-01,  3.9231e-01,\n",
      "        -1.7803e-01,  1.9181e-01, -3.3194e-01, -3.6218e-01,  4.5180e-01,\n",
      "        -1.1076e-01,  1.2105e-01,  1.3646e-02, -3.4898e-01, -1.1954e-03,\n",
      "        -3.8473e-01,  8.7495e-02, -4.6495e-01, -3.1510e-01, -3.5296e-01,\n",
      "         5.7931e-01, -3.1476e-01, -9.4901e-02, -3.9190e-01, -6.9694e-01,\n",
      "        -1.0447e-02,  2.3938e-01, -1.7280e-01, -5.3704e-01,  1.0612e+00,\n",
      "         5.0175e-01, -1.1020e-02,  3.8966e-01,  4.2643e-01, -9.9510e-03,\n",
      "         2.0185e-01, -4.3824e-01,  3.2814e-01, -4.8346e-01, -3.2599e-01,\n",
      "         1.8513e-01, -4.6976e-02,  4.5525e-01,  6.4502e-01, -3.2612e-02,\n",
      "         8.7192e-02, -2.1008e-01,  2.8687e-02,  1.1076e-01, -3.0017e-01,\n",
      "        -5.0154e-02,  3.8217e-01,  2.6532e-02,  1.2623e-01,  1.0394e-01,\n",
      "         4.3786e-02, -1.1118e-01,  2.8052e-02, -6.8033e-03, -5.0394e-03,\n",
      "         4.3601e-01,  8.1189e-02, -7.4181e-02, -3.6765e-01, -1.9569e-02,\n",
      "         1.4345e-01,  2.8632e-01, -2.6073e-01,  3.6885e-02, -3.4718e-01,\n",
      "         5.2495e-01,  3.8395e-01,  1.5273e-01, -2.1628e-01,  3.4222e-01,\n",
      "        -3.4717e-01,  1.3506e-01, -2.9593e-01, -4.3897e-01,  6.6618e-02,\n",
      "        -6.0420e-01,  4.6465e-01, -4.1210e-01,  6.5812e-01,  3.3184e-01,\n",
      "         2.2699e-01,  1.5620e-01,  3.7608e-01, -3.8086e-02, -3.2624e-01,\n",
      "        -1.5369e-01, -4.2839e-01, -4.0469e-01, -8.9543e-03, -6.6050e-01,\n",
      "         1.9467e-01,  8.0796e-01, -4.7144e-01, -6.3811e-01,  3.5103e-01,\n",
      "        -3.6293e-01, -2.7268e-01, -3.6439e-01,  5.5532e-02,  1.3991e-01,\n",
      "         8.0138e-01, -5.7100e-01,  1.0608e+00,  2.4445e-01, -7.6118e-01,\n",
      "         2.2254e-02,  1.3983e-02,  6.2986e-01, -7.3683e-02,  8.0212e-01,\n",
      "        -2.8109e-01,  6.6694e-01, -6.7035e-01, -9.6533e-02, -1.9628e-02,\n",
      "         1.3905e-01,  5.9583e-02,  4.8975e-02,  5.6256e-01, -2.9041e-01,\n",
      "         5.6460e-02,  4.1767e-01, -7.3050e-01,  2.9958e-02, -5.7242e-01,\n",
      "         3.7911e-01,  8.6302e-01, -8.6317e-01, -9.3029e-01, -8.1289e-02,\n",
      "        -7.8378e-02, -2.2158e-01, -3.6283e-02,  5.3579e-01, -5.3185e-01,\n",
      "         5.7798e-01,  3.4648e-01,  2.6285e-01, -1.8939e-01, -1.6681e-01,\n",
      "         7.8349e-01,  1.9662e-01,  1.2939e-01, -4.4017e-01,  4.0976e-01,\n",
      "         4.2476e-01, -4.9217e-01,  6.2978e-01, -1.4613e-01, -1.6054e-01,\n",
      "         7.4404e-01,  1.6765e-01, -3.2840e-01,  4.1663e-01,  6.0308e-01,\n",
      "        -1.0861e+00,  5.4388e-01, -9.2215e-01, -4.8429e-01, -1.3947e+00,\n",
      "         2.5982e-01,  1.4184e+00,  3.7120e-01, -9.2127e-01, -1.4159e+00,\n",
      "         1.6531e-02, -6.3792e-01,  5.1167e-01,  3.6167e-01, -1.3585e-01,\n",
      "         6.1094e-01,  2.7156e-01,  4.9552e-01, -1.0393e+00,  2.9700e-01,\n",
      "        -6.7169e-01, -7.1377e-01,  2.5848e-01,  7.3621e-02,  5.0331e-02,\n",
      "         2.2472e-01, -3.8532e-01,  9.9617e-03, -6.7879e-02, -7.7955e-02,\n",
      "        -4.4956e-01,  1.8528e+00,  1.5305e+00,  2.2598e-01, -5.8522e-01,\n",
      "         4.8994e-01,  6.9847e-01, -3.4993e-01,  4.0096e-01,  1.5367e+00,\n",
      "        -1.2456e-01, -9.0872e-01, -4.7142e-01, -1.1398e+00,  1.6423e+00,\n",
      "        -6.9061e-01, -8.8025e-01, -1.3386e+00, -5.0809e-01, -3.1707e-01,\n",
      "         2.0900e-01, -2.8918e-01, -3.6064e-01,  1.5625e-01,  6.1036e-02,\n",
      "        -4.7900e-01,  9.4345e-01,  3.1026e-01, -5.6936e-01,  5.1809e-01,\n",
      "         9.4103e-01, -4.7187e-01])\n",
      "Embedding of the fiftieth token:       tensor([-3.7413e+00, -1.7520e+00,  1.0879e+00, -2.6189e-01,  1.2209e+00,\n",
      "        -2.1202e+00,  2.4666e-01, -1.6095e+00, -1.4584e+00, -2.8486e-01,\n",
      "        -4.0003e-02,  5.5437e-01, -3.2988e-01, -1.7677e+00,  1.8240e-02,\n",
      "         7.1387e-01, -2.4287e+00, -5.1276e-01, -1.0957e+00, -1.0621e-01,\n",
      "        -3.9150e-01, -6.3917e-01, -1.6922e+00,  4.6370e-01,  2.7983e+00,\n",
      "        -2.1735e+00,  2.2633e-01, -1.5044e+00,  2.5043e+00,  2.8687e+00,\n",
      "        -5.4855e-01, -1.2493e+00, -1.0729e+00,  4.8591e-01,  6.2581e-01,\n",
      "         7.3945e-01, -2.7724e-01,  3.2579e-01, -3.9838e-01, -1.5016e-01,\n",
      "         4.0103e-01, -1.4956e-01, -1.3609e-01,  1.7004e-01, -3.6427e-01,\n",
      "         2.1721e-01,  6.5192e-02,  8.9158e-01,  1.9804e-01, -7.5707e-01,\n",
      "        -3.0202e-01, -2.5986e-01, -3.5698e+00, -2.7806e-01, -1.1644e+00,\n",
      "        -2.4118e-01, -3.8254e-01,  9.2729e-02,  1.1562e+00, -3.6127e-01,\n",
      "         3.6679e-01, -4.3867e-01, -7.8185e-01, -5.4513e-01,  1.3964e-01,\n",
      "        -7.3291e-01, -6.2211e-01, -2.6527e-01, -1.8252e-01, -1.5734e-01,\n",
      "         8.6029e-01,  1.1440e+00,  2.4581e-01, -5.7757e-01,  1.6544e-02,\n",
      "        -1.2038e-01,  3.0286e-01,  6.6625e-01, -7.7792e-01, -2.0005e-01,\n",
      "         1.6162e-01, -2.8081e-01, -2.4011e-01, -3.9464e-01,  3.5476e-01,\n",
      "        -1.8748e-01,  2.8218e-01, -4.5322e-01, -1.3274e-01, -4.5206e-01,\n",
      "         4.6736e-01,  5.2971e-01,  3.1713e-01, -2.5321e-01,  8.5581e-02,\n",
      "        -2.8297e-01, -7.2676e-01, -2.8202e-02, -7.3362e-01, -9.7544e-01,\n",
      "        -4.3956e-01,  1.7114e-01, -7.3933e-01,  5.1941e-01,  1.0717e+00,\n",
      "        -7.8227e-01,  1.4384e+00,  6.7075e-01, -2.2129e-01,  1.0321e+00,\n",
      "        -4.5814e-01, -5.4777e-01,  7.8797e-03,  7.2205e-01,  5.7920e-01,\n",
      "        -6.2781e-01,  4.7623e-02,  5.9258e-01,  5.4644e-01,  9.5627e-01,\n",
      "         7.7211e-01,  6.6021e-01, -7.4602e-01, -9.2431e-01,  1.4840e-01,\n",
      "        -4.4212e-01,  3.3725e-01,  6.2384e-02, -5.4018e-03,  9.6277e-02,\n",
      "         3.2993e-01, -5.9718e-01,  1.0119e+00,  2.5620e-01,  1.1206e+00,\n",
      "        -7.6352e-01, -8.2646e-01, -4.8976e-01,  7.2192e-01, -1.2910e-01,\n",
      "         3.4164e-01, -6.8374e-01,  7.3341e-01,  9.6608e-01, -5.8582e-01,\n",
      "         1.2115e-01, -4.2796e-02,  5.1138e-01,  4.1575e-01,  5.9013e-01,\n",
      "         6.3282e-01,  2.0153e-01,  2.6146e-01, -3.2249e-01, -5.9907e-01,\n",
      "         4.7676e-01,  3.2556e-01,  5.3057e-01, -7.6710e-02, -6.4532e-01,\n",
      "        -4.8919e-01,  1.9144e-01,  2.0949e-01,  5.0758e-01,  6.0826e-02,\n",
      "         7.0925e-02,  2.9674e-01,  3.8082e-01, -3.2900e-01, -8.4011e-01,\n",
      "         1.0623e-03,  5.4540e-02,  4.0313e-01,  2.6696e-01,  6.9018e-01,\n",
      "         2.3334e-01, -1.4693e-01,  3.9469e-01, -9.0735e-02,  6.1203e-01,\n",
      "         1.1399e-02, -4.8602e-01,  6.0451e-02, -5.1124e-01, -3.3937e-01,\n",
      "        -5.8241e-01, -4.4668e-01, -1.2441e-01,  8.3781e-01,  3.0757e-03,\n",
      "         8.4054e-01, -5.2071e-01, -3.3596e-01,  5.2715e-02, -1.4874e-01,\n",
      "        -2.6059e-02, -5.8843e-02,  5.8849e-02, -3.9703e-01,  3.4632e-01,\n",
      "         1.2173e-01, -3.1256e-01,  6.2137e-01, -5.7000e-01,  2.5655e-01,\n",
      "         4.0296e-01, -8.4895e-01,  3.3583e-01,  8.7760e-01, -3.7603e-01,\n",
      "         3.2345e-01,  9.9356e-01,  1.0282e+00, -8.1056e-01,  7.9826e-01,\n",
      "        -7.5651e-01,  2.5411e-01, -5.1109e-02,  4.4499e-01,  1.8826e-01,\n",
      "        -5.4997e-01, -6.2395e-01, -6.5825e-02, -4.1653e-01, -1.1921e-01,\n",
      "        -1.6639e-01,  2.2670e-01,  5.3948e-02, -1.0959e-01, -4.6128e-01,\n",
      "        -5.8965e-01, -1.5696e-01, -1.3991e-01,  3.1363e-01,  3.1763e-01,\n",
      "         8.8565e-03, -1.2458e-01,  2.0110e-01, -3.0728e-01,  3.3006e-02,\n",
      "        -6.4018e-01, -3.2276e-01, -4.6880e-01,  4.6960e-01, -1.1032e-01,\n",
      "         4.9715e-01, -5.2288e-02, -4.9376e-01, -4.6493e-02,  3.0779e-01,\n",
      "        -1.8611e-01, -2.0577e-01,  4.9825e-01, -2.4776e-01, -2.1613e-01,\n",
      "         7.2030e-01, -4.4467e-02, -4.5000e-02, -3.3078e-01, -1.1163e-01,\n",
      "        -4.0930e-01,  4.9919e-01, -4.2928e-01,  1.1394e-01,  2.9357e-01,\n",
      "        -1.8478e-01,  4.8979e-01,  3.9731e-01,  1.8359e-01,  5.8851e-03,\n",
      "        -1.1300e-01,  5.3262e-01,  1.2057e-01, -5.6521e-02, -4.3332e-01,\n",
      "         5.4306e-03, -1.9340e-01,  2.1756e-01,  3.2480e-01, -4.9140e-01,\n",
      "         3.8860e-01,  1.8530e-01, -1.8853e-01,  4.1961e-01,  5.1867e-01,\n",
      "         8.3060e-01,  4.5078e-01,  5.5106e-01, -8.6119e-02,  1.0205e-01,\n",
      "         4.8085e-01, -4.2561e-01, -3.5402e-01,  1.9525e-01,  3.9231e-01,\n",
      "        -1.7803e-01,  1.9181e-01, -3.3194e-01, -3.6218e-01,  4.5180e-01,\n",
      "        -1.1076e-01,  1.2105e-01,  1.3646e-02, -3.4898e-01, -1.1954e-03,\n",
      "        -3.8473e-01,  8.7495e-02, -4.6495e-01, -3.1510e-01, -3.5296e-01,\n",
      "         5.7931e-01, -3.1476e-01, -9.4901e-02, -3.9190e-01, -6.9694e-01,\n",
      "        -1.0447e-02,  2.3938e-01, -1.7280e-01, -5.3704e-01,  1.0612e+00,\n",
      "         5.0175e-01, -1.1020e-02,  3.8966e-01,  4.2643e-01, -9.9510e-03,\n",
      "         2.0185e-01, -4.3824e-01,  3.2814e-01, -4.8346e-01, -3.2599e-01,\n",
      "         1.8513e-01, -4.6976e-02,  4.5525e-01,  6.4502e-01, -3.2612e-02,\n",
      "         8.7192e-02, -2.1008e-01,  2.8687e-02,  1.1076e-01, -3.0017e-01,\n",
      "        -5.0154e-02,  3.8217e-01,  2.6532e-02,  1.2623e-01,  1.0394e-01,\n",
      "         4.3786e-02, -1.1118e-01,  2.8052e-02, -6.8033e-03, -5.0394e-03,\n",
      "         4.3601e-01,  8.1189e-02, -7.4181e-02, -3.6765e-01, -1.9569e-02,\n",
      "         1.4345e-01,  2.8632e-01, -2.6073e-01,  3.6885e-02, -3.4718e-01,\n",
      "         5.2495e-01,  3.8395e-01,  1.5273e-01, -2.1628e-01,  3.4222e-01,\n",
      "        -3.4717e-01,  1.3506e-01, -2.9593e-01, -4.3897e-01,  6.6618e-02,\n",
      "        -6.0420e-01,  4.6465e-01, -4.1210e-01,  6.5812e-01,  3.3184e-01,\n",
      "         2.2699e-01,  1.5620e-01,  3.7608e-01, -3.8086e-02, -3.2624e-01,\n",
      "        -1.5369e-01, -4.2839e-01, -4.0469e-01, -8.9543e-03, -6.6050e-01,\n",
      "         1.9467e-01,  8.0796e-01, -4.7144e-01, -6.3811e-01,  3.5103e-01,\n",
      "        -3.6293e-01, -2.7268e-01, -3.6439e-01,  5.5532e-02,  1.3991e-01,\n",
      "         8.0138e-01, -5.7100e-01,  1.0608e+00,  2.4445e-01, -7.6118e-01,\n",
      "         2.2254e-02,  1.3983e-02,  6.2986e-01, -7.3683e-02,  8.0212e-01,\n",
      "        -2.8109e-01,  6.6694e-01, -6.7035e-01, -9.6533e-02, -1.9628e-02,\n",
      "         1.3905e-01,  5.9583e-02,  4.8975e-02,  5.6256e-01, -2.9041e-01,\n",
      "         5.6460e-02,  4.1767e-01, -7.3050e-01,  2.9958e-02, -5.7242e-01,\n",
      "         3.7911e-01,  8.6302e-01, -8.6317e-01, -9.3029e-01, -8.1289e-02,\n",
      "        -7.8378e-02, -2.2158e-01, -3.6283e-02,  5.3579e-01, -5.3185e-01,\n",
      "         5.7798e-01,  3.4648e-01,  2.6285e-01, -1.8939e-01, -1.6681e-01,\n",
      "         7.8349e-01,  1.9662e-01,  1.2939e-01, -4.4017e-01,  4.0976e-01,\n",
      "         4.2476e-01, -4.9217e-01,  6.2978e-01, -1.4613e-01, -1.6054e-01,\n",
      "         7.4404e-01,  1.6765e-01, -3.2840e-01,  4.1663e-01,  6.0308e-01,\n",
      "        -1.0861e+00,  5.4388e-01, -9.2215e-01, -4.8429e-01, -1.3947e+00,\n",
      "         2.5982e-01,  1.4184e+00,  3.7120e-01, -9.2127e-01, -1.4159e+00,\n",
      "         1.6531e-02, -6.3792e-01,  5.1167e-01,  3.6167e-01, -1.3585e-01,\n",
      "         6.1094e-01,  2.7156e-01,  4.9552e-01, -1.0393e+00,  2.9700e-01,\n",
      "        -6.7169e-01, -7.1377e-01,  2.5848e-01,  7.3621e-02,  5.0331e-02,\n",
      "         2.2472e-01, -3.8532e-01,  9.9617e-03, -6.7879e-02, -7.7955e-02,\n",
      "        -4.4956e-01,  1.8528e+00,  1.5305e+00,  2.2598e-01, -5.8522e-01,\n",
      "         4.8994e-01,  6.9847e-01, -3.4993e-01,  4.0096e-01,  1.5367e+00,\n",
      "        -1.2456e-01, -9.0872e-01, -4.7142e-01, -1.1398e+00,  1.6423e+00,\n",
      "        -6.9061e-01, -8.8025e-01, -1.3386e+00, -5.0809e-01, -3.1707e-01,\n",
      "         2.0900e-01, -2.8918e-01, -3.6064e-01,  1.5625e-01,  6.1036e-02,\n",
      "        -4.7900e-01,  9.4345e-01,  3.1026e-01, -5.6936e-01,  5.1809e-01,\n",
      "         9.4103e-01, -4.7187e-01])\n"
     ]
    }
   ],
   "source": [
    "sequence = TrainTweetsDataset[0][0]\n",
    "sequence_embeddings = pretrained_embeddings_layer(sequence)\n",
    "\n",
    "print('Embedding of the first token:          {}'.format(sequence_embeddings[0]))\n",
    "print('Embedding of the second token:         {}'.format(sequence_embeddings[1]))\n",
    "print('Embedding of the third token:          {}'.format(sequence_embeddings[2]))\n",
    "print('Embedding of the fourth token:         {}'.format(sequence_embeddings[3]))\n",
    "print('Embedding of the fifth token:          {}'.format(sequence_embeddings[4]))\n",
    "print('Embedding of the sixth token:          {}'.format(sequence_embeddings[5]))\n",
    "print('Embedding of the twenty-fifth token:   {}'.format(sequence_embeddings[24]))\n",
    "print('Embedding of the fortieth token:       {}'.format(sequence_embeddings[39]))\n",
    "print('Embedding of the fiftieth token:       {}'.format(sequence_embeddings[44]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Neural Network with TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the TF-IDF column to a torch tensor\n",
    "X_train = torch.FloatTensor(tweets_train['TFIDF'].tolist())\n",
    "# Convert the target column to a torch tensor\n",
    "y_train = torch.FloatTensor(tweets_train['target'].tolist()).unsqueeze(1)\n",
    "\n",
    "# Convert the TF-IDF column to a torch tensor\n",
    "X_test = torch.FloatTensor(tweets_test['TFIDF'].tolist())\n",
    "# Convert the target column to a torch tensor\n",
    "y_test = torch.FloatTensor(tweets_test['target'].tolist()).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch Dataset object\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# Create a torch DataLoader object\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1024)\n",
    "\n",
    "# Create a torch Dataset object\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "# Create a torch DataLoader object\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customFCNN = CustomFCNN(input_size = X_train.shape[1], hidden_size = 2048, dropout_rate = 0.5).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customFCNN.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customFCNN, train_loader, test_loader, optimizer, criterion, epochs = 32, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LSTM Neural Network with Custom Pre-trained Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:50.418593600Z",
     "start_time": "2023-12-21T15:34:50.412589100Z"
    }
   },
   "outputs": [],
   "source": [
    "TrainTweetsDataset_SkipGram = TweetsDataset(tweets_train, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_SkipGram, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_SkipGram = TweetsDataset(tweets_test, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TestTweetsDataset_SkipGram, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM = CustomLSTM(word2vec_model = skipgram_model,\n",
    "                                  hidden_size = 64, \n",
    "                                  output_size = 1, \n",
    "                                  num_layers = 1, \n",
    "                                  bidirectional = True,\n",
    "                                  freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "======== Training phase ========\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6774 | Accuracy = 59.02% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 46.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6843\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7019 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 83.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6833\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 2/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6768 | Accuracy = 59.02% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 53.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6835\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7065 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 91.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6840\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 3/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7041 | Accuracy = 50.82% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 54.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6839\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7041 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 89.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6835\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 4/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7111 | Accuracy = 47.54% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 54.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6836\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7010 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 93.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6832\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 5/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6907 | Accuracy = 54.10% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 53.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6838\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6987 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 88.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6834\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 6/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6674 | Accuracy = 62.30% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 54.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6836\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7021 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 92.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6833\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 7/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6619 | Accuracy = 63.93% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 53.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6835\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7028 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 90.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6833\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 8/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6417 | Accuracy = 70.49% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 54.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6838\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7027 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 92.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6833\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 9/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7000 | Accuracy = 50.82% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 53.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6837\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7003 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 90.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6832\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 10/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7133 | Accuracy = 47.54% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 54.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6835\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7024 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 89.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6833\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 11/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7021 | Accuracy = 49.18% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 54.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6836\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6983 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 90.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6835\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 12/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6760 | Accuracy = 60.66% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 52.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6837\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6972 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 90.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6838\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 13/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6725 | Accuracy = 60.66% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 53.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6836\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7017 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 88.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6832\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 14/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6567 | Accuracy = 67.21% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 53.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6835\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6997 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 90.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6833\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 15/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7049 | Accuracy = 49.18% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 53.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6835\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7003 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 89.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6832\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 16/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6873 | Accuracy = 55.74% | F1-Score = 0.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:02<00:00, 54.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6834\n",
      "Training Accuracy = 57.03%\n",
      "Training F1-Score = 0.00%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7028 | Accuracy = 50.79% | F1-Score = 0.00% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 92.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6833\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM_Attention = CustomLSTM_Attention(word2vec_model = skipgram_model, \n",
    "                                                      hidden_size = 64, \n",
    "                                                      output_size = 1, \n",
    "                                                      num_layers = 1, \n",
    "                                                      bidirectional = True,\n",
    "                                                      freeze_embeddings = False).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM_Attention.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6268 | Accuracy = 65.57% | F1-Score = 16.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 26.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6743\n",
      "Training Accuracy = 57.40%\n",
      "Training F1-Score = 8.31%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6510 | Accuracy = 55.56% | F1-Score = 22.22% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 92.93it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6568\n",
      "Test Accuracy = 62.43%\n",
      "Test F1-Score = 28.72%\n",
      "\n",
      "Epoch 2/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5190 | Accuracy = 77.05% | F1-Score = 75.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.5731\n",
      "Training Accuracy = 72.90%\n",
      "Training F1-Score = 61.80%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3937 | Accuracy = 87.30% | F1-Score = 86.67% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 97.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5265\n",
      "Test Accuracy = 75.73%\n",
      "Test F1-Score = 71.12%\n",
      "\n",
      "Epoch 3/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5158 | Accuracy = 75.41% | F1-Score = 66.67% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4592\n",
      "Training Accuracy = 79.43%\n",
      "Training F1-Score = 74.29%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3264 | Accuracy = 90.48% | F1-Score = 89.66% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 96.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4708\n",
      "Test Accuracy = 79.25%\n",
      "Test F1-Score = 73.19%\n",
      "\n",
      "Epoch 4/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3705 | Accuracy = 81.97% | F1-Score = 77.55% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4173\n",
      "Training Accuracy = 81.75%\n",
      "Training F1-Score = 77.51%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3227 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 92.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4593\n",
      "Test Accuracy = 79.68%\n",
      "Test F1-Score = 73.34%\n",
      "\n",
      "Epoch 5/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3323 | Accuracy = 85.25% | F1-Score = 83.02% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3887\n",
      "Training Accuracy = 83.19%\n",
      "Training F1-Score = 79.37%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3224 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 98.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4539\n",
      "Test Accuracy = 79.96%\n",
      "Test F1-Score = 73.94%\n",
      "\n",
      "Epoch 6/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3259 | Accuracy = 86.89% | F1-Score = 84.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3627\n",
      "Training Accuracy = 84.64%\n",
      "Training F1-Score = 81.26%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3266 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 98.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4537\n",
      "Test Accuracy = 79.93%\n",
      "Test F1-Score = 73.73%\n",
      "\n",
      "Epoch 7/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3547 | Accuracy = 86.89% | F1-Score = 80.95% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3325\n",
      "Training Accuracy = 86.34%\n",
      "Training F1-Score = 83.41%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3401 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 98.10it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4651\n",
      "Test Accuracy = 79.74%\n",
      "Test F1-Score = 73.34%\n",
      "\n",
      "Epoch 8/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3238 | Accuracy = 85.25% | F1-Score = 82.35% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3041\n",
      "Training Accuracy = 87.53%\n",
      "Training F1-Score = 84.94%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3464 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 97.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4673\n",
      "Test Accuracy = 78.85%\n",
      "Test F1-Score = 74.16%\n",
      "\n",
      "Epoch 9/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3289 | Accuracy = 86.89% | F1-Score = 80.00% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2686\n",
      "Training Accuracy = 89.52%\n",
      "Training F1-Score = 87.51%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3749 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 98.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4905\n",
      "Test Accuracy = 79.01%\n",
      "Test F1-Score = 74.16%\n",
      "\n",
      "Epoch 10/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2779 | Accuracy = 86.89% | F1-Score = 88.89% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.2313\n",
      "Training Accuracy = 91.21%\n",
      "Training F1-Score = 89.53%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4015 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 99.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5230\n",
      "Test Accuracy = 78.70%\n",
      "Test F1-Score = 73.05%\n",
      "\n",
      "Epoch 11/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1556 | Accuracy = 91.80% | F1-Score = 91.23% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1961\n",
      "Training Accuracy = 92.55%\n",
      "Training F1-Score = 91.18%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4473 | Accuracy = 87.30% | F1-Score = 86.21% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 98.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5887\n",
      "Test Accuracy = 77.54%\n",
      "Test F1-Score = 70.43%\n",
      "\n",
      "Epoch 12/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1139 | Accuracy = 96.72% | F1-Score = 97.22% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1638\n",
      "Training Accuracy = 94.22%\n",
      "Training F1-Score = 93.20%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4767 | Accuracy = 84.13% | F1-Score = 83.33% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 103.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6200\n",
      "Test Accuracy = 77.14%\n",
      "Test F1-Score = 70.77%\n",
      "\n",
      "Epoch 13/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1330 | Accuracy = 93.44% | F1-Score = 91.30% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1370\n",
      "Training Accuracy = 95.32%\n",
      "Training F1-Score = 94.51%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5336 | Accuracy = 80.95% | F1-Score = 80.65% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 98.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6587\n",
      "Test Accuracy = 75.39%\n",
      "Test F1-Score = 70.55%\n",
      "\n",
      "Epoch 14/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.0745 | Accuracy = 98.36% | F1-Score = 97.30% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1192\n",
      "Training Accuracy = 95.77%\n",
      "Training F1-Score = 95.04%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5117 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 99.26it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6985\n",
      "Test Accuracy = 76.03%\n",
      "Test F1-Score = 70.04%\n",
      "\n",
      "Epoch 15/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1669 | Accuracy = 95.08% | F1-Score = 94.12% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.78it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.1016\n",
      "Training Accuracy = 96.40%\n",
      "Training F1-Score = 95.78%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5561 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 102.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.7562\n",
      "Test Accuracy = 75.82%\n",
      "Test F1-Score = 69.41%\n",
      "\n",
      "Epoch 16/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1382 | Accuracy = 96.72% | F1-Score = 95.65% | Batch ID = 119 : 100%|██████████| 119/119 [00:04<00:00, 27.72it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.0899\n",
      "Training Accuracy = 96.86%\n",
      "Training F1-Score = 96.33%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5597 | Accuracy = 85.71% | F1-Score = 84.75% | Batch ID = 51 : 100%|██████████| 51/51 [00:00<00:00, 100.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.7993\n",
      "Test Accuracy = 75.61%\n",
      "Test F1-Score = 69.36%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM_Attention, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "\n",
    "customPreTrainedLSTM_MultiheadAttention = CustomLSTM_MultiHeadAttention(word2vec_model = skipgram_model,\n",
    "                                                                        hidden_size = 1024, \n",
    "                                                                        output_size = 1, \n",
    "                                                                        dropout = 0.1,\n",
    "                                                                        num_layers = 1, \n",
    "                                                                        bidirectional = True,\n",
    "                                                                        freeze_embeddings = True,\n",
    "                                                                        num_heads = 16).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM_MultiheadAttention.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(model = customPreTrainedLSTM_MultiheadAttention, \n",
    "                                                       train_loader = TrainDataLoader_SkipGram, \n",
    "                                                       test_loader = TestDataLoader_SkipGram, \n",
    "                                                       optimizer = optimizer, \n",
    "                                                       loss_func = criterion, \n",
    "                                                       epochs = 16, \n",
    "                                                       device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_CBOW = TweetsDataset(tweets_train, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_CBOW, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_CBOW = TweetsDataset(tweets_test, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TestTweetsDataset_CBOW, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM = CustomLSTM(word2vec_model = cbow_model,\n",
    "                                  hidden_size = 64, \n",
    "                                  output_size = 1, \n",
    "                                  num_layers = 1, \n",
    "                                  bidirectional = True,\n",
    "                                  freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM_Attention = CustomLSTM_Attention(word2vec_model = cbow_model, \n",
    "                                                      hidden_size = 64, \n",
    "                                                      output_size = 1, \n",
    "                                                      num_layers = 1, \n",
    "                                                      bidirectional = True,\n",
    "                                                      freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(customPreTrainedLSTM_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM_Attention, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GRU Neural Network with Custom Pre-trained Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_SkipGram = TweetsDataset(tweets_train, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_SkipGram, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_SkipGram = TweetsDataset(tweets_test, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TestTweetsDataset_SkipGram, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU = CustomGRU(word2vec_model = skipgram_model, \n",
    "                                hidden_size = 64, \n",
    "                                output_size = 1, \n",
    "                                num_layers = 1, \n",
    "                                bidirectional = True,\n",
    "                                freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU_Attention = CustomGRU_Attention(word2vec_model = skipgram_model, \n",
    "                                                    hidden_size = 64, \n",
    "                                                    output_size = 1, \n",
    "                                                    num_layers = 1, \n",
    "                                                    bidirectional = True,\n",
    "                                                    freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU_Attention, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_CBOW = TweetsDataset(tweets_train, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_CBOW, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_CBOW = TweetsDataset(tweets_test, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TestTweetsDataset_CBOW, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU = CustomGRU(word2vec_model = cbow_model, \n",
    "                                hidden_size = 64, \n",
    "                                output_size = 1, \n",
    "                                num_layers = 1, \n",
    "                                bidirectional = True,\n",
    "                                freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU_Attention = CustomGRU_Attention(word2vec_model = cbow_model, \n",
    "                                                    hidden_size = 64, \n",
    "                                                    output_size = 1, \n",
    "                                                    num_layers = 1, \n",
    "                                                    bidirectional = True,\n",
    "                                                    freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU_Attention, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 8, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer implemented from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDatasetEncoder = TweetsDatasetEncoderTransformer(tweets_train, 'skipgram', attn_masks_train)\n",
    "TestDatasetEncoder = TweetsDatasetEncoderTransformer(tweets_test, 'skipgram', attn_masks_test)\n",
    "\n",
    "TrainDataLoaderEncoder = torch.utils.data.DataLoader(dataset = TrainDatasetEncoder, batch_size = 32, shuffle = True)\n",
    "TestDataLoaderEncoder = torch.utils.data.DataLoader(dataset = TestDatasetEncoder, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = set_device()\n",
    "TransformerEncoder = EncoderTransformer(word2vec_model = skipgram_model,\n",
    "                                        d_model = 512,\n",
    "                                        num_heads = 16,\n",
    "                                        num_layers = 8,\n",
    "                                        d_ff = 2048,\n",
    "                                        max_seq_length = 50,\n",
    "                                        dropout = 0.1,\n",
    "                                        freeze_embeddings = False).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(TransformerEncoder.parameters(), lr = 5e-5, weight_decay = 0.01)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoaderEncoder) * 16), \n",
    "                                            num_training_steps = len(TrainDataLoaderEncoder) * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2294 | Accuracy = 93.10% | F1-Score = 92.86% | Batch ID = 238 : 100%|██████████| 238/238 [00:38<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3734\n",
      "Training Accuracy = 83.11%\n",
      "Training F1-Score = 79.37%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3577 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4869\n",
      "Test Accuracy = 77.81%\n",
      "Test F1-Score = 69.01%\n",
      "\n",
      "Epoch 2/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2975 | Accuracy = 86.21% | F1-Score = 77.78% | Batch ID = 238 : 100%|██████████| 238/238 [00:38<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3744\n",
      "Training Accuracy = 83.38%\n",
      "Training F1-Score = 79.70%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3440 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4764\n",
      "Test Accuracy = 78.42%\n",
      "Test F1-Score = 70.72%\n",
      "\n",
      "Epoch 3/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4019 | Accuracy = 79.31% | F1-Score = 76.92% | Batch ID = 238 : 100%|██████████| 238/238 [00:38<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3808\n",
      "Training Accuracy = 83.52%\n",
      "Training F1-Score = 79.90%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3512 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4823\n",
      "Test Accuracy = 78.09%\n",
      "Test F1-Score = 69.82%\n",
      "\n",
      "Epoch 4/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.1975 | Accuracy = 93.10% | F1-Score = 91.67% | Batch ID = 238 : 100%|██████████| 238/238 [00:39<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3779\n",
      "Training Accuracy = 83.41%\n",
      "Training F1-Score = 79.72%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3588 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4883\n",
      "Test Accuracy = 77.81%\n",
      "Test F1-Score = 68.90%\n",
      "\n",
      "Epoch 5/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2939 | Accuracy = 96.55% | F1-Score = 95.65% | Batch ID = 238 : 100%|██████████| 238/238 [00:39<00:00,  6.09it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3748\n",
      "Training Accuracy = 83.67%\n",
      "Training F1-Score = 80.05%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3512 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 25.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4820\n",
      "Test Accuracy = 78.15%\n",
      "Test F1-Score = 69.83%\n",
      "\n",
      "Epoch 6/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4114 | Accuracy = 79.31% | F1-Score = 76.92% | Batch ID = 238 : 100%|██████████| 238/238 [00:38<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3759\n",
      "Training Accuracy = 83.45%\n",
      "Training F1-Score = 79.77%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3510 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 25.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4815\n",
      "Test Accuracy = 78.18%\n",
      "Test F1-Score = 70.03%\n",
      "\n",
      "Epoch 7/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3697 | Accuracy = 79.31% | F1-Score = 75.00% | Batch ID = 238 : 100%|██████████| 238/238 [00:38<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3778\n",
      "Training Accuracy = 83.57%\n",
      "Training F1-Score = 79.91%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3610 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4905\n",
      "Test Accuracy = 77.63%\n",
      "Test F1-Score = 68.67%\n",
      "\n",
      "Epoch 8/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4228 | Accuracy = 82.76% | F1-Score = 78.26% | Batch ID = 238 : 100%|██████████| 238/238 [00:38<00:00,  6.26it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3736\n",
      "Training Accuracy = 83.73%\n",
      "Training F1-Score = 79.95%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3538 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4837\n",
      "Test Accuracy = 78.03%\n",
      "Test F1-Score = 69.58%\n",
      "\n",
      "Epoch 9/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2762 | Accuracy = 86.21% | F1-Score = 80.00% | Batch ID = 238 : 100%|██████████| 238/238 [00:37<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3813\n",
      "Training Accuracy = 83.25%\n",
      "Training F1-Score = 79.69%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3508 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4808\n",
      "Test Accuracy = 78.33%\n",
      "Test F1-Score = 70.21%\n",
      "\n",
      "Epoch 10/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2433 | Accuracy = 93.10% | F1-Score = 90.91% | Batch ID = 238 : 100%|██████████| 238/238 [00:37<00:00,  6.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3772\n",
      "Training Accuracy = 83.79%\n",
      "Training F1-Score = 80.12%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3507 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4810\n",
      "Test Accuracy = 78.18%\n",
      "Test F1-Score = 69.91%\n",
      "\n",
      "Epoch 11/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2686 | Accuracy = 89.66% | F1-Score = 90.32% | Batch ID = 238 : 100%|██████████| 238/238 [00:39<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3716\n",
      "Training Accuracy = 83.87%\n",
      "Training F1-Score = 80.32%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3547 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4839\n",
      "Test Accuracy = 78.15%\n",
      "Test F1-Score = 69.85%\n",
      "\n",
      "Epoch 12/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2588 | Accuracy = 89.66% | F1-Score = 88.00% | Batch ID = 238 : 100%|██████████| 238/238 [00:39<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3816\n",
      "Training Accuracy = 83.34%\n",
      "Training F1-Score = 79.60%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3557 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 25.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4858\n",
      "Test Accuracy = 77.93%\n",
      "Test F1-Score = 69.34%\n",
      "\n",
      "Epoch 13/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3708 | Accuracy = 89.66% | F1-Score = 86.96% | Batch ID = 238 : 100%|██████████| 238/238 [00:39<00:00,  6.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3775\n",
      "Training Accuracy = 83.48%\n",
      "Training F1-Score = 79.73%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3552 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 25.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4854\n",
      "Test Accuracy = 77.97%\n",
      "Test F1-Score = 69.42%\n",
      "\n",
      "Epoch 14/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3075 | Accuracy = 89.66% | F1-Score = 86.96% | Batch ID = 238 : 100%|██████████| 238/238 [00:38<00:00,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3720\n",
      "Training Accuracy = 83.75%\n",
      "Training F1-Score = 80.12%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3578 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4871\n",
      "Test Accuracy = 78.00%\n",
      "Test F1-Score = 69.50%\n",
      "\n",
      "Epoch 15/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4453 | Accuracy = 82.76% | F1-Score = 82.76% | Batch ID = 238 : 100%|██████████| 238/238 [00:39<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3821\n",
      "Training Accuracy = 82.82%\n",
      "Training F1-Score = 78.90%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3574 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 25.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4880\n",
      "Test Accuracy = 77.69%\n",
      "Test F1-Score = 68.70%\n",
      "\n",
      "Epoch 16/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3143 | Accuracy = 89.66% | F1-Score = 88.89% | Batch ID = 238 : 100%|██████████| 238/238 [00:39<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3725\n",
      "Training Accuracy = 83.79%\n",
      "Training F1-Score = 80.10%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3488 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:03<00:00, 26.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4798\n",
      "Test Accuracy = 78.39%\n",
      "Test F1-Score = 70.49%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_EncoderTransformer(model = TransformerEncoder, \n",
    "                                                                          train_loader = TrainDataLoaderEncoder, \n",
    "                                                                          test_loader = TestDataLoaderEncoder, \n",
    "                                                                          optimizer = optimizer, \n",
    "                                                                          scheduler = scheduler,\n",
    "                                                                          loss_func = criterion, \n",
    "                                                                          epochs = 16, \n",
    "                                                                          device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDatasetEncoder = TweetsDatasetEncoderTransformer(tweets_train, 'cbow', attn_masks_train)\n",
    "TestDatasetEncoder = TweetsDatasetEncoderTransformer(tweets_test, 'cbow', attn_masks_test)\n",
    "\n",
    "TrainDataLoaderEncoder = torch.utils.data.DataLoader(dataset = TrainDatasetEncoder, batch_size = 32, shuffle = True)\n",
    "TestDataLoaderEncoder = torch.utils.data.DataLoader(dataset = TestDatasetEncoder, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "device = set_device()\n",
    "TransformerEncoder = EncoderTransformer(word2vec_model = cbow_model,\n",
    "                                        d_model = 512,\n",
    "                                        num_heads = 16,\n",
    "                                        num_layers = 16,\n",
    "                                        d_ff = 2048,\n",
    "                                        max_seq_length = 50,\n",
    "                                        dropout = 0.1,\n",
    "                                        freeze_embeddings = False).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(TransformerEncoder.parameters(), lr = 5e-5, weight_decay = 0.01)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoaderEncoder) * 16), \n",
    "                                            num_training_steps = len(TrainDataLoaderEncoder) * 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6981 | Accuracy = 51.72% | F1-Score = 50.00% | Batch ID = 238 : 100%|██████████| 238/238 [01:45<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.7186\n",
      "Training Accuracy = 52.78%\n",
      "Training F1-Score = 47.50%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6256 | Accuracy = 74.19% | F1-Score = 82.61% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6618\n",
      "Test Accuracy = 60.99%\n",
      "Test F1-Score = 63.70%\n",
      "\n",
      "Epoch 2/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5920 | Accuracy = 68.97% | F1-Score = 60.87% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6188\n",
      "Training Accuracy = 67.28%\n",
      "Training F1-Score = 62.23%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 5.1084 | Accuracy = 29.03% | F1-Score = 0.00% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 3.9953\n",
      "Test Accuracy = 57.09%\n",
      "Test F1-Score = 0.28%\n",
      "\n",
      "Epoch 3/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6555 | Accuracy = 72.41% | F1-Score = 71.43% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.5455\n",
      "Training Accuracy = 74.08%\n",
      "Training F1-Score = 69.10%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2951 | Accuracy = 83.87% | F1-Score = 88.89% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5780\n",
      "Test Accuracy = 70.64%\n",
      "Test F1-Score = 70.40%\n",
      "\n",
      "Epoch 4/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7360 | Accuracy = 62.07% | F1-Score = 52.17% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.5192\n",
      "Training Accuracy = 75.99%\n",
      "Training F1-Score = 70.93%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5499 | Accuracy = 83.87% | F1-Score = 87.18% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.9207\n",
      "Test Accuracy = 71.68%\n",
      "Test F1-Score = 52.12%\n",
      "\n",
      "Epoch 5/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3436 | Accuracy = 82.76% | F1-Score = 76.19% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4786\n",
      "Training Accuracy = 77.59%\n",
      "Training F1-Score = 72.52%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2878 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:07<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4762\n",
      "Test Accuracy = 77.78%\n",
      "Test F1-Score = 69.88%\n",
      "\n",
      "Epoch 6/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4792 | Accuracy = 72.41% | F1-Score = 63.64% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4619\n",
      "Training Accuracy = 78.65%\n",
      "Training F1-Score = 73.86%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5291 | Accuracy = 80.65% | F1-Score = 84.21% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6498\n",
      "Test Accuracy = 72.76%\n",
      "Test F1-Score = 54.43%\n",
      "\n",
      "Epoch 7/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4182 | Accuracy = 82.76% | F1-Score = 76.19% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4515\n",
      "Training Accuracy = 79.59%\n",
      "Training F1-Score = 74.81%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3957 | Accuracy = 83.87% | F1-Score = 87.18% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5273\n",
      "Test Accuracy = 76.03%\n",
      "Test F1-Score = 63.73%\n",
      "\n",
      "Epoch 8/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2932 | Accuracy = 89.66% | F1-Score = 88.00% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4397\n",
      "Training Accuracy = 80.02%\n",
      "Training F1-Score = 75.52%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2645 | Accuracy = 83.87% | F1-Score = 88.37% | Batch ID = 102 : 100%|██████████| 102/102 [00:07<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4780\n",
      "Test Accuracy = 77.02%\n",
      "Test F1-Score = 70.84%\n",
      "\n",
      "Epoch 9/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4798 | Accuracy = 79.31% | F1-Score = 76.92% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4310\n",
      "Training Accuracy = 80.84%\n",
      "Training F1-Score = 76.51%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3141 | Accuracy = 83.87% | F1-Score = 88.37% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4887\n",
      "Test Accuracy = 76.49%\n",
      "Test F1-Score = 72.62%\n",
      "\n",
      "Epoch 10/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6287 | Accuracy = 68.97% | F1-Score = 64.00% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4192\n",
      "Training Accuracy = 81.47%\n",
      "Training F1-Score = 77.33%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.8571 | Accuracy = 80.65% | F1-Score = 84.21% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 1.4445\n",
      "Test Accuracy = 72.54%\n",
      "Test F1-Score = 54.97%\n",
      "\n",
      "Epoch 11/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4115 | Accuracy = 82.76% | F1-Score = 81.48% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4185\n",
      "Training Accuracy = 81.68%\n",
      "Training F1-Score = 77.64%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3185 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4768\n",
      "Test Accuracy = 77.69%\n",
      "Test F1-Score = 71.54%\n",
      "\n",
      "Epoch 12/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2199 | Accuracy = 96.55% | F1-Score = 94.12% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4041\n",
      "Training Accuracy = 81.91%\n",
      "Training F1-Score = 77.94%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3167 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4682\n",
      "Test Accuracy = 78.30%\n",
      "Test F1-Score = 72.15%\n",
      "\n",
      "Epoch 13/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2876 | Accuracy = 86.21% | F1-Score = 80.00% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3968\n",
      "Training Accuracy = 82.61%\n",
      "Training F1-Score = 78.75%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3038 | Accuracy = 83.87% | F1-Score = 88.37% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5168\n",
      "Test Accuracy = 75.64%\n",
      "Test F1-Score = 73.24%\n",
      "\n",
      "Epoch 14/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3568 | Accuracy = 82.76% | F1-Score = 73.68% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3882\n",
      "Training Accuracy = 82.96%\n",
      "Training F1-Score = 79.24%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3711 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 15.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.5041\n",
      "Test Accuracy = 77.14%\n",
      "Test F1-Score = 69.45%\n",
      "\n",
      "Epoch 15/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3184 | Accuracy = 82.76% | F1-Score = 78.26% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3785\n",
      "Training Accuracy = 83.52%\n",
      "Training F1-Score = 80.07%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3838 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4965\n",
      "Test Accuracy = 77.72%\n",
      "Test F1-Score = 69.72%\n",
      "\n",
      "Epoch 16/16\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3113 | Accuracy = 89.66% | F1-Score = 85.71% | Batch ID = 238 : 100%|██████████| 238/238 [01:17<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3712\n",
      "Training Accuracy = 83.73%\n",
      "Training F1-Score = 80.34%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3561 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 15.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4875\n",
      "Test Accuracy = 77.51%\n",
      "Test F1-Score = 72.11%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_EncoderTransformer(model = TransformerEncoder, \n",
    "                                                                          train_loader = TrainDataLoaderEncoder, \n",
    "                                                                          test_loader = TestDataLoaderEncoder, \n",
    "                                                                          optimizer = optimizer, \n",
    "                                                                          scheduler = scheduler,\n",
    "                                                                          loss_func = criterion, \n",
    "                                                                          epochs = 16, \n",
    "                                                                          device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistilBERTbase_name = \"distilbert-base-uncased\"\n",
    "DistilBERTbase_tokenizer = DistilBertTokenizer.from_pretrained(DistilBERTbase_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = DistilBERTbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = DistilBERTbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a model savel with extentions .bin\n",
    "DistilBERTbase = DistilBertForSequenceClassification.from_pretrained(DistilBERTbase_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "DistilBERTbase = DistilBERTbase.to(device)\n",
    "optimizer = torch.optim.AdamW(DistilBERTbase.parameters(), lr = 5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3902 | Accuracy = 86.21% | F1-Score = 81.82% | Batch ID = 238 : 100%|██████████| 238/238 [00:23<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4746\n",
      "Training Accuracy = 78.26%\n",
      "Training F1-Score = 71.19%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3257 | Accuracy = 83.87% | F1-Score = 88.37% | Batch ID = 102 : 100%|██████████| 102/102 [00:02<00:00, 34.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4060\n",
      "Test Accuracy = 82.53%\n",
      "Test F1-Score = 77.72%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3391 | Accuracy = 89.66% | F1-Score = 88.00% | Batch ID = 238 : 100%|██████████| 238/238 [00:23<00:00, 10.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3237\n",
      "Training Accuracy = 87.04%\n",
      "Training F1-Score = 83.80%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2873 | Accuracy = 90.32% | F1-Score = 92.68% | Batch ID = 102 : 100%|██████████| 102/102 [00:02<00:00, 34.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4070\n",
      "Test Accuracy = 82.90%\n",
      "Test F1-Score = 78.51%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(DistilBERTbase, TrainDataLoader, TestDataLoader, optimizer, scheduler, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT\n",
    "# Reference: https://arxiv.org/pdf/1810.04805.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT base (110M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTbase_name = \"bert-base-uncased\"\n",
    "BERTbase_tokenizer = BertTokenizer.from_pretrained(BERTbase_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = BERTbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = BERTbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model for sequence classification\n",
    "BERTbase = BertForSequenceClassification.from_pretrained(BERTbase_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTbase = BERTbase.to(device)\n",
    "optimizer = torch.optim.AdamW(BERTbase.parameters(), lr = 5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4286 | Accuracy = 79.31% | F1-Score = 76.92% | Batch ID = 238 : 100%|██████████| 238/238 [00:49<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4677\n",
      "Training Accuracy = 78.37%\n",
      "Training F1-Score = 72.26%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3322 | Accuracy = 90.32% | F1-Score = 93.02% | Batch ID = 102 : 100%|██████████| 102/102 [00:05<00:00, 19.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4144\n",
      "Test Accuracy = 82.47%\n",
      "Test F1-Score = 78.58%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3629 | Accuracy = 86.21% | F1-Score = 80.00% | Batch ID = 238 : 100%|██████████| 238/238 [00:49<00:00,  4.81it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3259\n",
      "Training Accuracy = 87.05%\n",
      "Training F1-Score = 83.85%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3521 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:05<00:00, 20.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4087\n",
      "Test Accuracy = 82.68%\n",
      "Test F1-Score = 78.82%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(BERTbase, TrainDataLoader, TestDataLoader, optimizer, scheduler, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT large (340M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTlarge_name = \"bert-large-uncased\"\n",
    "BERTlarge_tokenizer = BertTokenizer.from_pretrained(BERTlarge_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = BERTlarge_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = BERTlarge_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model for sequence classification\n",
    "BERTlarge = BertForSequenceClassification.from_pretrained(BERTlarge_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTlarge = BERTlarge.to(device)\n",
    "optimizer = torch.optim.AdamW(BERTlarge.parameters(), lr = 5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6820 | Accuracy = 55.17% | F1-Score = 38.10% | Batch ID = 238 : 100%|██████████| 238/238 [02:16<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6773\n",
      "Training Accuracy = 57.23%\n",
      "Training F1-Score = 38.33%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7361 | Accuracy = 29.03% | F1-Score = 0.00% | Batch ID = 102 : 100%|██████████| 102/102 [00:14<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6844\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6513 | Accuracy = 68.97% | F1-Score = 40.00% | Batch ID = 238 : 100%|██████████| 238/238 [02:15<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6926\n",
      "Training Accuracy = 55.12%\n",
      "Training F1-Score = 25.02%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7774 | Accuracy = 29.03% | F1-Score = 0.00% | Batch ID = 102 : 100%|██████████| 102/102 [00:14<00:00,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6836\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(BERTlarge, TrainDataLoader, TestDataLoader, optimizer, scheduler, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roBERTa Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTAbase_name = \"roberta-base\"\n",
    "ROBERTAbase_tokenizer = RobertaTokenizer.from_pretrained(ROBERTAbase_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = ROBERTAbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = ROBERTAbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the roBERTa model for sequence classification\n",
    "ROBERTAbase = RobertaForSequenceClassification.from_pretrained(ROBERTAbase_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "ROBERTAbase = ROBERTAbase.to(device)\n",
    "optimizer = torch.optim.AdamW(ROBERTAbase.parameters(), lr = 5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5005 | Accuracy = 68.97% | F1-Score = 57.14% | Batch ID = 238 : 100%|██████████| 238/238 [00:51<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4979\n",
      "Training Accuracy = 76.42%\n",
      "Training F1-Score = 70.02%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3027 | Accuracy = 80.65% | F1-Score = 86.36% | Batch ID = 102 : 100%|██████████| 102/102 [00:05<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4584\n",
      "Test Accuracy = 78.79%\n",
      "Test F1-Score = 76.99%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3246 | Accuracy = 86.21% | F1-Score = 86.67% | Batch ID = 238 : 100%|██████████| 238/238 [00:50<00:00,  4.71it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3696\n",
      "Training Accuracy = 84.88%\n",
      "Training F1-Score = 81.16%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3428 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:05<00:00, 17.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4399\n",
      "Test Accuracy = 80.82%\n",
      "Test F1-Score = 77.38%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(ROBERTAbase, TrainDataLoader, TestDataLoader, optimizer, scheduler, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roBERTa Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTAlarge_name = \"roberta-large\"\n",
    "ROBERTAlarge_tokenizer = RobertaTokenizer.from_pretrained(ROBERTAlarge_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = ROBERTAlarge_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = ROBERTAlarge_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the roBERTa model for sequence classification\n",
    "ROBERTAlarge = RobertaForSequenceClassification.from_pretrained(ROBERTAlarge_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "ROBERTAlarge = ROBERTAlarge.to(device)\n",
    "optimizer = torch.optim.AdamW(ROBERTAlarge.parameters(), lr = 5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4995 | Accuracy = 79.31% | F1-Score = 62.50% | Batch ID = 238 : 100%|██████████| 238/238 [02:16<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6575\n",
      "Training Accuracy = 61.25%\n",
      "Training F1-Score = 46.13%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6020 | Accuracy = 67.74% | F1-Score = 70.59% | Batch ID = 102 : 100%|██████████| 102/102 [00:15<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6239\n",
      "Test Accuracy = 66.99%\n",
      "Test F1-Score = 39.19%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.6779 | Accuracy = 62.07% | F1-Score = 15.38% | Batch ID = 238 : 100%|██████████| 238/238 [02:16<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.6864\n",
      "Training Accuracy = 56.34%\n",
      "Training F1-Score = 11.74%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.7912 | Accuracy = 29.03% | F1-Score = 0.00% | Batch ID = 102 : 100%|██████████| 102/102 [00:15<00:00,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.6844\n",
      "Test Accuracy = 57.03%\n",
      "Test F1-Score = 0.00%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(ROBERTAlarge, TrainDataLoader, TestDataLoader, optimizer, scheduler, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTweet base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "BERTweetbase_name = \"vinai/bertweet-base\"\n",
    "BERTweetbase_tokenizer = AutoTokenizer.from_pretrained(BERTweetbase_name, use_fast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERTweet(tokenizer = BERTweetbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERTweet(tokenizer = BERTweetbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BERTweetbase = AutoModel.from_pretrained(BERTweetbase_name)\n",
    "BERTweetbase = BERTweetForSequenceClassification(bertweet_model = BERTweetbase, hidden_size = 768, output_size = 1, dropout_rate = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTweetbase = BERTweetbase.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(BERTweetbase.parameters(), lr = 5e-5, weight_decay = 0.05)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5318 | Accuracy = 79.31% | F1-Score = 80.00% | Batch ID = 238 : 100%|██████████| 238/238 [01:08<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4546\n",
      "Training Accuracy = 79.59%\n",
      "Training F1-Score = 75.58%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3595 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:07<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.3747\n",
      "Test Accuracy = 83.57%\n",
      "Test F1-Score = 78.81%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.2718 | Accuracy = 89.66% | F1-Score = 84.21% | Batch ID = 238 : 100%|██████████| 238/238 [01:06<00:00,  3.57it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3165\n",
      "Training Accuracy = 87.92%\n",
      "Training F1-Score = 85.12%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4641 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 15.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4088\n",
      "Test Accuracy = 84.00%\n",
      "Test F1-Score = 80.72%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERTweet(model = BERTweetbase, \n",
    "                                                                train_loader = TrainDataLoader, \n",
    "                                                                test_loader = TestDataLoader, \n",
    "                                                                optimizer = optimizer, \n",
    "                                                                scheduler = scheduler,\n",
    "                                                                loss_func = criterion, \n",
    "                                                                epochs = 2, \n",
    "                                                                device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTweet Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "BERTweetlarge_name = \"vinai/bertweet-large\"\n",
    "BERTweetlarge_tokenizer = AutoTokenizer.from_pretrained(BERTweetlarge_name, use_fast = False)\n",
    "\n",
    "# Initialize base BERTweet tokenizer to normalize tweets (large version doesn't do it)\n",
    "BERTweetbase_name = \"vinai/bertweet-base\"\n",
    "BERTweetbase_tokenizer = AutoTokenizer.from_pretrained(BERTweetbase_name, use_fast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERTweet(tokenizer = BERTweetlarge_tokenizer, \n",
    "                                                 df = tweets_train, \n",
    "                                                 batch_size = 32, \n",
    "                                                 shuffle = True, \n",
    "                                                 tokenizer_normalizeTweet = BERTweetbase_tokenizer)\n",
    "\n",
    "TestDataset, TestDataLoader = TokenizeBERTweet(tokenizer = BERTweetlarge_tokenizer, \n",
    "                                               df = tweets_test, \n",
    "                                               batch_size = 32, \n",
    "                                               shuffle = False, \n",
    "                                               tokenizer_normalizeTweet = BERTweetbase_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERTweetlarge = AutoModelForSequenceClassification.from_pretrained(BERTweetlarge_name)\n",
    "BERTweetlarge = AutoModel.from_pretrained(BERTweetlarge_name)\n",
    "BERTweetlarge = BERTweetForSequenceClassification(bertweet_model = BERTweetlarge, hidden_size = 1024, output_size = 1, dropout_rate = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTweetlarge = BERTweetlarge.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(BERTweetlarge.parameters(), lr = 5e-5, weight_decay = 0.05)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5674 | Accuracy = 72.41% | F1-Score = 63.64% | Batch ID = 238 : 100%|██████████| 238/238 [03:35<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.5324\n",
      "Training Accuracy = 74.24%\n",
      "Training F1-Score = 69.02%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3802 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:24<00:00,  4.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4348\n",
      "Test Accuracy = 82.62%\n",
      "Test F1-Score = 79.84%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.5191 | Accuracy = 79.31% | F1-Score = 70.00% | Batch ID = 238 : 100%|██████████| 238/238 [03:32<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3744\n",
      "Training Accuracy = 84.68%\n",
      "Training F1-Score = 80.79%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4215 | Accuracy = 83.87% | F1-Score = 87.80% | Batch ID = 102 : 100%|██████████| 102/102 [00:24<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.4070\n",
      "Test Accuracy = 84.00%\n",
      "Test F1-Score = 80.68%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERTweet(BERTweetlarge, TrainDataLoader, TestDataLoader, optimizer, scheduler, criterion, epochs = 2, device = device)\n",
    "#train_losses, train_f1s, test_losses, test_f1s = train_BERT(BERTweetlarge, TrainDataLoader, TestDataLoader, optimizer, scheduler, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTweetbase_8115f1 = torch.load('/Users/luish/Desktop/BERTweetbase_0.8115f1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:09<00:00, 10.95it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true, y_hat = predict(BERTweetbase_8115f1, TestDataLoader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "╒═══════════════════════╤════════════════════════════╤══════════════════════╕\n",
      "│                       │  Predicted Not a Disaster  │  Predicted Disaster  │\n",
      "╞═══════════════════════╪════════════════════════════╪══════════════════════╡\n",
      "│ Actual Not a Disaster │            1665            │         311          │\n",
      "├───────────────────────┼────────────────────────────┼──────────────────────┤\n",
      "│    Actual Disaster    │            196             │         1091         │\n",
      "╘═══════════════════════╧════════════════════════════╧══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "ComputeConfusionMatrix(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════╤═════════╕\n",
      "│       Metric       │  Value  │\n",
      "╞════════════════════╪═════════╡\n",
      "│      Accuracy      │ 84.46%  │\n",
      "├────────────────────┼─────────┤\n",
      "│ Weighted Precision │ 77.82%  │\n",
      "├────────────────────┼─────────┤\n",
      "│  Weighted Recall   │ 84.77%  │\n",
      "├────────────────────┼─────────┤\n",
      "│ Weighted F1 Score  │ 81.15%  │\n",
      "╘════════════════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "ComputeClassificationMetrics(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability (BERTweet Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ComputeAttentionMaps(dataset = TestDataset, model = BERTweetlarge, tokenizer = BERTweetlarge_tokenizer, input_id = 3, multiheadlayer_no = 0, head_no = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ComputeAttentionMaps(dataset = TestDataset, model = BERTweetlarge, tokenizer = BERTweetlarge_tokenizer, input_id = 3, multiheadlayer_no = 2, head_no = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Multi-Head Attention from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T23:11:27.031219500Z",
     "start_time": "2023-12-29T23:11:27.022593400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout = 0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        # Output layer for binary classification\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation for binary classification\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_mask = self.generate_mask(src)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        # Global average pooling across sequence length\n",
    "        pooled_output = F.adaptive_avg_pool1d(enc_output.permute(0, 2, 1), 1).view(enc_output.size(0), -1)\n",
    "\n",
    "        # Output layer with sigmoid activation for binary classification\n",
    "        output = self.fc(pooled_output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
