{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Custom Functions & Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T23:10:35.149706Z",
     "start_time": "2023-12-29T23:10:30.436532800Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "import re\n",
    "import math\n",
    "import spacy \n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertTokenizer, DistilBertForSequenceClassification, BertTokenizer, BertForSequenceClassification, \\\n",
    "                         RobertaTokenizer, RobertaForSequenceClassification, AutoModel, AutoModelForSequenceClassification, AutoTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "# spacy.cli.download(\"en_core_web_lg\")\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Ignore RuntimeWarning and UserWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T23:10:37.072317200Z",
     "start_time": "2023-12-29T23:10:36.877905600Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub('http\\S*', ' ', text)\n",
    "    \n",
    "    # remove non-alphabetic\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    \n",
    "    # make lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove one character word\n",
    "    text = re.sub(\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "    text = re.sub(\"^[a-zA-Z]\\s+\", '', text)\n",
    "    \n",
    "    # replace double space to one space\n",
    "    text = re.sub(\"\\s+\", ' ', text)\n",
    "    \n",
    "    # tokenize, lemmatize, remove stop words\n",
    "    doc = nlp(text)\n",
    "    text = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return \" \".join(text)\n",
    "\n",
    "\n",
    "def train_BPE_tokenizer(train_text_df, text_column, vocab_size=5000, min_frequency=2):\n",
    "    # Extract the text from the specified column\n",
    "    texts = train_text_df[text_column].tolist()\n",
    "\n",
    "    # Initialize a BPE tokenizer\n",
    "    tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "    # Train the BPE tokenizer on the text\n",
    "    tokenizer.train_from_iterator(texts, vocab_size=vocab_size, min_frequency=min_frequency)\n",
    "\n",
    "    # Tokenize the text in the DataFrame and remove \"Ġ\" character\n",
    "    train_text_df[text_column + '_tokenized'] = train_text_df[text_column].apply(lambda x: [token.replace(\"Ġ\", \"\") for token in tokenizer.encode(x).tokens])\n",
    "\n",
    "    return tokenizer\n",
    "\n",
    "\n",
    "def tokenize_text(tokenizer, df, text_column):\n",
    "    # Extract the text from the specified column\n",
    "    texts = df[text_column].tolist()\n",
    "\n",
    "    # Tokenize the text in the DataFrame using the pre-trained tokenizer and remove \"Ġ\" character\n",
    "    df[text_column + '_tokenized'] = [[token.replace(\"Ġ\", \"\") for token in tokenizer.encode(text).tokens] for text in texts]\n",
    "\n",
    "\n",
    "class BPE():\n",
    "    \"\"\"Byte-Pair Encoding: Subword-based tokenization algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus, vocab_size):\n",
    "        \"\"\"Initialize BPE tokenizer.\"\"\"\n",
    "        self.corpus = corpus\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "        # pre-tokenize the corpus into words, BERT pre-tokenizer is used here\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.word_freqs = defaultdict(int)\n",
    "        self.splits = {}\n",
    "        self.merges = {}\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Train BPE tokenizer.\"\"\"\n",
    "    # (1) Compute the frequencies of each word in the corpus\n",
    "    # (2) Compute the base vocabulary of all characters in the corpus\n",
    "    # (3) Split each word into individual characters before training\n",
    "    # (4) Merge the most frequent pair iteratively until the vocabulary size is reached\n",
    "\n",
    "        # compute the frequencies of each word in the corpus\n",
    "        for text in self.corpus:\n",
    "            words_with_offsets = self.tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "            new_words = [word for word, offset in words_with_offsets]\n",
    "            for word in new_words:\n",
    "                self.word_freqs[word] += 1\n",
    "\n",
    "        # compute the base vocabulary of all characters in the corpus\n",
    "        alphabet = []\n",
    "        for word in self.word_freqs.keys():\n",
    "            for letter in word:\n",
    "                if letter not in alphabet:\n",
    "                    alphabet.append(letter)\n",
    "        alphabet.sort()\n",
    "\n",
    "        # add the special token </w> at the beginning of the vocabulary\n",
    "        vocab = [\"</w>\"] + alphabet.copy()\n",
    "\n",
    "        # split each word into individual characters before training\n",
    "        self.splits = {word: [c for c in word] for word in self.word_freqs.keys()}\n",
    "\n",
    "        # merge the most frequent pair iteratively until the vocabulary size is reached\n",
    "        while len(vocab) < self.vocab_size:\n",
    "\n",
    "            # compute the frequency of each pair\n",
    "            pair_freqs = self.compute_pair_freqs()\n",
    "\n",
    "            # find the most frequent pair\n",
    "            best_pair = \"\"\n",
    "            max_freq = None\n",
    "            for pair, freq in pair_freqs.items():\n",
    "                if max_freq is None or max_freq < freq:\n",
    "                    best_pair = pair\n",
    "                    max_freq = freq\n",
    "\n",
    "            # merge the most frequent pair\n",
    "            self.splits = self.merge_pair(*best_pair)\n",
    "            self.merges[best_pair] = best_pair[0] + best_pair[1]\n",
    "            vocab.append(best_pair[0] + best_pair[1])\n",
    "        return self.merges\n",
    "\n",
    "\n",
    "    def compute_pair_freqs(self):\n",
    "        \"\"\"Compute the frequency of each pair.\"\"\"\n",
    "\n",
    "        pair_freqs = defaultdict(int)\n",
    "        for word, freq in self.word_freqs.items():\n",
    "            split = self.splits[word]\n",
    "            if len(split) == 1:\n",
    "                continue\n",
    "            for i in range(len(split) - 1):\n",
    "                pair = (split[i], split[i + 1])\n",
    "                pair_freqs[pair] += freq\n",
    "        return pair_freqs\n",
    "\n",
    "\n",
    "    def merge_pair(self, a, b):\n",
    "        \"\"\"Merge the given pair.\"\"\"\n",
    "\n",
    "        for word in self.word_freqs:\n",
    "            split = self.splits[word]\n",
    "            if len(split) == 1:\n",
    "                continue\n",
    "            i = 0\n",
    "            while i < len(split) - 1:\n",
    "                if split[i] == a and split[i + 1] == b:\n",
    "                    split = split[:i] + [a + b] + split[i + 2 :]\n",
    "                else:\n",
    "                    i += 1\n",
    "            self.splits[word] = split\n",
    "        return self.splits\n",
    "    \n",
    "\n",
    "    def tokenize(self, text):\n",
    "        \"\"\"Tokenize a given text with trained BPE tokenizer (including pre-tokenization, split, and merge).\"\"\"\n",
    "        \n",
    "        pre_tokenize_result = self.tokenizer._tokenizer.pre_tokenizer.pre_tokenize_str(text)\n",
    "        pre_tokenized_text = [word for word, offset in pre_tokenize_result]\n",
    "        splits_text = [[l for l in word] for word in pre_tokenized_text]\n",
    "\n",
    "        for pair, merge in self.merges.items():\n",
    "            for idx, split in enumerate(splits_text):\n",
    "                i = 0\n",
    "                while i < len(split) - 1:\n",
    "                    if split[i] == pair[0] and split[i + 1] == pair[1]:\n",
    "                        split = split[:i] + [merge] + split[i + 2 :]\n",
    "                    else:\n",
    "                        i += 1\n",
    "                splits_text[idx] = split\n",
    "        result = sum(splits_text, [])\n",
    "        return result\n",
    "    \n",
    "\n",
    "def get_tfidf_matrix(df, vectorizer):\n",
    "    \n",
    "    # Convert the TF-IDF matrix to a dense NumPy array\n",
    "    matrix = df.todense()\n",
    "\n",
    "    # Convert the dense matrix to a DataFrame\n",
    "    matrix = pd.DataFrame(matrix, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "# The sequences being in the formar ['word1', 'word2', 'word3', ...], preprocess it\n",
    "def string2embedding_idx(text_sequence, model):\n",
    "\n",
    "    sequence = []\n",
    "    for token in text_sequence:\n",
    "        try:\n",
    "            sequence.append(model.wv.key_to_index[token])\n",
    "        except:\n",
    "            sequence.append(2899)\n",
    "\n",
    "    return sequence\n",
    "\n",
    "\n",
    "def TSNE_10ClosestWords(model, word, size):\n",
    "    \n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    close_words = model.wv.similar_by_word(word)\n",
    "    arr = np.append(arr, np.array([model.wv[word]]), axis=0)\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "            \n",
    "    tsne = TSNE(n_components=2, random_state=0, perplexity = 10)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "    plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "    plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class TweetsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, word2vec_model):\n",
    "        self.df = df\n",
    "        self.word2vec_model = word2vec_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.df.iloc[idx, -1 if self.word2vec_model == 'skipgram' else -2]\n",
    "        label = self.df.iloc[idx, 1]\n",
    "\n",
    "        # Convert sequence to a 1D tensor\n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.long)\n",
    "\n",
    "        # Convert label to a 1D tensor (scalar)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return sequence_tensor, label_tensor\n",
    "\n",
    "\n",
    "def set_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device('mps')\n",
    "\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    print('Device:', device)\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "def TokenizeBERT(tokenizer, df, batch_size = 32, shuffle = True):\n",
    "    # Tokenize training data\n",
    "    encodings = tokenizer(df['clean_text'].tolist(), add_special_tokens = True, truncation = True, padding = True, return_tensors = \"pt\")\n",
    "\n",
    "    # Convert labels to PyTorch tensors\n",
    "    labels = torch.tensor(df['target'].tolist())\n",
    "\n",
    "    # Create a DataLoader for training data\n",
    "    dataset = torch.utils.data.TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], labels)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def TokenizeBERTweet(tokenizer, df, batch_size = 32, shuffle = True, tokenizer_normalizeTweet = None):\n",
    "\n",
    "    # Normalize the text\n",
    "    if tokenizer_normalizeTweet is not None:\n",
    "        normalized_tweets = df['text'].apply(lambda x: tokenizer_normalizeTweet.normalizeTweet(x))\n",
    "    else:\n",
    "        normalized_tweets = df['text'].apply(lambda x: tokenizer.normalizeTweet(x))\n",
    "\n",
    "    # Tokenize training data\n",
    "    encodings = tokenizer(normalized_tweets.tolist(), add_special_tokens = True, truncation = True, padding = True, return_tensors = \"pt\")\n",
    "\n",
    "    # Convert labels to PyTorch tensors\n",
    "    labels = torch.tensor(df['target'].tolist())\n",
    "\n",
    "    # Create a DataLoader for training data\n",
    "    dataset = torch.utils.data.TensorDataset(encodings[\"input_ids\"], encodings[\"attention_mask\"], labels)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, shuffle = shuffle)\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "def train(model, train_loader, test_loader, optimizer, loss_func, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - loss_func (torch.nn.Module): The loss function used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    loss_fn = kwargs.get('loss_fn', loss_func)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, (data, target) in pbar:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            predicted = (output > 0.0).float()\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in pbar:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predicted = (output > 0.0).float()\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "\n",
    "def train_BERT(model, train_loader, test_loader, optimizer, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, data in pbar:\n",
    "            input_ids = data[0].to(device)\n",
    "            attn_mask = data[1].to(device)\n",
    "            target = data[2].to(device)\n",
    "            model.zero_grad()\n",
    "            output = model(input_ids, attention_mask=attn_mask, labels=target)\n",
    "            logits = output.logits.squeeze(-1)\n",
    "\n",
    "            loss = output.loss\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in pbar:\n",
    "                input_ids = data[0].to(device)\n",
    "                attn_mask = data[1].to(device)\n",
    "                target = data[2].to(device)\n",
    "                model.zero_grad()\n",
    "                output = model(input_ids, attention_mask=attn_mask, labels=target)\n",
    "                logits = output.logits.squeeze(-1)\n",
    "\n",
    "                loss = output.loss\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "\n",
    "def train_BERTweet(model, train_loader, test_loader, optimizer, scheduler, loss_func, epochs, device, **kwargs):\n",
    "    \"\"\"\n",
    "    Trains a neural network model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The neural network model to be trained.\n",
    "    - train_loader (torch.utils.data.DataLoader): DataLoader for the training dataset.\n",
    "    - optimizer (torch.optim.Optimizer): The optimizer used for training.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - device (torch.device): The device on which the training will be performed.\n",
    "    - **kwargs: Additional arguments for customization.\n",
    "\n",
    "    Returns:\n",
    "    - train_loss_hist (list): List containing training loss values for each epoch.\n",
    "    - train_acc_hist (list): List containing training accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    num_epochs = kwargs.get('num_epochs', epochs)\n",
    "    loss_fn = kwargs.get('loss_func', loss_func)\n",
    "    device = kwargs.get('device', device)\n",
    "\n",
    "    train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst = [], [], [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "\n",
    "        print('======== Training phase ========')\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "        for batch_idx, data in pbar:\n",
    "            input_ids = data[0].to(device)\n",
    "            attn_mask = data[1].to(device)\n",
    "            target = data[2].float().unsqueeze(1).to(device)\n",
    "            model.zero_grad()\n",
    "            logits = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "            loss = loss_fn(logits, target)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            predicted = (logits > 0.0).float()\n",
    "            correct_batch = (predicted == target).sum().item()\n",
    "            mini_batch_size = target.size(0)\n",
    "            accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "            # Compute F1-score\n",
    "            f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "            total += mini_batch_size\n",
    "            correct += correct_batch\n",
    "            # Append targets and predictions to the lists\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            pbar.set_description(\n",
    "                f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "            )\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        train_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Training Cross-Entropy Loss = {train_loss:.4f}')\n",
    "        print(f'Training Accuracy = {train_accuracy:.2f}%')\n",
    "        print(f'Training F1-Score = {train_f1_score:.2f}%')\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        print('======== Validation phase ========')\n",
    "        model.eval()\n",
    "        test_loss = 0.\n",
    "        total = 0.\n",
    "        correct = 0.\n",
    "        # Lists to store targets and predictions\n",
    "        all_targets = []\n",
    "        all_predictions = []\n",
    "\n",
    "        pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data in pbar:\n",
    "                input_ids = data[0].to(device)\n",
    "                attn_mask = data[1].to(device)\n",
    "                target = data[2].float().unsqueeze(1).to(device)\n",
    "                model.zero_grad()\n",
    "                logits = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "                loss = loss_fn(logits, target)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                predicted = (logits > 0.0).float()\n",
    "                correct_batch = (predicted == target).sum().item()\n",
    "                mini_batch_size = target.size(0)\n",
    "                accuracy_batch = 100 * correct_batch / mini_batch_size\n",
    "\n",
    "                # Compute F1-score\n",
    "                f1_score_batch = 100 * f1_score(target.cpu().numpy(), predicted.cpu().numpy(), average='binary')\n",
    "\n",
    "                total += mini_batch_size\n",
    "                correct += correct_batch\n",
    "                # Append targets and predictions to the lists\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "                pbar.set_description(\n",
    "                    f'Loss = {loss:.4f} | Accuracy = {accuracy_batch:.2f}% | F1-Score = {f1_score_batch:.2f}% | Batch ID = {batch_idx + 1} '\n",
    "                )\n",
    "\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / total\n",
    "        all_targets = np.array(all_targets)\n",
    "        all_predictions = np.array(all_predictions)\n",
    "        test_f1_score = 100 * f1_score(all_targets, all_predictions, average='binary')\n",
    "\n",
    "        print(f'Test Cross-Entropy Loss = {test_loss:.4f}')\n",
    "        print(f'Test Accuracy = {test_accuracy:.2f}%')\n",
    "        print(f'Test F1-Score = {test_f1_score:.2f}%')\n",
    "        print()\n",
    "\n",
    "        train_loss_lst.append(train_loss)\n",
    "        train_f1_lst.append(train_f1_score)\n",
    "        test_loss_lst.append(test_loss)\n",
    "        test_f1_lst.append(test_f1_score)\n",
    "\n",
    "    return train_loss_lst, train_f1_lst, test_loss_lst, test_f1_lst\n",
    "\n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings\n",
    "class CustomLSTM(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embeddings = torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.lstm(x)\n",
    "        output = self.fc(output[:, -1, :])  # Use the last time step's output\n",
    "        return output\n",
    "\n",
    "\n",
    "# GRU model with pre-trained Word2Vec embeddings\n",
    "class CustomGRU(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomGRU, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(embeddings = torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.gru(x)\n",
    "        output = self.fc(output[:, -1, :])  # Use the last time step's output\n",
    "        return output\n",
    "\n",
    "\n",
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, output):\n",
    "        # lstm_output = [batch size, seq_len, hidden_dim]\n",
    "        attention_scores = self.attn(output)\n",
    "\n",
    "        return torch.nn.functional.softmax(attention_scores, dim=1)\n",
    "\n",
    "\n",
    "\n",
    "# GRU model with pre-trained Word2Vec embeddings and attention mechanism\n",
    "class CustomGRU_Attention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomGRU_Attention, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.gru = torch.nn.GRU(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "        self.attention = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.gru(x)\n",
    "        attention_weights = torch.nn.functional.softmax(self.attention(output), dim = 1)\n",
    "        output = torch.sum(attention_weights * output, dim = 1)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings and attention mechanism\n",
    "class CustomLSTM_Attention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, num_layers = 1, bidirectional = False, freeze_embeddings = True):\n",
    "        super(CustomLSTM_Attention, self).__init__()\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.attention = Attention(hidden_size * (2 if bidirectional else 1))\n",
    "        self.fc = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the embedding of each token in the sequence\n",
    "        x = self.embedding(x)\n",
    "        # Apply LSTM to the sequence of embeddings\n",
    "        output, _ = self.lstm(x)\n",
    "        # Apply the attention mechanism and get attention weights\n",
    "        attn_weights = self.attention(output)\n",
    "        # Compute the weighted sum of the hidden states\n",
    "        output = torch.sum(attn_weights * output, dim = 1)\n",
    "        # Compute the logits\n",
    "        logits = self.fc(output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "# LSTM model with pre-trained Word2Vec embeddings and multi-head attention mechanism\n",
    "class CustomLSTM_MultiHeadAttention(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, hidden_size, output_size, dropout=0.1, num_layers=1, bidirectional=False, freeze_embeddings=True, num_heads=8):\n",
    "        super(CustomLSTM_MultiHeadAttention, self).__init__()\n",
    "\n",
    "        # Word embedding layer\n",
    "        self.embedding_dim = word2vec_model.vector_size\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze=freeze_embeddings)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.sequence_size = 49\n",
    "        self.lstm = torch.nn.LSTM(self.embedding_dim, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "\n",
    "        # Multi-Head Attention layer\n",
    "        self.multihead_attention = torch.nn.MultiheadAttention(embed_dim=hidden_size * (2 if bidirectional else 1), num_heads=num_heads, dropout=dropout, batch_first=True)\n",
    "\n",
    "        # Fully-connected layers for classification head\n",
    "        self.fc1 = torch.nn.Linear(hidden_size * (2 if bidirectional else 1) * self.sequence_size, hidden_size * (2 if bidirectional else 1))\n",
    "        self.fc2 = torch.nn.Linear(hidden_size * (2 if bidirectional else 1), output_size)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.bn = torch.nn.BatchNorm1d(hidden_size * (2 if bidirectional else 1))\n",
    "        self.classification_head = torch.nn.Sequential(self.fc1, self.relu, self.bn, self.dropout, self.fc2)\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization\n",
    "        for layer in self.classification_head:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(layer.weight, nonlinearity = 'relu')\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization for the multi-head attention\n",
    "        torch.nn.init.kaiming_uniform_(self.multihead_attention.in_proj_weight, nonlinearity = 'relu')\n",
    "\n",
    "        # Initialize the weights with the kaiming uniform initialization for the LSTM\n",
    "        for layer in self.lstm._all_weights:\n",
    "            for param_name in layer:\n",
    "                if 'weight' in param_name:\n",
    "                    torch.nn.init.kaiming_uniform_(getattr(self.lstm, param_name), nonlinearity = 'relu')\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Get the embedding of each token in the sequence\n",
    "        embed = self.embedding(x)\n",
    "        # Apply LSTM to the sequence of embeddings\n",
    "        hx, cx = self.lstm(embed)\n",
    "        # Apply multihead attention and get attention weights\n",
    "        attn_output, attn_weights = self.multihead_attention(hx, hx, hx)\n",
    "        # Flatten or pool the multihead attention outputs across the sequence dimension\n",
    "        flattened_output = attn_output.reshape(attn_output.size(0), -1)\n",
    "        # Compute the logits considering the weighted values (V) of the multihead attention\n",
    "        logits = self.classification_head(flattened_output)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        self.positional_encoding = torch.zeros((1, max_len, d_model))\n",
    "        self.positional_encoding[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        self.positional_encoding[0, :, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.positional_encoding[:, :x.size(1), :]\n",
    "\n",
    "\n",
    "class TransformerEncoder(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, embedding_dim, num_heads, hidden_dim, num_layers, max_len=512, dropout=0.1, freeze_embeddings = True):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.FloatTensor(word2vec_model.wv.vectors), freeze = freeze_embeddings)\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dim, max_len)\n",
    "        \n",
    "        self.transformer_encoder_layer = torch.nn.TransformerEncoderLayer(\n",
    "                                                                          d_model=embedding_dim,\n",
    "                                                                          nhead=num_heads,\n",
    "                                                                          dim_feedforward=hidden_dim,\n",
    "                                                                          dropout=dropout\n",
    "                                                                          )\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(self.transformer_encoder_layer, num_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = x.permute(1, 0, 2)  # Change from (batch_size, seq_len, embedding_dim) to (seq_len, batch_size, embedding_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.permute(1, 0, 2)  # Change back to (batch_size, seq_len, embedding_dim)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TransformerEncoderForClassification(torch.nn.Module):\n",
    "    def __init__(self, word2vec_model, embedding_dim, num_heads, hidden_dim, num_layers, max_len=512, dropout=0.1, freeze_embeddings = True, num_classes=1):\n",
    "        super(TransformerEncoderForClassification, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.encoder = TransformerEncoder(word2vec_model, num_heads, hidden_dim, num_layers, max_len, dropout, freeze_embeddings)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc = torch.nn.Linear(self.embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_output = self.encoder(x)\n",
    "        \n",
    "        # Global average pooling along the sequence dimension\n",
    "        pooled_output = torch.nn.functional.adaptive_avg_pool1d(encoder_output.permute(0, 2, 1), 1).squeeze(-1)\n",
    "        \n",
    "        # Classification head\n",
    "        logits = self.fc(pooled_output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "# FCNN model to be used with the TF-IDF features\n",
    "class CustomFCNN(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_rate=0.1):\n",
    "        super(CustomFCNN, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.outlayer = torch.nn.Linear(hidden_size, 1)\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "        self.bn = torch.nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn(self.relu(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn(self.relu(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        logits = self.outlayer(x)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "class BERTweetForSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, bertweet_model, hidden_size, output_size, dropout_rate = 0.1):\n",
    "        super(BERTweetForSequenceClassification, self).__init__()\n",
    "\n",
    "        self.bertweet_model = bertweet_model\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.BatchNorm = torch.nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "        self.dense = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Apply batch normalization to the output of the BERTweet model\n",
    "        output = self.BatchNorm(self.bertweet_model(input_ids, attention_mask).pooler_output)\n",
    "        # Apply dropout\n",
    "        output = self.dropout(output)\n",
    "        # Apply the output layer\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "\n",
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    pbar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in pbar:\n",
    "            input_ids = data[0].to(device)\n",
    "            attn_mask = data[1].to(device)\n",
    "            target = data[2].float().flatten().to(device)\n",
    "            model.zero_grad()\n",
    "            logits = model(input_ids, attention_mask=attn_mask)\n",
    "\n",
    "            predicted = (logits > 0.0).float().flatten()\n",
    "\n",
    "            predictions.extend(predicted.tolist())\n",
    "            labels.extend(target.tolist())\n",
    "\n",
    "    return predictions, labels\n",
    "\n",
    "\n",
    "def ComputeConfusionMatrix(labels, preds):\n",
    "    \"\"\"\n",
    "    Computes the confusion matrix for the predicted and ground truth labels.\n",
    "\n",
    "    Args:\n",
    "    - labels_gt (numpy.ndarray): Numpy array containing the ground truth labels.\n",
    "    - labels_pred (numpy.ndarray): Numpy array containing the predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    confusion_table = tabulate(cm,\n",
    "                           headers = ['Predicted ' + cls for cls in ['Not a Disaster', 'Disaster']],\n",
    "                           showindex = ['Actual ' + cls for cls in ['Not a Disaster', 'Disaster']],\n",
    "                           tablefmt=\"fancy_grid\",\n",
    "                           stralign=\"center\",\n",
    "                           numalign=\"center\"\n",
    "                           )\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_table)\n",
    "\n",
    "\n",
    "def ComputeClassificationMetrics(labels, preds):\n",
    "    \"\"\"\n",
    "    Computes the classification metrics for the predicted and ground truth labels.\n",
    "\n",
    "    Args:\n",
    "    - labels_gt (numpy.ndarray): Numpy array containing the ground truth labels.\n",
    "    - labels_pred (numpy.ndarray): Numpy array containing the predicted labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the classification metrics\n",
    "    accuracy = accuracy_score(labels, preds) * 100\n",
    "    precision = precision_score(labels, preds, average='binary') * 100\n",
    "    recall = recall_score(labels, preds, average='binary') * 100\n",
    "    f1 = f1_score(labels, preds, average='binary') * 100\n",
    "\n",
    "    results_table = [\n",
    "            [\"Accuracy\", f\"{accuracy:.2f}%\"],\n",
    "            [\"Weighted Precision\", f\"{precision:.2f}%\"],\n",
    "            [\"Weighted Recall\", f\"{recall:.2f}%\"],\n",
    "            [\"Weighted F1 Score\", f\"{f1:.2f}%\"],\n",
    "        ]\n",
    "\n",
    "    print(tabulate(results_table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\", stralign=\"center\", numalign=\"center\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-29T16:48:51.252105700Z",
     "start_time": "2023-12-29T16:48:49.728914500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0                 Just happened a terrible car crash       1\n",
       "1  Heard about #earthquake is different cities, s...       1\n",
       "2  there is a forest fire at spot pond, geese are...       1\n",
       "3           Apocalypse lighting. #Spokane #wildfires       1\n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweets_train = pd.read_csv('../data/tweets_data/train.csv')[['text', 'target']].reset_index(drop=True)\n",
    "tweets_test = pd.read_csv('../data/tweets_data/test.csv')[['id', 'text']]\n",
    "tweets_labels = pd.read_csv('../data/tweets_data/test_labels.csv', encoding='latin-1')[['choose_one', 'text']]\n",
    "\n",
    "tweets_labels['target'] = (tweets_labels['choose_one']=='Relevant').astype(int)\n",
    "tweets_labels['id'] = tweets_labels.index\n",
    "\n",
    "tweets_test = pd.merge(left = tweets_test, right = tweets_labels, on='id', how = 'left')[['id', 'text_x', 'target']]\n",
    "tweets_test.rename(columns={'text_x': 'text'}, inplace=True)\n",
    "tweets_test = tweets_test[['text', 'target']]\n",
    "\n",
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning text using key-words and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:29:01.782176300Z",
     "start_time": "2023-12-21T15:27:58.466800200Z"
    }
   },
   "outputs": [],
   "source": [
    "tweets_train['clean_text'] = tweets_train['text'].apply(preprocess)\n",
    "tweets_test['clean_text'] = tweets_test['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:29:01.798553700Z",
     "start_time": "2023-12-21T15:29:01.785391100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \n",
       "0               deed reason earthquake allah forgive  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident ask shelter place notify officer evac...  \n",
       "3    people receive wildfire evacuation order cal...  \n",
       "4  got send photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \n",
       "0                     happen terrible car crash  \n",
       "1      hear earthquake different city stay safe  \n",
       "2  forest fire spot pond goose flee street save  \n",
       "3          apocalypse lighting spokane wildfire  \n",
       "4            typhoon soudelor kill china taiwan  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-word tokenization with BERT Tokenizer for Byte-Pair Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the BPE tokenizer on the training data\n",
    "Tokenizer = train_BPE_tokenizer(train_text_df = tweets_train, text_column = 'clean_text', vocab_size = 20000, min_frequency = 1)\n",
    "\n",
    "# Assuming Tokenizer is the pre-trained tokenizer from the training data\n",
    "# Tokenize the test data using the pre-trained tokenizer\n",
    "tokenize_text(tokenizer = Tokenizer, df = tweets_test, text_column = 'clean_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[deed, reason, earthquake, allah, forgive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ron, ge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shelter, place, notify, office...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[, people, receive, wildfire, evacuation, orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                clean_text_tokenized  \n",
       "0         [deed, reason, earthquake, allah, forgive]  \n",
       "1    [forest, fire, near, la, ron, ge, sask, canada]  \n",
       "2  [resident, ask, shelter, place, notify, office...  \n",
       "3  [, people, receive, wildfire, evacuation, orde...  \n",
       "4  [got, send, photo, ruby, alaska, smoke, wildfi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, terrible, car, crash]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, pond, go, ose, flee, stre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, lighting, sp, okane, wildfire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                clean_text_tokenized  \n",
       "0                     [happen, terrible, car, crash]  \n",
       "1    [hear, earthquake, different, city, stay, safe]  \n",
       "2  [forest, fire, spot, pond, go, ose, flee, stre...  \n",
       "3        [apocalypse, lighting, sp, okane, wildfire]  \n",
       "4           [typhoon, soudelor, kill, china, taiwan]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:30:29.849421800Z",
     "start_time": "2023-12-21T15:29:11.378522300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# set the hyperparameter of vocabulary size\\nvocab_size = 3000\\ncorpus = tweets_train['clean_text'].tolist()\\n\\n# create a BPE tokenizer object\\nMyBPE = BPE(corpus=corpus, vocab_size=vocab_size)\\n\\n# train BPE tokenizer with Wikipedia corpus\\nMyBPE.train()\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# set the hyperparameter of vocabulary size\n",
    "vocab_size = 3000\n",
    "corpus = tweets_train['clean_text'].tolist()\n",
    "\n",
    "# create a BPE tokenizer object\n",
    "MyBPE = BPE(corpus=corpus, vocab_size=vocab_size)\n",
    "\n",
    "# train BPE tokenizer with Wikipedia corpus\n",
    "MyBPE.train()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:13.493640100Z",
     "start_time": "2023-12-21T15:32:21.919839300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"tweets_train['tokenized_text'] = tweets_train['clean_text'].apply(lambda x: MyBPE.tokenize(x))\\ntweets_test['tokenized_text'] = tweets_test['clean_text'].apply(lambda x: MyBPE.tokenize(x))\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''tweets_train['tokenized_text'] = tweets_train['clean_text'].apply(lambda x: MyBPE.tokenize(x))\n",
    "tweets_test['tokenized_text'] = tweets_test['clean_text'].apply(lambda x: MyBPE.tokenize(x))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Text into Input Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:23.476189500Z",
     "start_time": "2023-12-21T15:33:21.430017200Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train = vectorizer.fit_transform(tweets_train['clean_text_tokenized'].apply(lambda tokens: ' '.join(tokens)))\n",
    "# Add a new column 'TFIDF' to the original DataFrame with the TF-IDF arrays\n",
    "tweets_train['TFIDF'] = X_train.toarray().tolist()\n",
    "\n",
    "X_test = vectorizer.transform(tweets_test['clean_text_tokenized'].apply(lambda tokens: ' '.join(tokens)))\n",
    "# Add a new column 'TFIDF' to the original DataFrame with the TF-IDF arrays\n",
    "tweets_test['TFIDF'] = X_test.toarray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:23.661826500Z",
     "start_time": "2023-12-21T15:33:23.626279500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[deed, reason, earthquake, allah, forgive]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ron, ge, sask, canada]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shelter, place, notify, office...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[, people, receive, wildfire, evacuation, orde...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0         [deed, reason, earthquake, allah, forgive]   \n",
       "1    [forest, fire, near, la, ron, ge, sask, canada]   \n",
       "2  [resident, ask, shelter, place, notify, office...   \n",
       "3  [, people, receive, wildfire, evacuation, orde...   \n",
       "4  [got, send, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                               TFIDF  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, terrible, car, crash]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, pond, go, ose, flee, stre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, lighting, sp, okane, wildfire]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0                     [happen, terrible, car, crash]   \n",
       "1    [hear, earthquake, different, city, stay, safe]   \n",
       "2  [forest, fire, spot, pond, go, ose, flee, stre...   \n",
       "3        [apocalypse, lighting, sp, okane, wildfire]   \n",
       "4           [typhoon, soudelor, kill, china, taiwan]   \n",
       "\n",
       "                                               TFIDF  \n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec (CBOW and Skip-Gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:33:26.004312100Z",
     "start_time": "2023-12-21T15:33:25.980689800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of tokenized text in training data: 26\n",
      "Maximum length of tokenized text in testing data: 45\n"
     ]
    }
   ],
   "source": [
    "print('Maximum length of tokenized text in training data:', max([len(sent) for sent in tweets_train['clean_text_tokenized']]))\n",
    "print('Maximum length of tokenized text in testing data:', max([len(sent) for sent in tweets_test['clean_text_tokenized']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:07.773767Z",
     "start_time": "2023-12-21T15:33:29.941367700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train Word2Vec model\n",
    "cbow_model = Word2Vec(sentences = tweets_train['clean_text_tokenized'], vector_size = 1024, window = 5, min_count = 1, workers = 4, sg = 0, epochs = 256)\n",
    "# Add the <pad> token to the cbow_model so that the last token is the <pad> token\n",
    "cbow_model.wv.key_to_index['<pad>'] = len(cbow_model.wv)\n",
    "# Add the embedding of <pad> token to the cbow_model\n",
    "cbow_model.wv.vectors = np.append(cbow_model.wv.vectors, np.zeros((1, 1024)), axis=0)\n",
    "\n",
    "\n",
    "skipgram_model = Word2Vec(sentences = tweets_train['clean_text_tokenized'], vector_size = 1024, window = 5, min_count = 1, workers = 4, sg = 1, epochs = 256)\n",
    "# Add the <pad> token to the skipgram_model so that the last token is the <pad> token\n",
    "skipgram_model.wv.key_to_index['<pad>'] = len(skipgram_model.wv)\n",
    "# Add the embedding of <pad> token to the skipgram_model\n",
    "skipgram_model.wv.vectors = np.append(skipgram_model.wv.vectors, np.zeros((1, 1024)), axis=0)\n",
    "\n",
    "# Add the <pad> token to all the tokenized text until the length of each tokenized text is 50\n",
    "tweets_train['clean_text_tokenized'] = tweets_train['clean_text_tokenized'].apply(lambda tokens: tokens + ['<pad>'] * (45 - len(tokens)))\n",
    "tweets_test['clean_text_tokenized'] = tweets_test['clean_text_tokenized'].apply(lambda tokens: tokens + ['<pad>'] * (45 - len(tokens)))\n",
    "\n",
    "# Apply the string2embedding_idx function to create a new column\n",
    "tweets_train['CBOW_sequences'] = tweets_train['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, cbow_model))\n",
    "tweets_train['SkipGram_sequences'] = tweets_train['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, skipgram_model))\n",
    "tweets_test['CBOW_sequences'] = tweets_test['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, cbow_model))\n",
    "tweets_test['SkipGram_sequences'] = tweets_test['clean_text_tokenized'].apply(lambda tokens: string2embedding_idx(tokens, skipgram_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:36.442786700Z",
     "start_time": "2023-12-21T15:34:36.381065300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "      <th>CBOW_sequences</th>\n",
       "      <th>SkipGram_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason earthquake allah forgive</td>\n",
       "      <td>[deed, reason, earthquake, allah, forgive, &lt;pa...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[3996, 461, 209, 1422, 2511, 13815, 13815, 138...</td>\n",
       "      <td>[3996, 461, 209, 1422, 2511, 13815, 13815, 138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ron, ge, sask, canada...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[120, 2, 176, 514, 2045, 1500, 6753, 1137, 138...</td>\n",
       "      <td>[120, 2, 176, 514, 2045, 1500, 6753, 1137, 138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>[resident, ask, shelter, place, notify, office...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1679, 515, 1901, 382, 6750, 322, 205, 1901, 3...</td>\n",
       "      <td>[1679, 515, 1901, 382, 6750, 322, 205, 1901, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>people receive wildfire evacuation order cal...</td>\n",
       "      <td>[, people, receive, wildfire, evacuation, orde...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0, 8, 2988, 84, 205, 292, 38, 13815, 13815, 1...</td>\n",
       "      <td>[0, 8, 2988, 84, 205, 292, 38, 13815, 13815, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>got send photo ruby alaska smoke wildfire pour...</td>\n",
       "      <td>[got, send, photo, ruby, alaska, smoke, wildfi...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[312, 207, 126, 6038, 1457, 217, 84, 3009, 125...</td>\n",
       "      <td>[312, 207, 126, 6038, 1457, 217, 84, 3009, 125...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1             Forest fire near La Ronge Sask. Canada       1   \n",
       "2  All residents asked to 'shelter in place' are ...       1   \n",
       "3  13,000 people receive #wildfires evacuation or...       1   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0               deed reason earthquake allah forgive   \n",
       "1              forest fire near la ronge sask canada   \n",
       "2  resident ask shelter place notify officer evac...   \n",
       "3    people receive wildfire evacuation order cal...   \n",
       "4  got send photo ruby alaska smoke wildfire pour...   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0  [deed, reason, earthquake, allah, forgive, <pa...   \n",
       "1  [forest, fire, near, la, ron, ge, sask, canada...   \n",
       "2  [resident, ask, shelter, place, notify, office...   \n",
       "3  [, people, receive, wildfire, evacuation, orde...   \n",
       "4  [got, send, photo, ruby, alaska, smoke, wildfi...   \n",
       "\n",
       "                                               TFIDF  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      CBOW_sequences  \\\n",
       "0  [3996, 461, 209, 1422, 2511, 13815, 13815, 138...   \n",
       "1  [120, 2, 176, 514, 2045, 1500, 6753, 1137, 138...   \n",
       "2  [1679, 515, 1901, 382, 6750, 322, 205, 1901, 3...   \n",
       "3  [0, 8, 2988, 84, 205, 292, 38, 13815, 13815, 1...   \n",
       "4  [312, 207, 126, 6038, 1457, 217, 84, 3009, 125...   \n",
       "\n",
       "                                  SkipGram_sequences  \n",
       "0  [3996, 461, 209, 1422, 2511, 13815, 13815, 138...  \n",
       "1  [120, 2, 176, 514, 2045, 1500, 6753, 1137, 138...  \n",
       "2  [1679, 515, 1901, 382, 6750, 322, 205, 1901, 3...  \n",
       "3  [0, 8, 2988, 84, 205, 292, 38, 13815, 13815, 1...  \n",
       "4  [312, 207, 126, 6038, 1457, 217, 84, 3009, 125...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_tokenized</th>\n",
       "      <th>TFIDF</th>\n",
       "      <th>CBOW_sequences</th>\n",
       "      <th>SkipGram_sequences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>1</td>\n",
       "      <td>happen terrible car crash</td>\n",
       "      <td>[happen, terrible, car, crash, &lt;pad&gt;, &lt;pad&gt;, &lt;...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[201, 1920, 43, 16, 13815, 13815, 13815, 13815...</td>\n",
       "      <td>[201, 1920, 43, 16, 13815, 13815, 13815, 13815...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>1</td>\n",
       "      <td>hear earthquake different city stay safe</td>\n",
       "      <td>[hear, earthquake, different, city, stay, safe...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[141, 209, 1039, 122, 390, 1008, 13815, 13815,...</td>\n",
       "      <td>[141, 209, 1039, 122, 390, 1008, 13815, 13815,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire spot pond goose flee street save</td>\n",
       "      <td>[forest, fire, spot, pond, go, ose, flee, stre...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[120, 2, 580, 3275, 6, 2899, 2406, 431, 104, 1...</td>\n",
       "      <td>[120, 2, 580, 3275, 6, 2899, 2406, 431, 104, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>apocalypse lighting spokane wildfire</td>\n",
       "      <td>[apocalypse, lighting, sp, okane, wildfire, &lt;p...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[373, 10784, 1663, 2899, 84, 13815, 13815, 138...</td>\n",
       "      <td>[373, 10784, 1663, 2899, 84, 13815, 13815, 138...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>1</td>\n",
       "      <td>typhoon soudelor kill china taiwan</td>\n",
       "      <td>[typhoon, soudelor, kill, china, taiwan, &lt;pad&gt;...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[171, 539, 11, 268, 1021, 13815, 13815, 13815,...</td>\n",
       "      <td>[171, 539, 11, 268, 1021, 13815, 13815, 13815,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  \\\n",
       "0                 Just happened a terrible car crash       1   \n",
       "1  Heard about #earthquake is different cities, s...       1   \n",
       "2  there is a forest fire at spot pond, geese are...       1   \n",
       "3           Apocalypse lighting. #Spokane #wildfires       1   \n",
       "4      Typhoon Soudelor kills 28 in China and Taiwan       1   \n",
       "\n",
       "                                     clean_text  \\\n",
       "0                     happen terrible car crash   \n",
       "1      hear earthquake different city stay safe   \n",
       "2  forest fire spot pond goose flee street save   \n",
       "3          apocalypse lighting spokane wildfire   \n",
       "4            typhoon soudelor kill china taiwan   \n",
       "\n",
       "                                clean_text_tokenized  \\\n",
       "0  [happen, terrible, car, crash, <pad>, <pad>, <...   \n",
       "1  [hear, earthquake, different, city, stay, safe...   \n",
       "2  [forest, fire, spot, pond, go, ose, flee, stre...   \n",
       "3  [apocalypse, lighting, sp, okane, wildfire, <p...   \n",
       "4  [typhoon, soudelor, kill, china, taiwan, <pad>...   \n",
       "\n",
       "                                               TFIDF  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                      CBOW_sequences  \\\n",
       "0  [201, 1920, 43, 16, 13815, 13815, 13815, 13815...   \n",
       "1  [141, 209, 1039, 122, 390, 1008, 13815, 13815,...   \n",
       "2  [120, 2, 580, 3275, 6, 2899, 2406, 431, 104, 1...   \n",
       "3  [373, 10784, 1663, 2899, 84, 13815, 13815, 138...   \n",
       "4  [171, 539, 11, 268, 1021, 13815, 13815, 13815,...   \n",
       "\n",
       "                                  SkipGram_sequences  \n",
       "0  [201, 1920, 43, 16, 13815, 13815, 13815, 13815...  \n",
       "1  [141, 209, 1039, 122, 390, 1008, 13815, 13815,...  \n",
       "2  [120, 2, 580, 3275, 6, 2899, 2406, 431, 104, 1...  \n",
       "3  [373, 10784, 1663, 2899, 84, 13815, 13815, 138...  \n",
       "4  [171, 539, 11, 268, 1021, 13815, 13815, 13815,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Training data')\n",
    "display(tweets_train.head())\n",
    "print()\n",
    "print('Testing data')\n",
    "display(tweets_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:38.609225400Z",
     "start_time": "2023-12-21T15:34:37.441115300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAGoCAYAAADRtEi1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABGN0lEQVR4nO3deVyVZf7/8fcBlE08giYHAwXXJDJUtK9LaeaWZpozlltJOZaaJWVpjtOoTYlLmqYzpDVpaWWL1mjmlrmUmrulYtqYhinEJAauIJzr94c/zngCFRsOyM3r+XicR97Xfd33/TlX4nlz3fd9bpsxxggAAACW41XaBQAAAMAzCHoAAAAWRdADAACwKIIeAACARRH0AAAALIqgBwAAYFEEPQAAAIsi6AEAAFgUQQ8AAMCiCHpACYiPj1ePHj1KuwwAQDlj4xFogOdlZmbKGKMqVaqUdikAgHKEGT2gBNjtdkIeUI60bdtWCQkJpV0GQNADitNHH32kW265Rf7+/qpatarat2+vM2fOFDh1e7l+0n9P806YMEGhoaGqUqWKxo8fr9zcXD377LMKCQlReHi43nzzTbdj79mzR+3atXPt89FHH9Xp06dL8u0D14XIyEhNnz69RI61bt062Ww2/frrr27tixcv1t/+9rcSqQG4EoIeUExSU1PVp08fPfLII9q/f7/WrVunnj176rdXRxSl3xdffKHjx49rw4YNmjZtmsaNG6d77rlHwcHB2rJliwYPHqzBgwfr6NGjkqSzZ8+qc+fOCg4O1rZt2/Thhx/q888/17Bhw0p0DICyIi8vT06n02P7DwkJUVBQkMf2DxSZAVAsduzYYSSZI0eOFFg3YMAA071796v2y+9bq1Ytk5eX52pr0KCBuf32213Lubm5JjAw0Lz33nvGGGPmzJljgoODzenTp119li1bZry8vExaWlpxvD2g2OTl5ZmJEyeaOnXqmIoVK5qIiAjz4osvGmOM+fbbb82dd95p/Pz8TEhIiBk0aJA5deqUa9v8n6UpU6YYh8NhQkJCzNChQ01OTo4xxpg2bdoYSW4vY4yZO3eusdvtZunSpaZhw4bG29vb/PDDD6ZNmzZm+PDhbvV1797dDBgwwLV8/vx58+yzz5rw8HBTsWJFU7duXfPGG2+Yw4cPFzhW/na/3W9GRoZ58MEHTZUqVYy/v7/p3LmzOXjwoGt9fn0rVqwwN910kwkMDDSdOnUyx48fL8aRR3nEjB5QTG699VbddddduuWWW9SrVy+9/vrrOnny5O/qd/PNN8vL678/nqGhobrllltcy97e3qpatarS09MlSfv379ett96qwMBAV59WrVrJ6XTqwIEDxf1Wgf/J6NGjNWnSJD3//PNKTk7Wu+++q9DQ0CLPTK9du1aHDh3S2rVr9dZbb2nevHmaN2+epIunTMPDw/XCCy8oNTVVqampru3Onj2rxMREvfHGG9q3b5+qV69epHofeughLVy4UK+++qr279+v1157TZUqVVJERIQWLVokSTpw4IBSU1M1Y8aMQvcRHx+v7du3a8mSJdq8ebOMMerSpYsuXLjgVt/LL7+s+fPna8OGDUpJSdEzzzxzLUMLFOBT2gUAVuHt7a3Vq1dr06ZNWrVqlWbOnKkxY8Zoy5YtRe4XFRUlSapQoYLbNjabrdC2/FNPxhjZbLZC67pcO1AaTp06pRkzZmjWrFkaMGCAJKlOnTpq3bq1Xn/9dZ07d05vv/2265eWWbNmqVu3bpo0aZJCQ0MlScHBwZo1a5a8vb110003qWvXrlqzZo0GDRqkkJAQeXt7KygoSA6Hw+3YFy5c0D/+8Q/deuutRa734MGD+uCDD7R69Wq1b99eklS7dm3X+pCQEElS9erVL3vD1ffff68lS5Zo48aNatmypSTpnXfeUUREhD755BP16tXLVd9rr72mOnXqSJKGDRumF154oci1AoVhRg8oRjabTa1atdL48eO1a9cuVaxYUR9//PHv7ldU0dHR2r17t+uGDknauHGjvLy8VL9+/d+9X6C47d+/X9nZ2brrrrsKXVeUmembb75Z3t7eruWwsDDX7PaVVKxYUY0aNbqmenfv3i1vb2+1adPmmra71P79++Xj46PbbrvN1Va1alU1aNBA+/fvd7UFBAS4Qp5U9PcFXAlBDygmW7Zs0YQJE7R9+3alpKRo8eLF+s9//qOGDRv+rn7Xol+/fvLz89OAAQO0d+9erV27Vk888YQefPBB1ywIcD3w9/e/7LqizkxfaXb7asf+7f69vLwK3DB16enUK9VbVL/d/6XtV3tfl9sWKKoyf+rW6XTq+PHjCgoK4hQVSpWXl5e++OILvfLKKzp16pQiIiL00ksvqVWrVlqwYIFyc3OVlZV1xX5ZWVm6cOGCq2++vLw85eTkuLUZY3T+/HlX26JFizRq1Cg1a9ZM/v7+uvfeezVhwgS3bYDSFhoaKn9/f3366aeuU7f5oqKiNG/ePKWmprpm9VavXi0vLy+FhYVd9ucjJydHeXl5rjYfHx+dOXPGrc+5c+ckqcDPQ5UqVZSSkuJqz8vL0549e3T77bcrKytLkZGRcjqd+uyzz3TnnXcWeD/5ofDXX391u6720p/ZmjVrKjc3V1988YVrVi8jI0MHDx5UrVq1lJWVVWh9Z8+eLbRmqzDG6NSpU6pRo4bb2KF4lfknY/z000+KiIgo7TIAAMDvcPToUYWHh5d2GZZV5mf08r+n6OjRo6pcuXIpV4PyYusPGXrkrW1X7ffmgGZqXjukBCoCri9X+hkxxqlT2z7R6T1rZDv3q8LCHHr44Yc1YsQI7du3T6NGjdK2bdvcZqYrVaokSRoyZIgyMzP17rvvuvb33HPPac+ePVq2bJkkadu2bUpISND333+v7OxsZWZm6p133tHo0aOVkpLiVsuFCxc0atQoLV68WD4+Pho6dKi2b98uu92upKQkSdL58+f1wgsvaNGiRcrIyFB4eLhGjBih/v37S5ImT56sN954Q+np6erTp4+SkpLUtWtX3XLLLZo4caIk6eTJk3ruuee0fPly5eTkqGXLlpoyZYrrmrzC6vv000/Vr18/ZWZmFsf/kutOVlaWIiIi+L5BDyvzM3pZWVmy2+3KzMwk6KHE5DmNWk/6QmmZ51XYD5BNksPup69GtZO3F5cUoPz51+5jGr5w91X7zegdq+6xN3q+IFx3+PwuGZwUB34Hby+bxnaLlnQx1F0qf3lst2hCHsqt6kF+xdoPwO9D0AN+p84xYUrq30QOu/sHlcPup6T+TdQ5JqyUKgNKX/OoEIXZ/Qr8IpTPJinM7qfmUVzaAHhSmb9GDyhNnWPC1CHaoa2HM5R+6ryqB1384GImD+Vd/qz3kAU7ZZPcLnFg1hsoOVyjBwDwmBV7UzV+abJSM8+72sLsfhrbLZpZ73KOz++SwYweAMBjmPUGShdBDwDgUd5eNrWoU7W0ywDKJW7GAAAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRHg96x44dU//+/VW1alUFBAQoNjZWO3bscK03xmjcuHGqUaOG/P391bZtW+3bt8/TZQEAAFieR4PeyZMn1apVK1WoUEHLly9XcnKypk6dqipVqrj6TJ48WdOmTdOsWbO0bds2ORwOdejQQadOnfJkaQAAAJZnM8YYT+38ueee08aNG/Xll18Wut4Yoxo1aighIUGjRo2SJGVnZys0NFSTJk3SY489dtVjZGVlyW63KzMzU5UrVy7W+gEAgGfw+V0yPDqjt2TJEsXFxalXr16qXr26GjdurNdff921/vDhw0pLS1PHjh1dbb6+vmrTpo02bdpU6D6zs7OVlZXl9gIAAEBBHg16P/zwg5KSklSvXj2tXLlSgwcP1pNPPqm3335bkpSWliZJCg0NddsuNDTUte63EhMTZbfbXa+IiAhPvgUAAIAyy6NBz+l0qkmTJpowYYIaN26sxx57TIMGDVJSUpJbP5vN5rZsjCnQlm/06NHKzMx0vY4ePeqx+gEAAMoyjwa9sLAwRUdHu7U1bNhQKSkpkiSHwyFJBWbv0tPTC8zy5fP19VXlypXdXgAAACjIo0GvVatWOnDggFvbwYMHVatWLUlSVFSUHA6HVq9e7Vqfk5Oj9evXq2XLlp4sDQAAwPJ8PLnzp556Si1bttSECRN0//33a+vWrZozZ47mzJkj6eIp24SEBE2YMEH16tVTvXr1NGHCBAUEBKhv376eLA0AAMDyPBr0mjVrpo8//lijR4/WCy+8oKioKE2fPl39+vVz9Rk5cqTOnTunoUOH6uTJk7rtttu0atUqBQUFebI0AAAAy/Po9+iVBL6HBwCAsofP75LBs24BAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0CsDbDabPvnkk9IuAwAAlDEEPQCW07ZtWyUkJJR2GQBQ6gh614HIyEhNnz7drS02Nlbjxo1TZGSkJOm+++6TzWZzLUvSkiVLFBcXJz8/P1WrVk09e/YsuaIBAMB1j6B3ndu2bZskae7cuUpNTXUtL1u2TD179lTXrl21a9curVmzRnFxcaVZKgAAuM4Q9EpJntNo86ET+tfuY8rOdcppTKH9brjhBklSlSpV5HA4XMsvvfSSevfurfHjx6thw4a69dZb9ec//7nE6gfKkhUrVshut+vtt99WfHy8evTooQkTJig0NFRVqlTR+PHjlZubq2effVYhISEKDw/Xm2++WdplA8D/zKe0CyiPVuxN1filyUrNPC9J+s+pbL265ntFd0hV55iwIu1j9+7dGjRokCfLBCxh4cKFevTRRzV//nx1795dX3zxhb744guFh4drw4YN2rhxowYOHKjNmzfrjjvu0JYtW/T+++9r8ODB6tChgyIiIkr7LQDA78aMXglbsTdVQxbsdIU86eJdtVnnLmjIgp1asTdVknThwoUr7sff39+jdQJW8I9//EODBw/Wv/71L3Xv3t3VHhISoldffVUNGjTQI488ogYNGujs2bP685//rHr16mn06NGqWLGiNm7cWIrVA8D/jhm9EpTnNBq/NFm/PUnrFWBX3ukMSdL4pcm6LTxAhw8fdq2vUKGC8vLy3LZp1KiR1qxZo4cfftjTZQNlQp7TaOvhDKWfOq+scxe0aNEi/fzzz/rqq6/UvHlzt74333yzvLz++3tuaGioYmJiXMve3t6qWrWq0tPTS6x+APAEgl4J2no4w20mL59frUY6s2eN/Os214//qaQe90+Tt7e3a31kZKTWrFmjVq1aydfXV8HBwRo7dqzuuusu1alTR71791Zubq6WL1+ukSNHluRbAq4Lv70cIi01S/6VwlU5J1dz585Vs2bNZLPZXP0rVKjgtr3NZiu0zel0er54APCgEjt1m5iYKJvN5vbdVsYYjRs3TjVq1JC/v7/atm2rffv2lVRJJS79VMGQJ0n2/7tfvhExSv/oBaV/OF6xrTuoTp06rvVTp07V6tWrFRERocaNG0u6+D1hH374oZYsWaLY2Fi1a9dOW7ZsKZH3AVxPCrscQpLyAqvLr/t4fbDoYz3xxBOlVB0AlK4SmdHbtm2b5syZo0aNGrm1T548WdOmTdO8efNUv359vfjii+rQoYMOHDigoKCgkiitRFUP8iu03cs3QDd0H+Va7t3v/zTjrwmu5W7duqlbt24FtuvZsyffnYdy7XKXQ+SrEHKjqvWfqEXvjZaPj0+B76sEAKvz+Ize6dOn1a9fP73++usKDg52tRtjNH36dI0ZM0Y9e/ZUTEyM3nrrLZ09e1bvvvuup8sqFc2jQhRm95PtMuttksLsfmoeFVKSZQFl1uUuh8hnJP1a8QZNm7dY7733nkaMGFFyxQHAdcDjM3qPP/64unbtqvbt2+vFF190tR8+fFhpaWnq2LGjq83X11dt2rTRpk2b9NhjjxW6v+zsbGVnZ7uWs7KyPFd8MfP2smlst2gNWbBTNsltFiI//I3tFi1vr8tFQQCXutzlEI6+E92WA0Jr6ueff77sftatW1eg7ciRI/9LaQBwXfDojN7ChQu1c+dOJSYmFliXlpYm6eLdbpcKDQ11rStMYmKi7Ha761XWvuOqc0yYkvo3kcPufhrXYfdTUv8mRf4ePQCXvxzi9/YDAKvx2Ize0aNHNXz4cK1atUp+fpf/R/bSO+Gki6d0f9t2qdGjR+vpp592LWdlZZXJsNch2uH6KojqQRdP1zKTB1yb/Msh0jLPF3qdnk0Xf4nicgig+ERGRiohIcHt5kpcvzw2o7djxw6lp6eradOm8vHxkY+Pj9avX69XX31VPj4+rpm8387epaenF5jlu5Svr68qV67s9iqLvL1salGnqrrH3qgWdaoS8oDfIf9yCEkFrn3lcgjgfzNv3jxVqVKltMvA/8hjQe+uu+7Snj17tHv3btcrLi5O/fr10+7du1W7dm05HA6tXr3atU1OTo7Wr1+vli1beqosABbD5RBA8bva05lQdngs6AUFBSkmJsbtFRgYqKpVqyomJsb1nXoTJkzQxx9/rL179yo+Pl4BAQHq27evp8oCYEGdY8L01ah2em/Q/2lG71i9N+j/9NWodoQ84P9bsWKFWrdurSpVqqhq1aq65557dOjQIUkXbzyy2Wz64IMP1LZtW/n5+WnBggV6+OGHlZmZKZvNJpvNpnHjxrn2d/bsWT3yyCMKCgpSzZo1NWfOnFJ6Z7iaUn3W7ciRI5WQkKChQ4cqLi5Ox44d06pVqyz5HXoAPIvLIYDLO3PmjJ5++mlt27ZNa9askZeXl+677z63p7+MGjVKTz75pPbv36+77rpL06dPV+XKlZWamqrU1FQ988wzrr5Tp05VXFycdu3apaFDh2rIkCH67rvvSuOt4SpsxpjLfddomZCVlSW73a7MzMwye70eAADF6dJnPxd2w99//vMfVa9eXXv27FGlSpUUFRWl6dOna/jw4a4+8+bNU0JCgn799Ve3fUdGRur222/X/PnzJV28idLhcGj8+PEaPHhwkWvk87tk8KxbAAAs5LfPfpak4NwMVUlerB+/+0a//PKLayYvJSVF0dEXb2iKi4sr8jEufdKVzWaTw+FQenp6Mb0DFCeCHgAAFpH/7OffnqrbN2+MvIOq6a9jJqpHq1vkdDoVExOjnJwcV5/AwMAiH6dChQpuyzabze00MK4fpXqNHgAAKB6Xe/Zz3rksXThxVFVaPqAl/6mq+g1u0smTJ6+6v4oVKyovL88zxaLEMKMHAIAFXO7Zz15+leTlX1mnvlmplEoh+se7WZr/asEnVv1WZGSkTp8+rTVr1ujWW29VQECAAgICPFE6PIgZPQAALOByz3622bxU7d6Rykn7t47/83FNe2GMpkyZctX9tWzZUoMHD9YDDzygG264QZMnTy7uklECuOsWAAAL2HzohPq8/vVV+7036P/Uok7VEqjoyvj8LhnM6AEAYAH5z36+3DdI2iSF8ezncoegBwCABfDsZxSGoAcAgEXw7Gf8FnfdAgBgIZ1jwtQh2nHFJ2Og/CDoAQBgMfnPfgY4dQsAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAojwa9BITE9WsWTMFBQWpevXq6tGjhw4cOODWxxijcePGqUaNGvL391fbtm21b98+T5YFAABQLng06K1fv16PP/64vv76a61evVq5ubnq2LGjzpw54+ozefJkTZs2TbNmzdK2bdvkcDjUoUMHnTp1ypOlAQAAWJ7NGGNK6mD/+c9/VL16da1fv1533HGHjDGqUaOGEhISNGrUKElSdna2QkNDNWnSJD322GNX3WdWVpbsdrsyMzNVuXJlT78FAABQDPj8Lhkleo1eZmamJCkkJESSdPjwYaWlpaljx46uPr6+vmrTpo02bdpU6D6ys7OVlZXl9gIAAEBBJRb0jDF6+umn1bp1a8XExEiS0tLSJEmhoaFufUNDQ13rfisxMVF2u931ioiI8GzhAAAAZVSJBb1hw4bp22+/1XvvvVdgnc1mc1s2xhRoyzd69GhlZma6XkePHvVIvQAAAGWdT0kc5IknntCSJUu0YcMGhYeHu9odDoekizN7YWFhrvb09PQCs3z5fH195evr69mCAQAALMCjM3rGGA0bNkyLFy/WF198oaioKLf1UVFRcjgcWr16tastJydH69evV8uWLT1ZGgAAgOV5dEbv8ccf17vvvqt//etfCgoKcl13Z7fb5e/vL5vNpoSEBE2YMEH16tVTvXr1NGHCBAUEBKhv376eLA0AAMDyPBr0kpKSJElt27Z1a587d67i4+MlSSNHjtS5c+c0dOhQnTx5UrfddptWrVqloKAgT5YGAABgeSX6PXqewPfwAABQ9vD5XTJ41i0AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAiyLoAWWQzWbTJ598UtplAACucz6lXQCAa5eamqrg4ODSLgMAcJ0j6AElKCcnRxUrVvyf9+NwOIqhGgCA1XHqFvCgtm3batiwYXr66adVrVo1dejQQcnJyerSpYsqVaqk0NBQPfjgg/rll1/ctnnyySc1cuRIhYSEyOFwaNy4cW77vfTUbU5OjoYNG6awsDD5+fkpMjJSiYmJrr4pKSnq3r27KlWqpMqVK+v+++/Xzz//7Fo/btw4xcbGav78+YqMjJTdblfv3r116tQpj44NAMDzCHqAh7311lvy8fHRxo0bNXHiRLVp00axsbHavn27VqxYoZ9//ln3339/gW0CAwO1ZcsWTZ48WS+88IJWr15d6P5fffVVLVmyRB988IEOHDigBQsWKDIyUpJkjFGPHj2UkZGh9evXa/Xq1Tp06JAeeOABt30cOnRIn3zyiT799FN9+umnWr9+vSZOnOiR8QAAlBxO3QLFLM9ptPVwhtJPnVfWuQuqW7euJk+eLEn661//qiZNmmjChAmu/m+++aYiIiJ08OBB1a9fX5LUqFEjjR07VpJUr149zZo1S2vWrFGHDh0KHC8lJUX16tVT69atZbPZVKtWLde6zz//XN9++60OHz6siIgISdL8+fN18803a9u2bWrWrJkkyel0at68eQoKCpIkPfjgg1qzZo1eeuklD4wQAKCkEPSAYrRib6rGL01WauZ5SVJaapbsoRFasTdVnWPCtGPHDq1du1aVKlUqsO2hQ4fcgt6lwsLClJ6eXugx4+Pj1aFDBzVo0ECdO3fWPffco44dO0qS9u/fr4iICFfIk6To6GhVqVJF+/fvdwW9yMhIV8i72vEAAGUHQQ8oJiv2pmrIgp0yv2k/ZypoyIKdSurfRE6nU926ddOkSZMKbB8WFub6c4UKFdzW2Ww2OZ3OQo/bpEkTHT58WMuXL9fnn3+u+++/X+3bt9dHH30kY4xsNluBbX7bfi3HAwCUHQQ9oBjkOY3GL00uEPIuNX5psto2bqyPFy9WZGSkfHyK78evcuXKeuCBB/TAAw/oj3/8ozp37qyMjAxFR0crJSVFR48edc3qJScnKzMzUw0bNiy24wMArk/cjAEUg62HM1ynawtjJKVmnleLe/oqIyNDffr00datW/XDDz9o1apVeuSRR5SXl/e7jv3KK69o4cKF+u6773Tw4EF9+OGHcjgcqlKlitq3b69GjRqpX79+2rlzp7Zu3aqHHnpIbdq0UVxc3O98twCAsoKgBxSD9FOXD3mXMgHB2rhxo/Ly8tSpUyfFxMRo+PDhstvt8vL6fT+OlSpV0qRJkxQXF6dmzZrpyJEj+uyzz+Tl5eX6Gpbg4GDdcccdat++vWrXrq3333//dx0LAFC22IwxVzrbdN3LysqS3W5XZmamKleuXNrloJzafOiE+rz+9VX7vTfo/9SiTtUSqAgArm98fpcMZvSAYtA8KkRhdj8VvO3hIpukMLufmkeFlGRZAIByjqAHFANvL5vGdouWpAJhL395bLdoeXtdLgoCAFD8CHpAMekcE6ak/k3ksPu5tTvsfkrq30SdY8IusyVw/br0cXsAyh6+XgUoRp1jwtQh2uF6Mkb1oIuna5nJAwCUBoIeUMy8vWzccAEAuC5w6hYALGr27Nm68cYbCzzl5N5779WAAQMkSUlJSapTp44qVqyoBg0aaP78+Vfc508//aTevXsrJCREgYGBiouL05YtWyRdfIxf9+7dFRoaqkqVKqlZs2b6/PPP3baPjIzUhAkT9MgjjygoKEg1a9bUnDlz3Prs2bNH7dq1k7+/v6pWrapHH31Up0+f/l+HAyiXCHoAYFG9evXSL7/8orVr17raTp48qZUrV6pfv376+OOPNXz4cI0YMUJ79+7VY489pocfftit/6VOnz6tNm3a6Pjx41qyZIm++eYbjRw50hUkT58+rS5duujzzz/Xrl271KlTJ3Xr1k0pKSlu+5k6dari4uK0a9cuDR06VEOGDNF3330nSTp79qw6d+6s4OBgbdu2TR9++KE+//xzDRs2zEOjBFicuQ78/e9/N5GRkcbX19c0adLEbNiwocjbZmZmGkkmMzPTgxUCQNl07733mkceecS1PHv2bONwOExubq5p2bKlGTRokFv/Xr16mS5duriWJZmPP/7YtW1QUJA5ceJEkY8fHR1tZs6c6VquVauW6d+/v2vZ6XSa6tWrm6SkJGOMMXPmzDHBwcHm9OnTrj7Lli0zXl5eJi0trcjHxfWPz++SUeozeu+//74SEhI0ZswY7dq1S7fffrvuvvvuAr8BAgCKJs9ptPnQCf1r9zE1u+teLVq0SNnZ2ZKkd955R71795a3t7f279+vVq1auW3bqlUr7d+/v9D97t69W40bN1ZISOHfB3nmzBmNHDlS0dHRqlKliipVqqTvvvuuwL/njRo1cv3ZZrPJ4XAoPT1dkrR//37deuutCgwMdKvJ6XTqwIED1z4YQDlX6jdjTJs2TQMHDtSf/vQnSdL06dO1cuVKJSUlKTExsZSrA4CyZcXeVI1fmux69rLzQrBOn7+gF5MW6NE/dNSXX36padOmufrbbO53hBtjCrTl8/f3v+Kxn332Wa1cuVIvv/yy6tatK39/f/3xj39UTk6OW78KFSq4LdtsNtfp3ysd/3LtAC6vVGf0cnJytGPHDnXs2NGtvWPHjtq0aVOh22RnZysrK8vtBQC4GPKGLNjpCnmS5FXBV371Wmha0psa98ps1a9fX02bNpUkNWzYUF999ZXbPjZt2qSGDRsWuv9GjRpp9+7dysjIKHT9l19+qfj4eN1333265ZZb5HA4dOTIkWt6D9HR0dq9e7fOnDnjatu4caO8vLxUv379a9oXgFIOer/88ovy8vIUGhrq1h4aGqq0tLRCt0lMTJTdbne9IiIiSqJUALiu5TmNxi9NVmEPLw+Mbquzh7bp3flvq2+/fq72Z599VvPmzdNrr72m77//XtOmTdPixYv1zDPPFHqMPn36yOFwqEePHtq4caN++OEHLVq0SJs3b5Yk1a1bV4sXL9bu3bv1zTffqG/fvgXu+L2afv36yc/PTwMGDNDevXu1du1aPfHEE3rwwQcLfFYAuLpSv0ZPurZTB6NHj1ZmZqbrdfTo0ZIoEQCua1sPZ7jN5F3Kr1YjefsH6fwvRxXduourvUePHpoxY4amTJmim2++WbNnz9bcuXPVtm3bQvdTsWJFrVq1StWrV1eXLl10yy23aOLEifL29pYkvfLKKwoODlbLli3VrVs3derUSU2aNLmm9xEQEKCVK1cqIyNDzZo10x//+EfdddddmjVr1jXtB8BFNmNMYb8AloicnBwFBAToww8/1H333edqHz58uHbv3q3169dfdR9ZWVmy2+3KzMxU5cqVPVkuAFy3/rX7mIYv3H3VfjN6x6p77I2eLwi4Cj6/S0apzuhVrFhRTZs21erVq93aV69erZYtW5ZSVQBQ9lQP8rt6p2voB8AaSv2u26effloPPvig4uLi1KJFC82ZM0cpKSkaPHhwaZcGAGVG86gQhdn9lJZ5vtDr9GySHPaLz14GUH6UetB74IEHdOLECb3wwgtKTU1VTEyMPvvsM9WqVau0SwOAMsPby6ax3aI1ZMFO2SS3sJd/xfPYbtHy9uIrSoDypFSv0SsOnOMHgP/67ffoSVKY3U9ju0Wrc0xYKVYGuOPzu2SU+oweAKD4dI4JU4doh7YezlD6qfOqHnTxdC0zeUD5RNADAIvx9rKpRZ2qpV0GgOvAdfE9egAAACh+BD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoHeNxo0bp9jY2NIuAwAA4KoIegAAABZF0AMAALAoSwW9M2fO6KGHHlKlSpUUFhamqVOnqm3btkpISJAk2Ww2ffLJJ27bVKlSRfPmzXMtjxo1SvXr11dAQIBq166t559/XhcuXLjsMQ8fPqy6detqyJAhcjqdysnJ0ciRI3XjjTcqMDBQt912m9atW1f8bxYAAOAqLBX0nn32Wa1du1Yff/yxVq1apXXr1mnHjh3XtI+goCDNmzdPycnJmjFjhl5//XW98sorhfbdu3evWrVqpV69eikpKUleXl56+OGHtXHjRi1cuFDffvutevXqpc6dO+v7778vjrcIAABQZD6lXUBxOX36tP75z3/q7bffVocOHSRJb731lsLDw69pP3/5y19cf46MjNSIESP0/vvva+TIkW79Nm/erHvuuUejR4/WM888I0k6dOiQ3nvvPf3000+qUaOGJOmZZ57RihUrNHfuXE2YMOF/eYsAAADXxDJBb+mXu5WTk6MWLVq42kJCQtSgQYNr2s9HH32k6dOn69///rdOnz6t3NxcVa5c2a1PSkqK2rdvrxdffFFPPfWUq33nzp0yxqh+/fpu/bOzs1W1atXf8a4AAAB+P8sEvbFL9kmS1h34WQ/VrFloH5vNJmOMW9ul1999/fXX6t27t8aPH69OnTrJbrdr4cKFmjp1qts2N9xwg2rUqKGFCxdq4MCBriDodDrl7e2tHTt2yNvb222bSpUq/c/vEQAA4FpY5ho9nyoOyctHz8xapBV7UyVJJ0+e1MGDB119brjhBqWmprqWv//+e509e9a1vHHjRtWqVUtjxoxRXFyc6tWrpx9//LHAsfz9/fXpp5/Kz89PnTp10qlTpyRJjRs3Vl5entLT01W3bl23l8Ph8NRbBwAAKJRlgp5XRT9VatRBGeve1NOvLNA33+5RfHy8vLz++xbbtWunWbNmaefOndq+fbsGDx6sChUquNbXrVtXKSkpWrhwoQ4dOqRXX31VH3/8caHHCwwM1LJly+Tj46O7775bp0+fVv369dWvXz899NBDWrx4sQ4fPqxt27Zp0qRJ+uyzzzw+BgAAAJeyTNCTpOA7H5FfRIy+m/+82t3VXq1bt1bTpk1d66dOnaqIiAjdcccd6tu3r5555hkFBAS41nfv3l1PPfWUhg0bptjYWG3atEnPP//8ZY9XqVIlLV++XMYYdenSRWfOnNHcuXP10EMPacSIEWrQoIHuvfdebdmyRRERER597wAAAL9lM7+9aK2MycrKkt1uV0TCB/Ly/W9om9E7Vt1jb1Tbtm0VGxur6dOnl16RAADATf7nd2ZmZoGbHj1p3rx5SkhI0K+//lpixyzNWiw1o3ep6kF+pV0CAAAoRZGRkeV+osdyQc8mKczup+ZRIaVdCgAAKAU5OTmlXcJ1w1JBz/b//zu2W7S8vS4urVu3rtyneQAArmfGGE2ePFm1a9eWv7+/br31Vn300UeSpLy8PA0cOFBRUVHy9/dXgwYNNGPGDLft4+Pj1aNHDyUmJqpGjRqqX7++2rZtqx9//FFPPfWUbDabbDab2zYrV65Uw4YNValSJXXu3NntWzny8vL09NNPq0qVKqpatapGjhypAQMGqEePHq4+hc0WxsbGaty4ca7ladOm6ZZbblFgYKAiIiI0dOhQnT59+rLjcOLECTVv3lz33nuvzp8/f8VxKSpLBT2H3U9J/Zuoc0xYaZcCAACK6C9/+Yvmzp2rpKQk7du3T0899ZT69++v9evXy+l0Kjw8XB988IGSk5P117/+VX/+85/1wQcfuO1jzZo12r9/v1avXq1PP/1UixcvVnh4uF544QWlpqa6BbmzZ8/q5Zdf1vz587VhwwalpKS4nnIlXbx5880339Q///lPffXVV8rIyLjst3BciZeXl1599VXt3btXb731lr744osCT9rK99NPP+n222/XTTfdpMWLF8vPz++K41JkpozLzMw0kszqXYdNbp6ztMsBAABFkP/5ffz4cePn52c2bdrktn7gwIGmT58+hW47dOhQ84c//MG1PGDAABMaGmqys7Pd+tWqVcu88sorbm1z5841ksy///1vV9vf//53Exoa6loOCwszEydOdC1fuHDBhIeHm+7du19x37feeqsZO3bsZd/zBx98YKpWrepWi91uNwcOHDA1a9Y0TzzxhHE6L2aZ06dPX/O4FMYyT8ZoXjvEdboWAABcv/KcRlt/yJAkfffddzp//rzrOfX5cnJy1LhxY0nSa6+9pjfeeEM//vijzp07p5ycHMXGxrr1v+WWW1SxYsUiHT8gIEB16tRxLYeFhSk9PV2SlJmZqdTUVLdHqvr4+CguLq7A07WuZu3atZowYYKSk5OVlZWl3NxcnT9/XmfOnFFgYKAk6dy5c2rdurX69Onjdko6OTn5quNSFJYJegAA4Pq3Ym+qxi9N1rH0i0EvPzwtW7ZMN954o1tfX19fffDBB3rqqac0depUtWjRQkFBQZoyZYq2bNni1jc/OBXFpQ9LkAp/ROrVeHl5XfGxqj/++KO6dOmiwYMH629/+5tCQkL01VdfaeDAgW79fH191b59ey1btkzPPvuswsPDJV18rKp0+XEpKoIeAAAoESv2pmrIgp26NB41aNBAvr6+SklJUZs2bQpsM3nyZLVs2VJDhw51tR06dKhIx6tYsaLy8vKuqUa73a6wsDB9/fXXuuOOOyRJubm52rFjh5o0aeLq99vHqmZlZenw4cOu5e3btys3N1dTp051PaXrt9cVShcD4/z589W3b1+1a9dO69atU40aNRQdHX3FcSkqgh4AAPC4PKfR+KXJ+u28WVBQkJ555hk99dRTcjqdat26tbKysrRp0yZVqlRJdevW1dtvv62VK1cqKipK8+fP17Zt2xQVFXXVY0ZGRmrDhg3q3bu3fH19Va1atSLVOnz4cE2cOFH16tVTw4YNNW3atAJfatyuXTvNmzdP3bp1U3BwsJ5//nl5e3u71tepU0e5ubmaOXOmunXrpo0bN+q1114r9Hje3t5655131KdPH1fYczgcVxyXAQMGFOm9WOquWwAAcH3aejhDqZnnC133t7/9TX/961+VmJiohg0bqlOnTlq6dKmioqI0ePBg9ezZUw888IBuu+02nThxwm1270peeOEFHTlyRHXq1NENN9xQ5FpHjBihhx56SPHx8a7Txffdd59bn9GjR+uOO+7QPffcoy5duqhHjx5u1/3FxsZq2rRpmjRpkmJiYvTOO+8oMTHxssf08fHRe++9p5tvvlnt2rVTenr6FcelqCzzCLSSfoQKAAAoun/tPqbhC3e7lp3ZZ3V0+v1l5vM7Pj5ev/76qz755JPSLuWaMKMHAAA8jkeTlg6CHgAA8LjmUSEKs/uJL0IrWQQ9AADgcd5eNo3tFi1JZTLszZs3r8ydtpUIegAAoIR0jglTUv8mctg5jVtSuBkDAACUqDyn0dpvf1SHxlF8fnsYM3oAAKBEeXvZ1Lx2SGmXUS4Q9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEV5LOgdOXJEAwcOVFRUlPz9/VWnTh2NHTtWOTk5bv1SUlLUrVs3BQYGqlq1anryyScL9AEAAMC18/HUjr/77js5nU7Nnj1bdevW1d69ezVo0CCdOXNGL7/8siQpLy9PXbt21Q033KCvvvpKJ06c0IABA2SM0cyZMz1VGgAAQLlQos+6nTJlipKSkvTDDz9IkpYvX6577rlHR48eVY0aNSRJCxcuVHx8vNLT04v07DuedQsAQNnD53fJKNFr9DIzMxUS8t9n223evFkxMTGukCdJnTp1UnZ2tnbs2FHoPrKzs5WVleX2AgAAQEElFvQOHTqkmTNnavDgwa62tLQ0hYaGuvULDg5WxYoVlZaWVuh+EhMTZbfbXa+IiAiP1g0AAFBWXXPQGzdunGw22xVf27dvd9vm+PHj6ty5s3r16qU//elPbutsNluBYxhjCm2XpNGjRyszM9P1Onr06LW+BQAAgHLhmm/GGDZsmHr37n3FPpGRka4/Hz9+XHfeeadatGihOXPmuPVzOBzasmWLW9vJkyd14cKFAjN9+Xx9feXr63utZQMAAJQ71xz0qlWrpmrVqhWp77Fjx3TnnXeqadOmmjt3rry83CcQW7RooZdeekmpqakKCwuTJK1atUq+vr5q2rTptZYGAACAS3jsrtvjx4+rTZs2qlmzpt5++215e3u71jkcDkkXv14lNjZWoaGhmjJlijIyMhQfH68ePXoU+etVuGsHAICyh8/vkuGx79FbtWqV/v3vf+vf//63wsPD3dblZ0tvb28tW7ZMQ4cOVatWreTv76++ffu6vmcPAAAAv1+Jfo+eJ/AbAQAAZQ+f3yWDZ90CAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRBD0AAACLIugBAABYFEEPAADAogh6AAAAFkXQAwAAsCiCHgAAgEUR9AAAACyKoAcAAGBRJRL0srOzFRsbK5vNpt27d7utS0lJUbdu3RQYGKhq1arpySefVE5OTkmUBQAAYGk+JXGQkSNHqkaNGvrmm2/c2vPy8tS1a1fdcMMN+uqrr3TixAkNGDBAxhjNnDmzJEoDAACwLI/P6C1fvlyrVq3Syy+/XGDdqlWrlJycrAULFqhx48Zq3769pk6dqtdff11ZWVmeLg34n7Rt21YJCQnXtM2RI0cKndkGAMATPDqj9/PPP2vQoEH65JNPFBAQUGD95s2bFRMToxo1arjaOnXqpOzsbO3YsUN33nlngW2ys7OVnZ3tWiYQoiyJiIhQamqqqlWrVtqlAADKAY/N6BljFB8fr8GDBysuLq7QPmlpaQoNDXVrCw4OVsWKFZWWllboNomJibLb7a5XREREsdcOeEJOTo68vb3lcDjk41MiV00AAMq5aw5648aNk81mu+Jr+/btmjlzprKysjR69Ogr7s9msxVoM8YU2i5Jo0ePVmZmput19OjRa30LQLHJzc3VsGHDVKVKFVWtWlV/+ctfZIyRJEVGRurFF19UfHy87Ha7Bg0aVODU7bp162Sz2bRmzRrFxcUpICBALVu21IEDB9yOs2TJEsXFxcnPz0/VqlVTz549XetOnjyphx56SMHBwQoICNDdd9+t77//vsTGAABw/brmoDds2DDt37//iq+YmBh98cUX+vrrr+Xr6ysfHx/VrVtXkhQXF6cBAwZIkhwOR4GZu5MnT+rChQsFZvry+fr6qnLlym4voLS89dZb8vHx0ZYtW/Tqq6/qlVde0RtvvOFaP2XKFMXExGjHjh16/vnnL7ufMWPGaOrUqdq+fbt8fHz0yCOPuNYtW7ZMPXv2VNeuXbVr1y5XKMwXHx+v7du3a8mSJdq8ebOMMerSpYsuXLjgmTcNACg7jIf8+OOPZs+ePa7XypUrjSTz0UcfmaNHjxpjjPnss8+Ml5eXOX78uGu7hQsXGl9fX5OZmVmk42RmZhpJRe4PFJc2bdqYhg0bGqfT6WobNWqUadiwoTHGmFq1apkePXq4bXP48GEjyezatcsYY8zatWuNJPP555+7+ixbtsxIMufOnTPGGNOiRQvTr1+/Qms4ePCgkWQ2btzoavvll1+Mv7+/+eCDD4rlfQKAJ/D5XTI8dqFQzZo13ZYrVaokSapTp47Cw8MlSR07dlR0dLQefPBBTZkyRRkZGXrmmWc0aNAgZupwXcpzGm09nKH0U+eVde6CbrvtNrfLDFq0aKGpU6cqLy9Pki57fepvNWrUyPXnsLAwSVJ6erpq1qyp3bt3a9CgQYVut3//fvn4+Oi2225ztVWtWlUNGjTQ/v37r/n9AQCspVSvCPf29tayZcs0dOhQtWrVSv7+/urbt2+hX8UClLYVe1M1fmmyUjPPS5LSUrP0U16qVuxNVeeYsEK3CQwMLNK+K1So4PpzfnB0Op2SJH9//8tuZ/7/9YCFtV/uOlcAQPlRYo9Ai4yMlDFGsbGxbu01a9bUp59+qrNnz+rEiROaOXOmfH19S6osoEhW7E3VkAU7XSEv369HkjVkwU6t2JsqSfr6669Vr149eXt7F9uxGzVqpDVr1hS6Ljo6Wrm5udqyZYur7cSJEzp48KAaNmxYbDUAAMomvuMBuIo8p9H4pckqbO4s99Qvyljzup7L6aETTStq5syZmjp1arEef+zYsbrrrrtUp04d9e7dW7m5uVq+fLlGjhypevXqqXv37ho0aJBmz56toKAgPffcc7rxxhvVvXv3Yq0DAFD2lNiMHlBWbT2cUWAmL1/gze3kzM3Rt39/XEMef1xPPPGEHn300WI9ftu2bfXhhx9qyZIlio2NVbt27dxm8ObOnaumTZvqnnvuUYsWLWSM0WeffeZ2OhgAUD7ZzOUu8ikjsrKyZLfblZmZyQ0c8Ih/7T6m4Qt3X7XfjN6x6h57o+cLAgAL4PO7ZDCjB1xF9SC/Yu0HAEBJIegBV9E8KkRhdj9d7h5Wm6Qwu5+aR4WUZFkAAFwVQQ+4Cm8vm8Z2i5akAmEvf3lst2h5e/F1JrCe/Mf0/frrr6VdCoDfgaAHFEHnmDAl9W8ih9399KzD7qek/k0u+z16QFnTtm1bJSQklHYZAIoJX68CFFHnmDB1iHa4noxRPeji6Vpm8gAA1ytm9IBr4O1lU4s6VdU99ka1qFOVkAdLiY+P1/r16zVjxgzZbDbZbDYdOXJEkrRjxw7FxcUpICBALVu21IEDB9y2Xbp0qZo2bSo/Pz/Vrl1b48ePV25urmu9zWbTG2+8ofvuu08BAQGqV6+elixZUpJvDyiXCHoAAEnSjBkz1KJFCw0aNEipqalKTU1VRESEJGnMmDGaOnWqtm/fLh8fHz3yyCOu7VauXKn+/fvrySefVHJysmbPnq158+bppZdectv/+PHjdf/99+vbb79Vly5d1K9fP2VkZJToewTKG4IeAJRzeU6jzYdOaN3h0zqfZ5O/v78cDoccDofrcX4vvfSS2rRpo+joaD333HPatGmTzp8/71r33HPPacCAAapdu7Y6dOigv/3tb5o9e7bbceLj49WnTx/VrVtXEyZM0JkzZ7R169YSf79AecI1egBQjq3Ym6rxS5NdT39JS81S6vafdPfeVLebjBo1auT6c1jYxfb09HTVrFlTO3bs0LZt29xm8PLy8nT+/HmdPXtWAQEBBfYRGBiooKAgpaene/T9AeUdQQ8AyqkVe1M1ZMHOAs9xPpOdqyELdiqpfxPl32d+6SP1bLaL16Y6nU7Xf8ePH6+ePXsWOIaf33/vVP/tY/lsNptrHwA8g6AHAOVQntNo/NLkAiHP5l1BMhfD1/ilyXrxtqtf4dOkSRMdOHBAdevW9UClAP4XZT7o5T+qNysrq5QrAYCyY+sPGTqWXvBGCO9KIco+tl/Z6UeU8qufdlb1l3Tx31gvr4uh7/Tp05KkU6dOKSsrSyNGjNADDzyg6tWrq0ePHvLy8tLevXuVnJys559/3rXvs2fPFvi3+ty5c/z7XU7l/3/P/xyHZ9hMGR/hn376yXVXGAAAKFuOHj2q8PDw0i7Dssp80HM6nTp+/LiCgoJc1414SlZWliIiInT06FFVrlzZo8cq6xiromGcio6xKhrGqegYq6Lx1DgZY3Tq1CnVqFHDNVuM4lfmT916eXmV+G8ClStX5h+FImKsioZxKjrGqmgYp6JjrIrGE+Nkt9uLdX8oiAgNAABgUQQ9AAAAiyLoXQNfX1+NHTtWvr6+pV3KdY+xKhrGqegYq6JhnIqOsSoaxqlsK/M3YwAAAKBwzOgBAABYFEEPAADAogh6AAAAFkXQAwAAsCiC3jVYtmyZbrvtNvn7+6tatWrq2bOn2/qUlBR169ZNgYGBqlatmp588knl5OSUUrWlLzs7W7GxsbLZbNq9e7fbuvI+VkeOHNHAgQMVFRUlf39/1alTR2PHji0wBuV9nPL94x//UFRUlPz8/NS0aVN9+eWXpV1SqUpMTFSzZs0UFBTker7sgQMH3PoYYzRu3DjVqFFD/v7+atu2rfbt21dKFV8/EhMTZbPZlJCQ4GpjrC46duyY+vfvr6pVqyogIECxsbHasWOHaz3jVDYR9Ipo0aJFevDBB/Xwww/rm2++0caNG9W3b1/X+ry8PHXt2lVnzpzRV199pYULF2rRokUaMWJEKVZdukaOHKkaNWoUaGespO+++05Op1OzZ8/Wvn379Morr+i1117Tn//8Z1cfxumi999/XwkJCRozZox27dql22+/XXfffbdSUlJKu7RSs379ej3++OP6+uuvtXr1auXm5qpjx446c+aMq8/kyZM1bdo0zZo1S9u2bZPD4VCHDh106tSpUqy8dG3btk1z5sxRo0aN3NoZK+nkyZNq1aqVKlSooOXLlys5OVlTp05VlSpVXH0YpzLK4KouXLhgbrzxRvPGG29cts9nn31mvLy8zLFjx1xt7733nvH19TWZmZklUeZ15bPPPjM33XST2bdvn5Fkdu3a5baOsSpo8uTJJioqyrXMOF3UvHlzM3jwYLe2m266yTz33HOlVNH1Jz093Ugy69evN8YY43Q6jcPhMBMnTnT1OX/+vLHb7ea1114rrTJL1alTp0y9evXM6tWrTZs2bczw4cONMYxVvlGjRpnWrVtfdj3jVHYxo1cEO3fu1LFjx+Tl5aXGjRsrLCxMd999t9uU9ebNmxUTE+M2g9WpUydlZ2e7TX2XBz///LMGDRqk+fPnKyAgoMB6xqpwmZmZCgkJcS0zTlJOTo527Nihjh07urV37NhRmzZtKqWqrj+ZmZmS5Pr7c/jwYaWlpbmNm6+vr9q0aVNux+3xxx9X165d1b59e7d2xuqiJUuWKC4uTr169VL16tXVuHFjvf766671jFPZRdArgh9++EGSNG7cOP3lL3/Rp59+quDgYLVp00YZGRmSpLS0NIWGhrptFxwcrIoVKyotLa3Eay4txhjFx8dr8ODBiouLK7QPY1XQoUOHNHPmTA0ePNjVxjhJv/zyi/Ly8gqMQ2hoaLkZg6sxxujpp59W69atFRMTI0musWHcLlq4cKF27typxMTEAusYq4t++OEHJSUlqV69elq5cqUGDx6sJ598Um+//bYkxqksK9dBb9y4cbLZbFd8bd++XU6nU5I0ZswY/eEPf1DTpk01d+5c2Ww2ffjhh6792Wy2AscwxhTaXtYUdaxmzpyprKwsjR49+or7s+pYFXWcLnX8+HF17txZvXr10p/+9Ce3dVYdp2v12/dbHsfgcoYNG6Zvv/1W7733XoF1jJt09OhRDR8+XAsWLJCfn99l+5X3sXI6nWrSpIkmTJigxo0b67HHHtOgQYOUlJTk1q+8j1NZ5FPaBZSmYcOGqXfv3lfsExkZ6brQNDo62tXu6+ur2rVruy4Idzgc2rJli9u2J0+e1IULFwr8BlQWFXWsXnzxRX399dcFnokYFxenfv366a233rL0WBV1nPIdP35cd955p1q0aKE5c+a49bPyOBVVtWrV5O3tXWDGID09vdyMwZU88cQTWrJkiTZs2KDw8HBXu8PhkHRxFiYsLMzVXh7HbceOHUpPT1fTpk1dbXl5edqwYYNmzZrlulu5vI9VWFiY22ecJDVs2FCLFi2SxN+pMq3Urg4sQzIzM42vr6/bzRg5OTmmevXqZvbs2caY/144f/z4cVefhQsXlrsL53/88UezZ88e12vlypVGkvnoo4/M0aNHjTGMVb6ffvrJ1KtXz/Tu3dvk5uYWWM84XdS8eXMzZMgQt7aGDRuW65sxnE6nefzxx02NGjXMwYMHC13vcDjMpEmTXG3Z2dnl8sL5rKwst3+T9uzZY+Li4kz//v3Nnj17GKv/r0+fPgVuxkhISDAtWrQwxvB3qiwj6BXR8OHDzY033mhWrlxpvvvuOzNw4EBTvXp1k5GRYYwxJjc318TExJi77rrL7Ny503z++ecmPDzcDBs2rJQrL12HDx8ucNctY2XMsWPHTN26dU27du3MTz/9ZFJTU12vfIzTRQsXLjQVKlQw//znP01ycrJJSEgwgYGB5siRI6VdWqkZMmSIsdvtZt26dW5/d86ePevqM3HiRGO3283ixYvNnj17TJ8+fUxYWJjJysoqxcqvD5fedWsMY2WMMVu3bjU+Pj7mpZdeMt9//7155513TEBAgFmwYIGrD+NUNhH0iignJ8eMGDHCVK9e3QQFBZn27dubvXv3uvX58ccfTdeuXY2/v78JCQkxw4YNM+fPny+liq8PhQU9YxiruXPnGkmFvi5V3scp39///ndTq1YtU7FiRdOkSRPX14iUV5f7uzN37lxXH6fTacaOHWscDofx9fU1d9xxh9mzZ0/pFX0d+W3QY6wuWrp0qYmJiTG+vr7mpptuMnPmzHFbzziVTTZjjCmFM8YAAADwsHJ91y0AAICVEfQAAAAsiqAHAABgUQQ9AAAAiyLoAQAAWBRBDwAAwKIIegAAABZF0AMAALAogh4AAIBFEfQAAAAsiqAHAABgUQQ9AAAAi/p/Rpx6+SyiPNQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(cbow_model, 'earthquake', 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:39.868591200Z",
     "start_time": "2023-12-21T15:34:39.426708900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(skipgram_model, 'earthquake', 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:40.997210400Z",
     "start_time": "2023-12-21T15:34:40.562299400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(cbow_model, 'disaster', 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:42.087371100Z",
     "start_time": "2023-12-21T15:34:41.642630900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TSNE_10ClosestWords(skipgram_model, 'disaster', 1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Testing our Pre-Trained Embeddings to the PyTorch's Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:46.149953400Z",
     "start_time": "2023-12-21T15:34:46.078377300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1773,  0.1768, -0.1317,  ..., -0.1484,  0.3132, -0.1420],\n",
       "        [-0.2578,  0.0246, -0.3352,  ..., -0.2775,  0.0449,  0.2594],\n",
       "        [-0.0917, -0.0222,  0.0112,  ..., -0.2537,  0.2060, -0.0622],\n",
       "        ...,\n",
       "        [-0.0177,  0.0844,  0.0200,  ..., -0.0068,  0.0031,  0.0847],\n",
       "        [ 0.2132,  0.1367,  0.1521,  ..., -0.0835,  0.1972,  0.3232],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embedding layer with pre-trained weights\n",
    "pretrained_embeddings_layer = torch.nn.Embedding.from_pretrained(torch.FloatTensor(skipgram_model.wv.vectors))\n",
    "# check weights of the pre-trained embedding layer\n",
    "pretrained_embeddings_layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:46.893954100Z",
     "start_time": "2023-12-21T15:34:46.867690500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3996,   461,   209,  1422,  2511, 13815, 13815, 13815, 13815, 13815,\n",
       "         13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815,\n",
       "         13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815,\n",
       "         13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815, 13815,\n",
       "         13815, 13815, 13815, 13815, 13815]),\n",
       " tensor([1.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainTweetsDataset = TweetsDataset(tweets_train, 'skipgram')\n",
    "TrainTweetsDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:48.356003700Z",
     "start_time": "2023-12-21T15:34:48.329539400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding of the first token:          tensor([ 0.2345,  0.0495,  0.1780,  ..., -0.1183,  0.2505, -0.1380])\n",
      "Embedding of the second token:         tensor([-0.0336, -0.3276, -0.0760,  ..., -0.1701,  0.1266,  0.0974])\n",
      "Embedding of the third token:          tensor([ 0.0702,  0.0658, -0.1169,  ..., -0.1883,  0.5498,  0.1769])\n",
      "Embedding of the fourth token:         tensor([-0.1679, -0.2163,  0.1535,  ...,  0.0306,  0.4516,  0.3725])\n",
      "Embedding of the fifth token:          tensor([-0.0255, -0.0488, -0.0416,  ...,  0.0742,  0.1146,  0.1289])\n",
      "Embedding of the sixth token:          tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Embedding of the twenty-fifth token:   tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Embedding of the fortieth token:       tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Embedding of the fiftieth token:       tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "sequence = TrainTweetsDataset[0][0]\n",
    "sequence_embeddings = pretrained_embeddings_layer(sequence)\n",
    "\n",
    "print('Embedding of the first token:          {}'.format(sequence_embeddings[0]))\n",
    "print('Embedding of the second token:         {}'.format(sequence_embeddings[1]))\n",
    "print('Embedding of the third token:          {}'.format(sequence_embeddings[2]))\n",
    "print('Embedding of the fourth token:         {}'.format(sequence_embeddings[3]))\n",
    "print('Embedding of the fifth token:          {}'.format(sequence_embeddings[4]))\n",
    "print('Embedding of the sixth token:          {}'.format(sequence_embeddings[5]))\n",
    "print('Embedding of the twenty-fifth token:   {}'.format(sequence_embeddings[24]))\n",
    "print('Embedding of the fortieth token:       {}'.format(sequence_embeddings[39]))\n",
    "print('Embedding of the fiftieth token:       {}'.format(sequence_embeddings[44]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-Connected Neural Network with TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the TF-IDF column to a torch tensor\n",
    "X_train = torch.FloatTensor(tweets_train['TFIDF'].tolist())\n",
    "# Convert the target column to a torch tensor\n",
    "y_train = torch.FloatTensor(tweets_train['target'].tolist()).unsqueeze(1)\n",
    "\n",
    "# Convert the TF-IDF column to a torch tensor\n",
    "X_test = torch.FloatTensor(tweets_test['TFIDF'].tolist())\n",
    "# Convert the target column to a torch tensor\n",
    "y_test = torch.FloatTensor(tweets_test['target'].tolist()).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch Dataset object\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "# Create a torch DataLoader object\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 1024)\n",
    "\n",
    "# Create a torch Dataset object\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "# Create a torch DataLoader object\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customFCNN = CustomFCNN(input_size = X_train.shape[1], hidden_size = 2048, dropout_rate = 0.5).to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customFCNN.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customFCNN, train_loader, test_loader, optimizer, criterion, epochs = 32, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LSTM Neural Network with Custom Pre-trained Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T15:34:50.418593600Z",
     "start_time": "2023-12-21T15:34:50.412589100Z"
    }
   },
   "outputs": [],
   "source": [
    "TrainTweetsDataset_SkipGram = TweetsDataset(tweets_train, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_SkipGram, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_SkipGram = TweetsDataset(tweets_test, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TestTweetsDataset_SkipGram, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM = CustomLSTM(word2vec_model = skipgram_model,\n",
    "                                  hidden_size = 64, \n",
    "                                  output_size = 1, \n",
    "                                  num_layers = 1, \n",
    "                                  bidirectional = True,\n",
    "                                  freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM_Attention = CustomLSTM_Attention(word2vec_model = skipgram_model, \n",
    "                                                      hidden_size = 64, \n",
    "                                                      output_size = 1, \n",
    "                                                      num_layers = 1, \n",
    "                                                      bidirectional = True,\n",
    "                                                      freeze_embeddings = False).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM_Attention.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM_Attention, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "\n",
    "customPreTrainedLSTM_MultiheadAttention = CustomLSTM_MultiHeadAttention(word2vec_model = skipgram_model,\n",
    "                                                                        hidden_size = 1024, \n",
    "                                                                        output_size = 1, \n",
    "                                                                        dropout = 0.1,\n",
    "                                                                        num_layers = 1, \n",
    "                                                                        bidirectional = True,\n",
    "                                                                        freeze_embeddings = True,\n",
    "                                                                        num_heads = 16).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM_MultiheadAttention.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(model = customPreTrainedLSTM_MultiheadAttention, \n",
    "                                                       train_loader = TrainDataLoader_SkipGram, \n",
    "                                                       test_loader = TestDataLoader_SkipGram, \n",
    "                                                       optimizer = optimizer, \n",
    "                                                       loss_func = criterion, \n",
    "                                                       epochs = 16, \n",
    "                                                       device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_CBOW = TweetsDataset(tweets_train, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_CBOW, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_CBOW = TweetsDataset(tweets_test, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TestTweetsDataset_CBOW, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM = CustomLSTM(word2vec_model = cbow_model,\n",
    "                                  hidden_size = 64, \n",
    "                                  output_size = 1, \n",
    "                                  num_layers = 1, \n",
    "                                  bidirectional = True,\n",
    "                                  freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedLSTM.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedLSTM_Attention = CustomLSTM_Attention(word2vec_model = cbow_model, \n",
    "                                                      hidden_size = 64, \n",
    "                                                      output_size = 1, \n",
    "                                                      num_layers = 1, \n",
    "                                                      bidirectional = True,\n",
    "                                                      freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(customPreTrainedLSTM_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedLSTM_Attention, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training GRU Neural Network with Custom Pre-trained Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SkipGram Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_SkipGram = TweetsDataset(tweets_train, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_SkipGram, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_SkipGram = TweetsDataset(tweets_test, 'skipgram')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_SkipGram = torch.utils.data.DataLoader(dataset = TestTweetsDataset_SkipGram, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU = CustomGRU(word2vec_model = skipgram_model, \n",
    "                                hidden_size = 64, \n",
    "                                output_size = 1, \n",
    "                                num_layers = 1, \n",
    "                                bidirectional = True,\n",
    "                                freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU_Attention = CustomGRU_Attention(word2vec_model = skipgram_model, \n",
    "                                                    hidden_size = 64, \n",
    "                                                    output_size = 1, \n",
    "                                                    num_layers = 1, \n",
    "                                                    bidirectional = True,\n",
    "                                                    freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU_Attention, TrainDataLoader_SkipGram, TestDataLoader_SkipGram, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainTweetsDataset_CBOW = TweetsDataset(tweets_train, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TrainDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TrainTweetsDataset_CBOW, batch_size = 64, shuffle = True)\n",
    "\n",
    "TestTweetsDataset_CBOW = TweetsDataset(tweets_test, 'cbow')\n",
    "# Create a dataloade for the training dataset\n",
    "TestDataLoader_CBOW = torch.utils.data.DataLoader(dataset = TestTweetsDataset_CBOW, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU = CustomGRU(word2vec_model = cbow_model, \n",
    "                                hidden_size = 64, \n",
    "                                output_size = 1, \n",
    "                                num_layers = 1, \n",
    "                                bidirectional = True,\n",
    "                                freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 16, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "customPreTrainedGRU_Attention = CustomGRU_Attention(word2vec_model = cbow_model, \n",
    "                                                    hidden_size = 64, \n",
    "                                                    output_size = 1, \n",
    "                                                    num_layers = 1, \n",
    "                                                    bidirectional = True,\n",
    "                                                    freeze_embeddings = True).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(customPreTrainedGRU_Attention.parameters(), lr = 1e-4, weight_decay = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train(customPreTrainedGRU_Attention, TrainDataLoader_CBOW, TestDataLoader_CBOW, optimizer, criterion, epochs = 8, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "DistilBERTbase_name = \"distilbert-base-uncased\"\n",
    "DistilBERTbase_tokenizer = DistilBertTokenizer.from_pretrained(DistilBERTbase_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = DistilBERTbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = DistilBERTbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a model savel with extentions .bin\n",
    "DistilBERTbase = DistilBertForSequenceClassification.from_pretrained(DistilBERTbase_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "DistilBERTbase = DistilBERTbase.to(device)\n",
    "optimizer = torch.optim.AdamW(DistilBERTbase.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(DistilBERTbase, TrainDataLoader, TestDataLoader, optimizer, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT\n",
    "# Reference: https://arxiv.org/pdf/1810.04805.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT base (110M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTbase_name = \"bert-base-uncased\"\n",
    "BERTbase_tokenizer = BertTokenizer.from_pretrained(BERTbase_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = BERTbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = BERTbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model for sequence classification\n",
    "BERTbase = BertForSequenceClassification.from_pretrained(BERTbase_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTbase = BERTbase.to(device)\n",
    "optimizer = torch.optim.AdamW(BERTbase.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(BERTbase, TrainDataLoader, TestDataLoader, optimizer, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT large (340M parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d815ac4716084ad69fdd51b0deed1990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208634a2dcfe496eae0822afbc326136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f18d0d462e5746d39e748e95d94c14dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BERTlarge_name = \"bert-large-uncased\"\n",
    "BERTlarge_tokenizer = BertTokenizer.from_pretrained(BERTlarge_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = BERTlarge_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = BERTlarge_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa5f9cec3a541f39c73961f4f096dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model for sequence classification\n",
    "BERTlarge = BertForSequenceClassification.from_pretrained(BERTlarge_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTlarge = BERTlarge.to(device)\n",
    "optimizer = torch.optim.AdamW(BERTlarge.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(BERTlarge, TrainDataLoader, TestDataLoader, optimizer, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# roBERTa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roBERTa Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTAbase_name = \"roberta-base\"\n",
    "ROBERTAbase_tokenizer = RobertaTokenizer.from_pretrained(ROBERTAbase_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = ROBERTAbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = ROBERTAbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the roBERTa model for sequence classification\n",
    "ROBERTAbase = RobertaForSequenceClassification.from_pretrained(ROBERTAbase_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "ROBERTAbase = ROBERTAbase.to(device)\n",
    "optimizer = torch.optim.AdamW(ROBERTAbase.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(ROBERTAbase, TrainDataLoader, TestDataLoader, optimizer, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roBERTa Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROBERTAlarge_name = \"roberta-large\"\n",
    "ROBERTAlarge_tokenizer = RobertaTokenizer.from_pretrained(ROBERTAlarge_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERT(tokenizer = ROBERTAlarge_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERT(tokenizer = ROBERTAlarge_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the roBERTa model for sequence classification\n",
    "ROBERTAlarge = RobertaForSequenceClassification.from_pretrained(ROBERTAlarge_name, num_labels = 2, output_attentions = False, output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "ROBERTAlarge = ROBERTAlarge.to(device)\n",
    "optimizer = torch.optim.AdamW(ROBERTAlarge.parameters(), lr = 5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERT(ROBERTAlarge, TrainDataLoader, TestDataLoader, optimizer, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTweet base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "BERTweetbase_name = \"vinai/bertweet-base\"\n",
    "BERTweetbase_tokenizer = AutoTokenizer.from_pretrained(BERTweetbase_name, use_fast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERTweet(tokenizer = BERTweetbase_tokenizer, df = tweets_train, batch_size = 32, shuffle = True)\n",
    "TestDataset, TestDataLoader = TokenizeBERTweet(tokenizer = BERTweetbase_tokenizer, df = tweets_test, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "BERTweetbase = AutoModel.from_pretrained(BERTweetbase_name)\n",
    "BERTweetbase = BERTweetForSequenceClassification(bertweet_model = BERTweetbase, hidden_size = 768, output_size = 1, dropout_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTweetbase = BERTweetbase.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(BERTweetbase.parameters(), lr = 5e-5)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer = optimizer, \n",
    "                                            num_warmup_steps = int(0.1 * len(TrainDataLoader) * 2), \n",
    "                                            num_training_steps = len(TrainDataLoader) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "======== Training phase ========\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4058 | Accuracy = 82.76% | F1-Score = 80.00% | Batch ID = 238 : 100%|██████████| 238/238 [01:06<00:00,  3.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.4457\n",
      "Training Accuracy = 80.22%\n",
      "Training F1-Score = 76.35%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4706 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 15.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.3921\n",
      "Test Accuracy = 84.13%\n",
      "Test F1-Score = 79.51%\n",
      "\n",
      "Epoch 2/2\n",
      "======== Training phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.3988 | Accuracy = 86.21% | F1-Score = 75.00% | Batch ID = 238 : 100%|██████████| 238/238 [01:05<00:00,  3.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Cross-Entropy Loss = 0.3232\n",
      "Training Accuracy = 87.32%\n",
      "Training F1-Score = 84.37%\n",
      "======== Validation phase ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss = 0.4786 | Accuracy = 87.10% | F1-Score = 90.48% | Batch ID = 102 : 100%|██████████| 102/102 [00:06<00:00, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Cross-Entropy Loss = 0.3954\n",
      "Test Accuracy = 84.46%\n",
      "Test F1-Score = 81.15%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERTweet(model = BERTweetbase, \n",
    "                                                                train_loader = TrainDataLoader, \n",
    "                                                                test_loader = TestDataLoader, \n",
    "                                                                optimizer = optimizer, \n",
    "                                                                scheduler = scheduler,\n",
    "                                                                loss_func = criterion, \n",
    "                                                                epochs = 2, \n",
    "                                                                device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERTweet Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "BERTweetlarge_name = \"vinai/bertweet-large\"\n",
    "BERTweetlarge_tokenizer = AutoTokenizer.from_pretrained(BERTweetlarge_name, use_fast = False)\n",
    "\n",
    "# Initialize base BERTweet tokenizer to normalize tweets (large version doesn't do it)\n",
    "BERTweetbase_name = \"vinai/bertweet-base\"\n",
    "BERTweetbase_tokenizer = AutoTokenizer.from_pretrained(BERTweetbase_name, use_fast = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "TrainDataset, TrainDataLoader = TokenizeBERTweet(tokenizer = BERTweetlarge_tokenizer, \n",
    "                                                 df = tweets_train, \n",
    "                                                 batch_size = 32, \n",
    "                                                 shuffle = True, \n",
    "                                                 tokenizer_normalizeTweet = BERTweetbase_tokenizer)\n",
    "\n",
    "TestDataset, TestDataLoader = TokenizeBERTweet(tokenizer = BERTweetlarge_tokenizer, \n",
    "                                               df = tweets_test, \n",
    "                                               batch_size = 32, \n",
    "                                               shuffle = False, \n",
    "                                               tokenizer_normalizeTweet = BERTweetbase_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-large were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/bertweet-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BERTweetlarge = AutoModelForSequenceClassification.from_pretrained(BERTweetlarge_name)\n",
    "BERTweetlarge = AutoModel.from_pretrained(BERTweetlarge_name)\n",
    "BERTweetlarge = BERTweetForSequenceClassification(bertweet_model = BERTweetlarge, hidden_size = 1024, output_size = 1, dropout_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Initialize the network, loss function, and optimizer\n",
    "device = set_device()\n",
    "BERTweetlarge = BERTweetlarge.to(device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(BERTweetlarge.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_f1s, test_losses, test_f1s = train_BERTweet(BERTweetlarge, TrainDataLoader, TestDataLoader, optimizer, criterion, epochs = 2, device = device)\n",
    "#train_losses, train_f1s, test_losses, test_f1s = train_BERT(BERTweetlarge, TrainDataLoader, TestDataLoader, optimizer, epochs = 2, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERTweetbase_8115f1 = torch.load('/Users/luish/Desktop/BERTweetbase_0.8115f1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:06<00:00, 16.65it/s]\n"
     ]
    }
   ],
   "source": [
    "y_true, y_hat = predict(BERTweetbase_8115f1, TestDataLoader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "╒═══════════════════════╤════════════════════════════╤══════════════════════╕\n",
      "│                       │  Predicted Not a Disaster  │  Predicted Disaster  │\n",
      "╞═══════════════════════╪════════════════════════════╪══════════════════════╡\n",
      "│ Actual Not a Disaster │            1665            │         311          │\n",
      "├───────────────────────┼────────────────────────────┼──────────────────────┤\n",
      "│    Actual Disaster    │            196             │         1091         │\n",
      "╘═══════════════════════╧════════════════════════════╧══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "ComputeConfusionMatrix(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════╤═════════╕\n",
      "│       Metric       │  Value  │\n",
      "╞════════════════════╪═════════╡\n",
      "│      Accuracy      │ 84.46%  │\n",
      "├────────────────────┼─────────┤\n",
      "│ Weighted Precision │ 77.82%  │\n",
      "├────────────────────┼─────────┤\n",
      "│  Weighted Recall   │ 84.77%  │\n",
      "├────────────────────┼─────────┤\n",
      "│ Weighted F1 Score  │ 81.15%  │\n",
      "╘════════════════════╧═════════╛\n"
     ]
    }
   ],
   "source": [
    "ComputeClassificationMetrics(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretability (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Transformer Implementation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T23:11:27.031219500Z",
     "start_time": "2023-12-29T23:11:27.022593400Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n",
    "\n",
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-29T23:11:42.408492600Z",
     "start_time": "2023-12-29T23:11:42.384459100Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        # Output layer for binary classification\n",
    "        self.fc = nn.Linear(d_model, 1)\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation for binary classification\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        src_mask = self.generate_mask(src)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        # Global average pooling across sequence length\n",
    "        pooled_output = F.adaptive_avg_pool1d(enc_output.permute(0, 2, 1), 1).view(enc_output.size(0), -1)\n",
    "\n",
    "        # Output layer with sigmoid activation for binary classification\n",
    "        output = self.fc(pooled_output)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_transformer(model, train_loader, test_loader, num_epochs=5, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "\n",
    "        for data in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/ {num_epochs}\"):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            predictions.extend(outputs.cpu().detach().numpy())\n",
    "            true_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_predictions = []\n",
    "        val_true_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(test_loader, desc=\"Validation\"):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                val_predictions.extend(outputs.cpu().detach().numpy())\n",
    "                val_true_labels.extend(labels.cpu().detach().numpy())\n",
    "\n",
    "        val_loss /= len(test_loader)\n",
    "\n",
    "        # Calculate metrics\n",
    "        train_accuracy = accuracy_score(true_labels, np.round(predictions))\n",
    "        val_accuracy = accuracy_score(val_true_labels, np.round(val_predictions))\n",
    "\n",
    "        train_f1 = f1_score(true_labels, np.round(predictions))\n",
    "        val_f1 = f1_score(val_true_labels, np.round(val_predictions))\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}:\"\n",
    "              f\" Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Train F1: {train_f1:.4f},\"\n",
    "              f\" Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}, Val F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
